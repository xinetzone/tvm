# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-06-10 19:41+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:10002
msgid "部署 Single Shot Multibox Detector(SSD) 模型"
msgstr ""

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:10004
msgid ""
"**原作者**：[Yao Wang](https://github.com/kevinthesun)，[Leyuan "
"Wang](https://github.com/Laurawly)"
msgstr ""

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:10006
msgid "本文是使用 TVM 部署 SSD 模型的介绍性教程。使用 GluonCV 预训练 SSD 模型，并将其转换为 Relay IR。"
msgstr ""

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:40002
msgid "初始和设置参数"
msgstr ""

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:40007
msgid "现在支持在 CPU 和 GPU 上编译 SSD。"
msgstr ""

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:40009
msgid ""
"为了在 CPU 上获得最佳的推理性能，根据你的设备改变目标参数，按照 {ref}`tune_relay_x86` 来调优 x86 CPU，按照 "
"{ref}`tune_relay_arm` 来调优 ARM CPU。"
msgstr ""

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:40011
msgid ""
"为了在 Intel graphics 上获得最佳的推理性能，将目标参数改为 `opencl "
"-device=intel_graphics`。但是当在 Mac 上使用 Intel graphics 时，target 需要设置为 "
"`opencl`，只是因为 Mac 上不支持 Intel subgroup 扩展。"
msgstr ""

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:40013
msgid ""
"为了在基于 ``cuda`` 的 GPU 上获得最佳的推理性能，将目标参数改为 ``cuda``；对于基于 ``opencl`` 的 "
"GPU，根据你的设备更改目标参数为 ``opencl``。"
msgstr ""

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:60002
msgid "下载并预处理演示图像。"
msgstr ""

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:80002
msgid "为 CPU 转换和编译模型。"
msgstr ""

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:100004
msgid "创建 TVM 运行时并进行推理"
msgstr ""

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:100007
msgid ""
"如果你在 cmake 期间设定 `-DUSE_THRUST=ON` 启用了 thrust，则使用 ``target = \"cuda "
"-libs\"`` 来启用基于 thrust 的排序。"
msgstr ""

#: ../../../xin/docs/how_to/deploy_models/deploy_ssd_gluoncv.ipynb:120002
msgid "显示结果："
msgstr ""

#~ msgid ""
#~ ":download:`Download Python source code: "
#~ "deploy_ssd_gluoncv.py <deploy_ssd_gluoncv.py>`"
#~ msgstr ""

#~ msgid ""
#~ ":download:`Download Jupyter notebook: "
#~ "deploy_ssd_gluoncv.ipynb <deploy_ssd_gluoncv.ipynb>`"
#~ msgstr ""

#~ msgid ""
#~ "`Gallery generated by Sphinx-Gallery "
#~ "<https://sphinx-gallery.github.io>`_"
#~ msgstr ""

#~ msgid ""
#~ "Click :ref:`here "
#~ "<sphx_glr_download_how_to_deploy_models_deploy_ssd_gluoncv.py>` "
#~ "to download the full example code"
#~ msgstr ""

#~ msgid "Deploy Single Shot Multibox Detector(SSD) model"
#~ msgstr ""

#~ msgid ""
#~ "**Author**: `Yao Wang "
#~ "<https://github.com/kevinthesun>`_ `Leyuan Wang "
#~ "<https://github.com/Laurawly>`_"
#~ msgstr ""

#~ msgid ""
#~ "This article is an introductory tutorial"
#~ " to deploy SSD models with TVM. "
#~ "We will use GluonCV pre-trained "
#~ "SSD model and convert it to Relay"
#~ " IR"
#~ msgstr ""

#~ msgid "Preliminary and Set parameters"
#~ msgstr ""

#~ msgid "We support compiling SSD on both CPUs and GPUs now."
#~ msgstr ""

#~ msgid ""
#~ "To get best inference performance on "
#~ "CPU, change target argument according to"
#~ " your device and follow the "
#~ ":ref:`tune_relay_x86` to tune x86 CPU "
#~ "and :ref:`tune_relay_arm` for arm CPU."
#~ msgstr ""

#~ msgid ""
#~ "To get best inference performance on "
#~ "Intel graphics, change target argument "
#~ "to :code:`opencl -device=intel_graphics`. But "
#~ "when using Intel graphics on Mac, "
#~ "target needs to be set to `opencl`"
#~ " only for the reason that Intel "
#~ "subgroup extension is not supported on"
#~ " Mac."
#~ msgstr ""

#~ msgid ""
#~ "To get best inference performance on "
#~ "CUDA-based GPUs, change the target "
#~ "argument to :code:`cuda`; and for "
#~ "OPENCL-based GPUs, change target argument"
#~ " to :code:`opencl` followed by device "
#~ "argument according to your device."
#~ msgstr ""

#~ msgid "Download and pre-process demo image"
#~ msgstr ""

#~ msgid "Convert and compile model for CPU."
#~ msgstr ""

#~ msgid "Create TVM runtime and do inference .. note::"
#~ msgstr ""

#~ msgid "Display result"
#~ msgstr ""


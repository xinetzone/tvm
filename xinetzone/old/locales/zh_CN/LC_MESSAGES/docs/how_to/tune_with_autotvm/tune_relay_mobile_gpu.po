# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-05-27 12:49+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:13
msgid ""
"Click :ref:`here "
"<sphx_glr_download_how_to_tune_with_autotvm_tune_relay_mobile_gpu.py>` to"
" download the full example code"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:22
msgid "Auto-tuning a Convolutional Network for Mobile GPU"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:23
msgid ""
"**Author**: `Lianmin Zheng <https://github.com/merrymercy>`_, `Eddie Yan "
"<https://github.com/eqy>`_"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:25
msgid ""
"Auto-tuning for a specific device is critical for getting the best "
"performance. This is a tutorial about how to tune a whole convolutional "
"network."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:29
msgid ""
"The operator implementation for Mobile GPU in TVM is written in template "
"form. The template has many tunable knobs (tile factor, vectorization, "
"unrolling, etc). We will tune all convolution, depthwise convolution and "
"dense operators in the neural network. After tuning, we produce a log "
"file which stores the best knob values for all required operators. When "
"the TVM compiler compiles these operators, it will query this log file to"
" get the best knob values."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:36
msgid ""
"We also released pre-tuned parameters for some arm devices. You can go to"
" `Mobile GPU Benchmark <https://github.com/apache/tvm/wiki/Benchmark"
"#mobile-gpu>`_ to see the results."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:40
msgid ""
"Note that this tutorial will not run on Windows or recent versions of "
"macOS. To get it to run, you will need to wrap the body of this tutorial "
"in a :code:`if __name__ == \"__main__\":` block."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:47
msgid "Install dependencies"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:48
msgid ""
"To use the autotvm package in tvm, we need to install some extra "
"dependencies. (change \"3\" to \"2\" if you use python2):"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:55
msgid ""
"To make TVM run faster during tuning, it is recommended to use cython as "
"FFI of tvm. In the root directory of tvm, execute (change \"3\" to \"2\" "
"if you use python2):"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:64
msgid "Now return to python code. Import packages."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:86
msgid "Define network"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:87
msgid ""
"First we need to define the network in relay frontend API. We can load "
"some pre-defined network from :code:`relay.testing`. We can also load "
"models from MXNet, ONNX and TensorFlow."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:146
msgid "Start RPC Tracker"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:147
msgid ""
"TVM uses RPC session to communicate with ARM boards. During tuning, the "
"tuner will send the generated code to the board and measure the speed of "
"code on the board."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:151
msgid ""
"To scale up the tuning, TVM uses RPC Tracker to manage distributed "
"devices. The RPC Tracker is a centralized controller node. We can "
"register all devices to the tracker. For example, if we have 10 phones, "
"we can register all of them to the tracker, and run 10 measurements in "
"parallel, accelerating the tuning process."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:156
msgid ""
"To start an RPC tracker, run this command on the host machine. The "
"tracker is required during the whole tuning process, so we need to open a"
" new terminal for this command:"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:164
msgid "The expected output is"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:173
msgid "Register Devices to RPC Tracker"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:174
msgid ""
"Now we can register our devices to the tracker. The first step is to "
"build the TVM runtime for the ARM devices."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:177
msgid ""
"For Linux: Follow this section :ref:`build-tvm-runtime-on-device` to "
"build the TVM runtime on the device. Then register the device to tracker "
"by"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:185
msgid "(replace :code:`[HOST_IP]` with the IP address of your host machine)"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:187
msgid ""
"For Android: Follow this `readme page "
"<https://github.com/apache/tvm/tree/main/apps/android_rpc>`_ to install "
"TVM RPC APK on the android device. Make sure you can pass the android RPC"
" test. Then you have already registered your device. During tuning, you "
"have to go to developer option and enable \"Keep screen awake during "
"changing\" and charge your phone to make it stable."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:193
msgid "After registering devices, we can confirm it by querying rpc_tracker"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:199
msgid ""
"For example, if we have 2 Huawei mate10 pro, 11 Raspberry Pi 3B and 2 "
"rk3399, the output can be"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:213
msgid ""
"You can register multiple devices to the tracker to accelerate the "
"measurement in tuning."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:218
msgid "Set Tuning Options"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:219
msgid ""
"Before tuning, we should apply some configurations. Here I use an RK3399 "
"board as example. In your setting, you should modify the target and "
"device_key accordingly. set :code:`use_android` to True if you use "
"android phone."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:264
msgid "How to set tuning options"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:266
msgid ""
"In general, the default values provided here work well. If you have "
"enough time budget, you can set :code:`n_trial`, :code:`early_stopping` "
"larger, which makes the tuning run longer. If your device runs very slow "
"or your conv2d operators have many GFLOPs, considering to set timeout "
"larger."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:276
msgid "Begin Tuning"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:277
msgid ""
"Now we can extract tuning tasks from the network and begin tuning. Here, "
"we provide a simple utility function to tune a list of tasks. This "
"function is just an initial implementation which tunes them in sequential"
" order. We will introduce a more sophisticated tuning scheduler in the "
"future."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:341
msgid "Finally, we launch tuning jobs and evaluate the end-to-end performance."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:406
msgid "Sample Output"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:407
msgid ""
"The tuning needs to compile many programs and extract feature from them. "
"So a high performance CPU is recommended. One sample output is listed "
"below. It takes about 3 hours on a 32T AMD Ryzen Threadripper."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:440
msgid "**Experiencing Difficulties?**"
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:442
msgid ""
"The auto tuning module is error-prone. If you always see \" 0.00/ 0.00 "
"GFLOPS\", then there must be something wrong."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:445
msgid ""
"First, make sure you set the correct configuration of your device. Then, "
"you can print debug information by adding these lines in the beginning of"
" the script. It will print every measurement result, where you can find "
"useful error messages."
msgstr ""

#: ../../../xin/docs/how_to/tune_with_autotvm/tune_relay_mobile_gpu.rst:455
msgid ""
"Finally, always feel free to ask our community for help on "
"https://discuss.tvm.apache.org"
msgstr ""

#~ msgid ""
#~ ":download:`Download Python source code: "
#~ "tune_relay_mobile_gpu.py <tune_relay_mobile_gpu.py>`"
#~ msgstr ""

#~ msgid ""
#~ ":download:`Download Jupyter notebook: "
#~ "tune_relay_mobile_gpu.ipynb <tune_relay_mobile_gpu.ipynb>`"
#~ msgstr ""

#~ msgid ""
#~ "`Gallery generated by Sphinx-Gallery "
#~ "<https://sphinx-gallery.github.io>`_"
#~ msgstr ""


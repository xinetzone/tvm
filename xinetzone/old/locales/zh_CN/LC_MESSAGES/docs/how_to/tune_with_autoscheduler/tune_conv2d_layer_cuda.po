# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-05-05 16:40+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:10002
msgid "在 GPU 上自动调优卷积层"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:10004
msgid ""
"**原作者**: [Lianmin Zheng](https://github.com/merrymercy), [Chengfan "
"Jia](https://github.com/jcf94/)"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:10006
msgid "这是关于如何使用 GPU 自动调度器的教程。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:10008
msgid ""
"与基于模板的 [autotvm](../tune_with_autotvm/index) "
"依赖手动模板定义搜索空间不同，自动调度程序不需要任何调度模板。换句话说，自动调度器只使用 `tvm/python/topi` 中的 "
"compute，而不使用现有的调度模板。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:30002
msgid "定义计算"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:30004
msgid "定义卷积层的计算。函数应该返回输入/输出张量的列表。从这些张量中，自动调度程序可以得到整个计算图。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:50002
msgid "创建搜索任务"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:50005
msgid "然后为 resnet 中的最后一个卷积层创建搜索任务。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:70002
msgid "接下来，为自动调度器设置参数。这些参数主要指定在搜索过程中如何进行测量。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:70004
msgid "`measure_ctx` 启动不同的测量进程以提供隔离。它可以在测量期间保护主进程不受 GPU 崩溃的影响，并避免其他运行时冲突。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:70005
msgid ""
"`min_repeat_ms` 定义每次测量中一次“重复”的最小持续时间。这可以预热 GPU，这对于获得准确的测量结果是必要的。通常，建议值 >="
" 300 ms。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:70006
msgid ""
"`num_measure_trials` 是在调优期间可以使用的度量试验的数量。在实践中，建议将它设置在 "
"1000，这通常足以让搜索收敛。可以根据自己的时间预算调整该参数。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:70007
msgid "此外，使用 `RecordToFile` 将测量记录转储到日志文件中，测量记录可以用于查询历史，恢复搜索，并在以后进行更多的分析。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:70008
msgid ""
"查阅 "
"{mod}`tvm.auto_scheduler.TuningOptions`、{mod}`tvm.auto_scheduler.LocalRPCMeasureContext`"
" 获取更多参数。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:90002
msgid "运行搜索"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:90004
msgid "现在准备好所有输入。很简单，不是吗?"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:90006
msgid "可以开始搜索，让自动调度程序发挥它的魔力。经过一些测试之后，可以从日志文件中加载最佳调度并应用它。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:110002
msgid ""
"可以 lower 调度来查看自动调度后的 IR。自动调度器正确地执行优化，包括多级 tiling、cooperative "
"fetching、unrolling和算子融合。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:130002
msgid "检测正确性并评估性能"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:130004
msgid "构建二进制文件并检查其正确性和性能。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:150002
msgid "使用记录文件"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:150004
msgid "在搜索过程中，所有测量记录都被转储到记录文件“conv2d.json”中。测量记录可用于重新应用搜索结果、恢复搜索和执行其他分析。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:160002
msgid "下面的例子，从文件中加载最好的调度，打印等效的 python 调度 API 和 CUDA 源代码。它们可用于调试和学习自动调度器的行为。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:180002
msgid "更复杂的示例是恢复搜索。在这种情况下，需要自己创建搜索策略和代价模型，并通过日志文件恢复搜索策略和代价模型的状态。"
msgstr ""

#: ../../xin/docs/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.ipynb:180004
msgid "在下面的例子中，恢复状态并进行更多的 5 次试验。"
msgstr ""

#~ msgid ""
#~ ":download:`Download Python source code: "
#~ "tune_conv2d_layer_cuda.py <tune_conv2d_layer_cuda.py>`"
#~ msgstr ""

#~ msgid ""
#~ ":download:`Download Jupyter notebook: "
#~ "tune_conv2d_layer_cuda.ipynb <tune_conv2d_layer_cuda.ipynb>`"
#~ msgstr ""

#~ msgid ""
#~ "`Gallery generated by Sphinx-Gallery "
#~ "<https://sphinx-gallery.github.io>`_"
#~ msgstr ""

#~ msgid ""
#~ "Click :ref:`here "
#~ "<sphx_glr_download_how_to_tune_with_autoscheduler_tune_conv2d_layer_cuda.py>`"
#~ " to download the full example code"
#~ msgstr ""

#~ msgid ""
#~ "**Author**: `Lianmin Zheng "
#~ "<https://github.com/merrymercy>`_,             `Chengfan "
#~ "Jia <https://github.com/jcf94/>`_"
#~ msgstr ""

#~ msgid ""
#~ "Different from the template-based "
#~ ":ref:`autotvm <tutorials-autotvm-sec>` which"
#~ " relies on manual templates to define"
#~ " the search space, the auto-scheduler"
#~ " does not require any templates. "
#~ "Users only need to write the "
#~ "computation declaration without any schedule"
#~ " commands or templates. The auto-"
#~ "scheduler can automatically generate a "
#~ "large search space and find a good"
#~ " schedule in the space."
#~ msgstr ""

#~ msgid ""
#~ ":code:`measure_ctx` launches a different "
#~ "process for measurement to provide "
#~ "isolation. It can protect the master "
#~ "process from GPU crashes during "
#~ "measurement and avoid other runtime "
#~ "conflicts."
#~ msgstr ""

#~ msgid "Auto-scheduling a Convolution Layer for GPU"
#~ msgstr ""

#~ msgid ""
#~ "**Author**: [Lianmin "
#~ "Zheng](https://github.com/merrymercy),             [Chengfan "
#~ "Jia](https://github.com/jcf94/)"
#~ msgstr ""

#~ msgid "This is a tutorial on how to use the auto-scheduler for GPUs."
#~ msgstr ""

#~ msgid ""
#~ "Different from the template-based "
#~ "`autotvm <tutorials-autotvm-sec>` which "
#~ "relies on manual templates to define "
#~ "the search space, the auto-scheduler "
#~ "does not require any templates. Users"
#~ " only need to write the computation"
#~ " declaration without any schedule commands"
#~ " or templates. The auto-scheduler can"
#~ " automatically generate a large search "
#~ "space and find a good schedule in"
#~ " the space."
#~ msgstr ""

#~ msgid "We use a convolution layer as an example in this tutorial."
#~ msgstr ""

#~ msgid ""
#~ "Note that this tutorial will not "
#~ "run on Windows or recent versions "
#~ "of macOS. To get it to run, "
#~ "you will need to wrap the body "
#~ "of this tutorial in a :code:`if "
#~ "__name__ == \"__main__\":` block."
#~ msgstr ""

#~ msgid "Define the computation"
#~ msgstr ""

#~ msgid ""
#~ "To begin with, let us define the"
#~ " computation of a convolution layer. "
#~ "The function should return the list "
#~ "of input/output tensors. From these "
#~ "tensors, the auto-scheduler can get "
#~ "the whole computational graph."
#~ msgstr ""

#~ msgid "Create the search task"
#~ msgstr ""

#~ msgid ""
#~ "We then create a search task for"
#~ " the last convolution layer in the"
#~ " resnet."
#~ msgstr ""

#~ msgid ""
#~ "Next, we set parameters for the "
#~ "auto-scheduler. These parameters mainly "
#~ "specify how we do the measurement "
#~ "during the search."
#~ msgstr ""

#~ msgid ""
#~ ":code:`measure_ctx` launches a different "
#~ "process for measurement to provide "
#~ "isolation. It can protect the main "
#~ "process from GPU crashes during "
#~ "measurement and avoid other runtime "
#~ "conflicts."
#~ msgstr ""

#~ msgid ""
#~ ":code:`min_repeat_ms` defines the minimum "
#~ "duration of one \"repeat\" in every "
#~ "measurement. This can warmup the GPU,"
#~ " which is necessary to get accurate"
#~ " measurement results. Typically, we "
#~ "recommend a value >= 300 ms."
#~ msgstr ""

#~ msgid ""
#~ ":code:`num_measure_trials` is the number of"
#~ " measurement trials we can use during"
#~ " the search. We only make 10 "
#~ "trials in this tutorial for a fast"
#~ " demonstration. In practice, 1000 is "
#~ "a good value for the search to "
#~ "converge. You can do more trials "
#~ "according to your time budget."
#~ msgstr ""

#~ msgid ""
#~ "In addition, we use :code:`RecordToFile` "
#~ "to dump measurement records into a "
#~ "file `conv2d.json`. The measurement records"
#~ " can be used to query the "
#~ "history best, resume the search, and "
#~ "do more analyses later."
#~ msgstr ""

#~ msgid ""
#~ "see :any:`auto_scheduler.TuningOptions`, "
#~ ":any:`auto_scheduler.LocalRPCMeasureContext` for more "
#~ "parameters."
#~ msgstr ""

#~ msgid "Run the search"
#~ msgstr ""

#~ msgid ""
#~ "Now we get all inputs ready. "
#~ "Pretty simple, isn't it? We can "
#~ "kick off the search and let the"
#~ " auto-scheduler do its magic. After"
#~ " some measurement trials, we can load"
#~ " the best schedule from the log "
#~ "file and apply it."
#~ msgstr ""

#~ msgid ""
#~ "We can lower the schedule to see"
#~ " the IR after auto-scheduling. The"
#~ " auto-scheduler correctly performs "
#~ "optimizations including multi-level tiling,"
#~ " cooperative fetching, unrolling and "
#~ "operator fusion."
#~ msgstr ""

#~ msgid "Check correctness and evaluate performance"
#~ msgstr ""

#~ msgid "We build the binary and check its correctness and performance."
#~ msgstr ""

#~ msgid "Using the record file"
#~ msgstr ""

#~ msgid ""
#~ "During the search, all measurement "
#~ "records are dumped into the record "
#~ "file \"conv2d.json\". The measurement records"
#~ " can be used to re-apply search"
#~ " results, resume the search, and "
#~ "perform other analyses."
#~ msgstr ""

#~ msgid ""
#~ "Here is an example where we load"
#~ " the best schedule from a file, "
#~ "print the equivalent python schedule API"
#~ " and CUDA source code. They can "
#~ "be used for debugging and learning "
#~ "the behavior of the auto-scheduler."
#~ msgstr ""

#~ msgid ""
#~ "A more complicated example is to "
#~ "resume the search. In this case, "
#~ "we need to create the search "
#~ "policy and cost model by ourselves "
#~ "and resume the status of search "
#~ "policy and cost model with the log"
#~ " file. In the example below we "
#~ "resume the status and do more 5"
#~ " trials."
#~ msgstr ""


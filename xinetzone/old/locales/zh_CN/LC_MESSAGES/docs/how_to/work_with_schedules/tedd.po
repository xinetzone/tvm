# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-02-09 00:02+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:10002
msgid "使用 TEDD 进行可视化"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:10004
msgid "**原作者**: [Yongfeng Gu](https://github.com/yongfeng-nv)"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:10006
msgid "这是关于使用 TEDD (Tensor Expression Debug Display) 可视化张量表达式的介绍。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:10008
msgid ""
"张量表达式使用原语(primitive)调度。尽管单个原语通常很容易理解，但当您将它们放在一起时，它们很快就变得复杂了。在张量表达式中引入了调度原语的运算模型"
" (operational model)。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:10010
msgid "不同调度原语之间的交互，"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:10011
msgid "调度原语对最终代码生成(code generation)的影响。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:10013
msgid ""
"运算模型基于数据流图(Dataflow Graph)、调度树(Schedule Tree)和迭代关系图(IterVar Relationship "
"Graph)。调度原语对这些图执行运算。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:10015
msgid "TEDD 根据给定的调度呈现这三个图。本教程演示了如何使用 TEDD 以及如何解释呈现的图。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:30002
msgid "定义和调度带有 bias 和 ReLU 的卷积"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:30004
msgid "建立包含 Bias 和 ReLU 的卷积张量表达式的例子。首先连接 conv2d、add 和 relu TOPIs。然后，创建 TOPI 通用调度。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:50002
msgid "使用 TEDD 渲染 Graph"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:50004
msgid "渲染图来查看计算过程以及如何调度它。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:70002
msgid "也可保存图到本地:"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:80002
msgid ""
"第一个是数据流图。每个节点表示一个阶段，中间显示名称和 memory scope，两侧显示 inputs/outputs "
"信息。边表示节点的依赖关系。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:100002
msgid "刚刚渲染了调度树图。您可能会注意到关于范围不可用的警告。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:100004
msgid "该消息还建议调用 `normalize()` 来推断范围信息。鼓励您比较 `normalize()` 前后的图表，以了解其影响。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:120002
msgid ""
"现在，仔细看看第二个调度树。ROOT 下的每个块代表一个阶段。阶段名称显示在顶部行，计算显示在底部行。中间的行是 "
"IterVars，外部越高，内部越低。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:120004
msgid ""
"IterVar 行包含它的索引、名称、类型和其他可选信息。以 W.shared 为例。第一行告诉它的名称 \"W.shared\" 和内存作用域 "
"\"Shared\"。它的计算是: `W(ax0, ax1, ax2, ax3)`。它最外层的循环 IterVar 是 "
"ax0.ax1.fused.ax2.fused.ax3.fused.outer，kDataPar 的索引为 0，绑定到 threadIdx.y 和"
" range(min=0, ext=8)。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:120006
msgid "您还可以使用图例中所示的索引框颜色来告诉 IterVar 类型。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:120008
msgid ""
"如果一个阶段没有 compute_at 的任何其他阶段，它就有一条直接到 ROOT 节点的边。否则，它有一条边指向它所附加的 IterVar，例如"
" W.shared  附加到 rx.outer 中间计算阶段。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:120013
msgid "根据定义，itervar 是内部节点，计算是调度树的叶子节点。省略了 IterVars 之间的边和阶段内的计算，使每个阶段成为块，以提高可读性。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:140002
msgid ""
"最后一个是迭代关系图(IterVar Relationship Graph)。每个子图表示一个阶段，并包含 IterVar "
"节点和变换节点。例如，W.shared 有三个 split 节点和三个 fuse 节点。其余的是 IterVar 节点，其格式与 Schedule"
" Trees 中的 IterVar 行相同。Root itervar 是那些不受任何变换节点驱动的迭代器，例如 ax0; 叶 IterVars "
"不驱动任何变换节点，并且具有非负索引，如 ax0.ax1.fused.ax2.fused.ax3.fused.outer 索引为 0。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:150002
msgid "小结"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/tedd.ipynb:150004
msgid "本教程演示了 TEDD 的用法。使用一个用 TOPI 构建的示例来显示底层的调度。您还可以在任何调度原语之前和之后使用它来检查其效果。"
msgstr ""

#~ msgid ":download:`Download Python source code: tedd.py <tedd.py>`"
#~ msgstr ""

#~ msgid ":download:`Download Jupyter notebook: tedd.ipynb <tedd.ipynb>`"
#~ msgstr ""

#~ msgid ""
#~ "`Gallery generated by Sphinx-Gallery "
#~ "<https://sphinx-gallery.github.io>`_"
#~ msgstr ""

#~ msgid ""
#~ "Click :ref:`here "
#~ "<sphx_glr_download_how_to_work_with_schedules_tedd.py>` to "
#~ "download the full example code"
#~ msgstr ""

#~ msgid "Use Tensor Expression Debug Display (TEDD) for Visualization"
#~ msgstr ""

#~ msgid "**Author**: `Yongfeng Gu <https://github.com/yongfeng-nv>`_"
#~ msgstr ""

#~ msgid ""
#~ "This is an introduction about using "
#~ "TEDD to visualize tensor expressions."
#~ msgstr ""

#~ msgid ""
#~ "Tensor Expressions are scheduled with "
#~ "primitives.  Although individual primitives "
#~ "are usually easy to understand, they "
#~ "become complicated quickly when you put"
#~ " them together. We have introduced an"
#~ " operational model of schedule primitives"
#~ " in Tensor Expression."
#~ msgstr ""

#~ msgid "the interactions between different schedule primitives,"
#~ msgstr ""

#~ msgid "the impact of the schedule primitives on the final code generation."
#~ msgstr ""

#~ msgid ""
#~ "The operational model is based on "
#~ "a Dataflow Graph, a Schedule Tree "
#~ "and an IterVar Relationship Graph. "
#~ "Schedule primitives perform operations on "
#~ "these graphs."
#~ msgstr ""

#~ msgid ""
#~ "TEDD renders these three graphs from "
#~ "a given schedule.  This tutorial "
#~ "demonstrates how to use TEDD and "
#~ "how to interpret the rendered graphs."
#~ msgstr ""

#~ msgid "Define and Schedule Convolution with Bias and ReLU"
#~ msgstr ""

#~ msgid ""
#~ "Let's build an example Tensor Expression"
#~ " for a convolution followed by Bias"
#~ " and ReLU. We first connect conv2d,"
#~ " add, and relu TOPIs.  Then, we "
#~ "create a TOPI generic schedule."
#~ msgstr ""

#~ msgid "Render Graphs with TEDD"
#~ msgstr ""

#~ msgid ""
#~ "We render graphs to see the "
#~ "computation and how it is scheduled. "
#~ "If you run the tutorial in a "
#~ "Jupyter notebook, you can use the "
#~ "following commented lines to render SVG"
#~ " figures showing in notebook directly."
#~ msgstr ""

#~ msgid ""
#~ "The first one is a dataflow graph."
#~ "  Every node represents a stage with"
#~ " name and memory scope shown in "
#~ "the middle and inputs/outputs information "
#~ "on the sides. Edges show nodes' "
#~ "dependency."
#~ msgstr ""

#~ msgid ""
#~ "We just rendered the schedule tree "
#~ "graph.  You may notice an warning "
#~ "about ranges not available. The message"
#~ " also suggests to call normalize() to"
#~ " infer range information.  We will "
#~ "skip inspecting the first schedule tree"
#~ " and encourage you to compare the "
#~ "graphs before and after normalize() for"
#~ " its impact."
#~ msgstr ""

#~ msgid ""
#~ "Now, let us take a close look "
#~ "at the second schedule tree.  Every "
#~ "block under ROOT represents a stage."
#~ "  Stage name shows in the top "
#~ "row and compute shows in the "
#~ "bottom row. The middle rows are "
#~ "for IterVars, the higher the outer, "
#~ "the lower the inner. An IterVar "
#~ "row contains its index, name, type, "
#~ "and other optional information. Let's "
#~ "use the W.shared stage as an "
#~ "example.  The top row tells its "
#~ "name, \"W.shared\", and memory scope, "
#~ "\"Shared\".  Its compute is :code:`W(ax0, "
#~ "ax1, ax2, ax3)`. Its outer most "
#~ "loop IterVar is "
#~ "ax0.ax1.fused.ax2.fused.ax3.fused.outer, indexed with "
#~ "0, of kDataPar, bound to threadIdx.y,"
#~ " and with range(min=0, ext=8). You "
#~ "can also tell IterVar type with "
#~ "the index box color, shown in the"
#~ " legend."
#~ msgstr ""

#~ msgid ""
#~ "If a stage doesn't compute_at any "
#~ "other stage, it has an edge "
#~ "directly to the ROOT node.  Otherwise,"
#~ " it has an edge pointing to the"
#~ " IterVar it attaches to, such as "
#~ "W.shared attaches to rx.outer in the "
#~ "middle compute stage."
#~ msgstr ""

#~ msgid ""
#~ "By definition, IterVars are internal "
#~ "nodes and computes are leaf nodes "
#~ "in a schedule tree.   The edges "
#~ "among IterVars and compute within one"
#~ " stage are omitted, making every "
#~ "stage a block, for better readability."
#~ msgstr ""

#~ msgid ""
#~ "The last one is an IterVar "
#~ "Relationship Graph.  Every subgraph represents"
#~ " a stage and contains IterVar nodes"
#~ " and transformation nodes.  For example,"
#~ " W.shared has three split nodes and"
#~ " three fuse nodes.  The rest are "
#~ "IterVar nodes of the same format "
#~ "as the IterVar rows in Schedule "
#~ "Trees.  Root IterVars are those not "
#~ "driven by any transformation node, such"
#~ " as ax0; leaf IterVars don't drive"
#~ " any transformation node and have "
#~ "non-negative indices, such as "
#~ "ax0.ax1.fused.ax2.fused.ax3.fused.outer with index "
#~ "of 0."
#~ msgstr ""

#~ msgid "Summary"
#~ msgstr ""

#~ msgid ""
#~ "This tutorial demonstrates the usage of"
#~ " TEDD.  We use an example built "
#~ "with TOPI to show the schedules "
#~ "under the hood.  You can also use"
#~ " it before and after any schedule "
#~ "primitive to inspect its effect."
#~ msgstr ""


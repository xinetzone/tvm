# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-06-25 10:20+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:10002
msgid "Tensorflow 前端"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:10004
msgid "参考: [](https://xinetzone.github.io/tvm/docs/arch/frontend/tensorflow.html)"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:10007
msgid ""
"请将 `tensorflow` 的 GPU 内存使用限制在必要的范围内，而不是使用所有可用的内存。您可以参考 "
"[limiting_gpu_memory_growth](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)"
" 了解如何进行操作。"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:30002
msgid "准备阶段"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:50002
msgid "下载如下文件："
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:70002
msgid "在 tensorflow 上推理"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:70004
msgid "在 TensorFlow 上运行相应的模型。"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:90002
msgid "运行 TensorFlow 推理："
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:110002
msgid "展示结果："
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:130002
msgid "Relay 推理"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:130004
msgid "将 TensorFlow graph 定义导入到 Relay 前端。"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:130006
#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:170006
msgid "结果："
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:130008
msgid "sym: Relay 表达式，表示给定的 tensorflow protobuf。"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:130009
msgid "params: 从 tensorflow params（张量 protobuf）转换而来的参数。"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:140002
msgid "目标设备设置:"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:170002
msgid "Relay 构建"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:170004
msgid "使用给定的输入规格将图编译为 LLVM 目标。"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:170008
msgid "`graph`：编译后的最终计算图。"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:170009
msgid "`params`：编译后的最终参数。"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:170010
msgid "`lib`：可以在具有 TVM 运行时的目标上部署的目标库。"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:190002
msgid "在 TVM 上执行 portable graph"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:190004
msgid "现在我们可以尝试在目标设备上部署编译好的模型。"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:210002
msgid "TVM 处理输出"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:210004
msgid "将 InceptionV1 模型的输出处理成可读的文本形式。"
msgstr ""

#: ../../xin/docs/how_to/compile_models/from_tensorflow.ipynb:230002
msgid "布局变换"
msgstr ""

#~ msgid ""
#~ ":download:`Download Python source code: "
#~ "from_tensorflow.py <from_tensorflow.py>`"
#~ msgstr ""

#~ msgid ""
#~ ":download:`Download Jupyter notebook: "
#~ "from_tensorflow.ipynb <from_tensorflow.ipynb>`"
#~ msgstr ""

#~ msgid ""
#~ "`Gallery generated by Sphinx-Gallery "
#~ "<https://sphinx-gallery.github.io>`_"
#~ msgstr ""

#~ msgid ""
#~ "Click :ref:`here "
#~ "<sphx_glr_download_how_to_compile_models_from_tensorflow.py>` to"
#~ " download the full example code"
#~ msgstr ""

#~ msgid ""
#~ "tensorflow frontend import doesn't support "
#~ "preprocessing ops like JpegDecode. JpegDecode"
#~ " is bypassed (just return source "
#~ "node). Hence we supply decoded frame "
#~ "to TVM instead."
#~ msgstr ""

#~ msgid "Results:"
#~ msgstr ""

#~ msgid ""
#~ "sym: relay expr for given tensorflow "
#~ "protobuf. params: params converted from "
#~ "tensorflow params (tensor protobuf)."
#~ msgstr ""

#~ msgid ""
#~ "graph: Final graph after compilation. "
#~ "params: final params after compilation. "
#~ "lib: target library which can be "
#~ "deployed on target with TVM runtime."
#~ msgstr ""

#~ msgid "Compile Tensorflow Models"
#~ msgstr ""

#~ msgid ""
#~ "This article is an introductory tutorial"
#~ " to deploy tensorflow models with "
#~ "TVM."
#~ msgstr ""

#~ msgid ""
#~ "For us to begin with, tensorflow "
#~ "python module is required to be "
#~ "installed."
#~ msgstr ""

#~ msgid "Please refer to https://www.tensorflow.org/install"
#~ msgstr ""

#~ msgid "Tutorials"
#~ msgstr ""

#~ msgid ""
#~ "Please refer docs/frontend/tensorflow.md for "
#~ "more details for various models from "
#~ "tensorflow."
#~ msgstr ""

#~ msgid "Download required files"
#~ msgstr ""

#~ msgid "Download files listed above."
#~ msgstr ""

#~ msgid "Import model"
#~ msgstr ""

#~ msgid "Creates tensorflow graph definition from protobuf file."
#~ msgstr ""

#~ msgid "Decode image"
#~ msgstr ""

#~ msgid "Import the graph to Relay"
#~ msgstr ""

#~ msgid "Import tensorflow graph definition to relay frontend."
#~ msgstr ""

#~ msgid ""
#~ "Results:   sym: relay expr for given "
#~ "tensorflow protobuf.   params: params "
#~ "converted from tensorflow params (tensor "
#~ "protobuf)."
#~ msgstr ""

#~ msgid "Relay Build"
#~ msgstr ""

#~ msgid "Compile the graph to llvm target with given input specification."
#~ msgstr ""

#~ msgid ""
#~ "Results:   graph: Final graph after "
#~ "compilation.   params: final params after "
#~ "compilation.   lib: target library which "
#~ "can be deployed on target with TVM"
#~ " runtime."
#~ msgstr ""

#~ msgid "Execute the portable graph on TVM"
#~ msgstr ""

#~ msgid "Now we can try deploying the compiled model on target."
#~ msgstr ""

#~ msgid "Process the output"
#~ msgstr ""

#~ msgid "Process the model output to human readable text for InceptionV1."
#~ msgstr ""

#~ msgid "Inference on tensorflow"
#~ msgstr ""

#~ msgid "Run the corresponding model on tensorflow"
#~ msgstr ""


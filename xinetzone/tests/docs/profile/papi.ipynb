{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAPI 快速上手\n",
    "\n",
    "PAPI（Performance Application Programming Interface）是在各种平台上提供性能计数器的库。性能计数器提供关于给定执行运行期间处理器行为的准确底层信息。该信息可以包含简单的指标，如总周期计数（total cycle count）、缓存未命中（cache misses）和执行指令（instructions executed），以及更高级的信息，如总 FLOPS 和 warp 占用率（occupancy）。PAPI 使这些指标在分析时可用。\n",
    "\n",
    "## 安装 PAPI\n",
    "\n",
    "PAPI 可以使用你的包管理器来安装（``apt-get install libpapi-dev``）或者从[这里](https://bitbucket.org/icl/papi/src/master/)获取源码\n",
    "\n",
    "\n",
    "## 用 PAPI 构建 TVM\n",
    "\n",
    "要在 TVM 构建中包含 PAPI，需要在 ``config.cmake`` 中设置如下：\n",
    "\n",
    "```Makefile\n",
    "set(USE_PAPI ON)\n",
    "```\n",
    "\n",
    "如果 PAPI 被安装在非标准的地方，你可以像这样指定它的位置：\n",
    "\n",
    "```Makefile\n",
    "set(USE_PAPI path/to/papi.pc)\n",
    "```\n",
    "\n",
    "## 在剖析时使用 PAPI\n",
    "\n",
    "如果 TVM 是用 PAPI 构建的(见上文)，那么你可以将 {py:class}`tvm.runtime.profiling.PAPIMetricCollector` 传递给 {py:meth}`tvm.runtime.GraphModule.profile` 来收集性能指标。下面是例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pytest\n",
    "from tvm.runtime import profiler_vm\n",
    "from tvm import relay\n",
    "import tvm\n",
    "from tvm.relay.testing import mlp\n",
    "\n",
    "\n",
    "target = \"llvm\"\n",
    "dev = tvm.cpu()\n",
    "mod, params = mlp.get_workload(1)\n",
    "\n",
    "exe = relay.vm.compile(mod, target, params=params)\n",
    "vm = profiler_vm.VirtualMachineProfiler(exe, dev)\n",
    "\n",
    "data = tvm.nd.array(np.random.rand(1, 1, 28, 28).astype(\"float32\"), device=dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "report = vm.profile(\n",
    "    [data],\n",
    "    func_name=\"main\",\n",
    "    collectors=[tvm.runtime.profiling.PAPIMetricCollector({tvm.cpu(): [\"PAPI_FP_OPS\"]})],\n",
    ")\n",
    "print(report)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了保证正常运行，需要设定 `/proc/sys/kernel/perf_event_paranoid` 为 2 或者更小或者作为 root：\n",
    "\n",
    "```bash\n",
    "sudo sh -c \"echo 2 > /proc/sys/kernel/perf_event_paranoid\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = \"float32\"\n",
    "target = \"llvm\"\n",
    "x = relay.var(\"x\", shape=(relay.Any(), relay.Any()), dtype=dtype)\n",
    "y = relay.var(\"y\", shape=(relay.Any(), relay.Any()), dtype=dtype)\n",
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = relay.Function([x, y], relay.add(x, y))\n",
    "exe = relay.vm.compile(mod, target)\n",
    "vm = profiler_vm.VirtualMachineProfiler(exe, dev)\n",
    "\n",
    "data = np.random.rand(28, 28).astype(\"float32\")\n",
    "report = vm.profile(data, data, func_name=\"main\")\n",
    "assert \"fused_add\" in str(report)\n",
    "assert \"Total\" in str(report)\n",
    "assert \"AllocTensorReg\" in str(report)\n",
    "assert \"AllocStorage\" in str(report)\n",
    "assert report.configuration[\"Executor\"] == \"VM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import csv\n",
    "\n",
    "def read_csv(report):\n",
    "    f = StringIO(report.csv())\n",
    "    headers = []\n",
    "    rows = []\n",
    "    reader = csv.reader(f, delimiter=\",\")\n",
    "    # force parsing\n",
    "    in_header = True\n",
    "    for row in reader:\n",
    "        if in_header:\n",
    "            headers = row\n",
    "            in_header = False\n",
    "            rows = [[] for x in headers]\n",
    "        else:\n",
    "            for i in range(len(row)):\n",
    "                rows[i].append(row[i])\n",
    "    return dict(zip(headers, rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_csv = read_csv(report)\n",
    "\n",
    "assert \"Hash\" in _csv.keys()\n",
    "# Ops should have a duration greater than zero.\n",
    "assert all(\n",
    "    [\n",
    "        float(dur) > 0\n",
    "        for dur, name in zip(_csv[\"Duration (us)\"], _csv[\"Name\"])\n",
    "        if name[:5] == \"fused\"\n",
    "    ]\n",
    ")\n",
    "# AllocTensor or AllocStorage may be cached, so their duration could be 0.\n",
    "assert all(\n",
    "    [\n",
    "        float(dur) >= 0\n",
    "        for dur, name in zip(_csv[\"Duration (us)\"], _csv[\"Name\"])\n",
    "        if name[:5] != \"fused\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                                                 Duration (us)  Percent  Device  Count                                                    Argument Shapes              Hash  \n",
       "tvmgen_default_fused_nn_dense_nn_bias_add_nn_relu            49.04    42.70    cpu0      1  float32[1, 784], float32[128, 784], float32[128], float32[1, 128]  35ac6d50e6e03a62  \n",
       "tvmgen_default_fused_nn_dense_nn_bias_add_nn_relu_1           9.33     8.12    cpu0      1     float32[1, 128], float32[64, 128], float32[64], float32[1, 64]  7c89e1efbba1ce3b  \n",
       "tvmgen_default_fused_nn_dense_nn_bias_add                     5.50     4.79    cpu0      1       float32[1, 64], float32[10, 64], float32[10], float32[1, 10]  8a679957c4723fed  \n",
       "__nop                                                         1.08     0.94    cpu0      1                             float32[1, 1, 28, 28], float32[1, 784]  9efde5b782d81fa1  \n",
       "tvmgen_default_fused_nn_softmax                               0.77     0.67    cpu0      1                                     float32[1, 10], float32[1, 10]  0cc19816e7a3c070  \n",
       "----------                                                                                                                                                                       \n",
       "Sum                                                          65.72    57.23              5                                                                                       \n",
       "Total                                                       114.84             cpu0      1                                                                                       \n",
       "\n",
       "Configuration\n",
       "-------------\n",
       "Number of threads: 24\n",
       "Executor: Graph"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tvm.contrib.debugger import debug_executor\n",
    "\n",
    "mod, params = mlp.get_workload(1)\n",
    "\n",
    "exe = relay.build(mod, target, params=params)\n",
    "gr = debug_executor.create(exe.get_graph_json(), exe.lib, dev)\n",
    "\n",
    "data = np.random.rand(1, 1, 28, 28).astype(\"float32\")\n",
    "report = gr.profile(data=data)\n",
    "assert \"fused_nn_softmax\" in str(report)\n",
    "assert \"Total\" in str(report)\n",
    "assert \"Hash\" in str(report)\n",
    "assert \"Graph\" in str(report)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.runtime.profiling import Report\n",
    "from tvm.script import tir as T\n",
    "\n",
    "@T.prim_func\n",
    "def axpy_cpu(a: T.handle, b: T.handle, c: T.handle) -> None:\n",
    "    A = T.match_buffer(a, [10], \"float64\")\n",
    "    B = T.match_buffer(b, [10], \"float64\")\n",
    "    C = T.match_buffer(c, [10], \"float64\")\n",
    "    for i in range(10):\n",
    "        C[i] = A[i] + B[i]\n",
    "\n",
    "\n",
    "@T.prim_func\n",
    "def axpy_gpu(a: T.handle, b: T.handle, c: T.handle) -> None:\n",
    "    A = T.match_buffer(a, [10], \"float64\")\n",
    "    B = T.match_buffer(b, [10], \"float64\")\n",
    "    C = T.match_buffer(c, [10], \"float64\")\n",
    "    for i in T.thread_binding(0, 10, \"threadIdx.x\"):\n",
    "        C[i] = A[i] + B[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_profile_function(target, dev):\n",
    "    target = tvm.target.Target(target)\n",
    "    if str(target.kind) == \"llvm\":\n",
    "        metric = \"PAPI_FP_OPS\"\n",
    "        func = axpy_cpu\n",
    "    elif str(target.kind) == \"cuda\":\n",
    "        metric = (\n",
    "            \"cuda:::gpu__compute_memory_access_throughput.max.pct_of_peak_sustained_region:device=0\"\n",
    "        )\n",
    "        func = axpy_gpu\n",
    "    else:\n",
    "        pytest.skip(f\"Target {target.kind} not supported by this test\")\n",
    "    f = tvm.build(func, target=target)\n",
    "    a = tvm.nd.array(np.ones(10), device=dev)\n",
    "    b = tvm.nd.array(np.ones(10), device=dev)\n",
    "    c = tvm.nd.array(np.zeros(10), device=dev)\n",
    "    report = tvm.runtime.profiling.profile_function(\n",
    "        f, dev, [tvm.runtime.profiling.PAPIMetricCollector({dev: [metric]})]\n",
    "    )(a, b, c)\n",
    "    assert metric in report.keys()\n",
    "    assert report[metric].value > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2d1ab9d1dc65ef84f368aa5042276df6e59670f363eef0e3da4892909479be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

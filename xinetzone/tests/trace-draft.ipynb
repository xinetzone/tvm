{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 追踪变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import te, relay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(\n",
       "        a: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "        b: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "        c: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "    ):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr(\n",
       "            {\n",
       "                <span style=\"color: #BA2121\">&quot;from_legacy_te_schedule&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>),\n",
       "                <span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>,\n",
       "                <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>),\n",
       "            }\n",
       "        )\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i <span style=\"color: #008000; font-weight: bold\">in</span> range(<span style=\"color: #008000\">128</span>):\n",
       "            c_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), data<span style=\"color: #AA22FF; font-weight: bold\">=</span>c<span style=\"color: #AA22FF; font-weight: bold\">.</span>data)\n",
       "            a_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), data<span style=\"color: #AA22FF; font-weight: bold\">=</span>a<span style=\"color: #AA22FF; font-weight: bold\">.</span>data)\n",
       "            b_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), data<span style=\"color: #AA22FF; font-weight: bold\">=</span>b<span style=\"color: #AA22FF; font-weight: bold\">.</span>data)\n",
       "            c_1[i] <span style=\"color: #AA22FF; font-weight: bold\">=</span> a_1[i] <span style=\"color: #AA22FF; font-weight: bold\">+</span> b_1[i]\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = tvm.tir.const(128, \"int32\")\n",
    "a = te.placeholder((n,), name=\"a\")\n",
    "b = te.placeholder((n,), name=\"b\")\n",
    "c = te.compute((n,), lambda i: a[i] + b[i], name=\"c\")\n",
    "\n",
    "sch = te.create_schedule(c.op)\n",
    "ir = tvm.lower(sch, [a, b, c])\n",
    "ir.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loops = []\n",
    "\n",
    "def find_width8(op):\n",
    "    \"\"\"找出所有范围能被 8 除的 'tir.For' 节点。\"\"\"\n",
    "    if isinstance(op, tvm.tir.For):\n",
    "        if isinstance(op.extent, tvm.tir.IntImm):\n",
    "            if op.extent.value % 8 == 0:\n",
    "                loops.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize8(op):\n",
    "    \"\"\"Split can vectorize the loops found in `find_width8`.\"\"\"\n",
    "    if op in loops:\n",
    "        extent = op.extent.value\n",
    "        name = op.loop_var.name\n",
    "        lo, li = te.var(name + \".outer\"), te.var(name + \".inner\")\n",
    "        body = tvm.tir.stmt_functor.substitute(op.body, {op.loop_var: lo * 8 + li})\n",
    "        body = tvm.tir.For(li, 0, 8, tvm.tir.ForKind.VECTORIZED, body)\n",
    "        body = tvm.tir.For(lo, 0, extent // 8, tvm.tir.ForKind.SERIAL, body)\n",
    "        return body\n",
    "    return None\n",
    "\n",
    "\n",
    "@tvm.tir.transform.prim_func_pass(opt_level=0)\n",
    "def vectorize(f, mod, ctx):\n",
    "    global loops\n",
    "    tvm.tir.stmt_functor.post_order_visit(f.body, find_width8)\n",
    "    if not loops:\n",
    "        return f\n",
    "    # 最后一个 list 参数表示要转换的节点类型。\n",
    "    # 因此，在这种情况下，只有 `For` 节点会调用 `vectorize8`\n",
    "    return f.with_body(tvm.tir.stmt_functor.ir_transform(f.body, None, vectorize8, [\"tir.For\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(\n",
       "        a: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "        b: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "        c: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), <span style=\"color: #BA2121\">&quot;float32&quot;</span>),\n",
       "    ):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr(\n",
       "            {\n",
       "                <span style=\"color: #BA2121\">&quot;from_legacy_te_schedule&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>),\n",
       "                <span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>,\n",
       "                <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>),\n",
       "            }\n",
       "        )\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i_outer <span style=\"color: #008000; font-weight: bold\">in</span> range(<span style=\"color: #008000\">16</span>):\n",
       "            cse_var_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">=</span> i_outer <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">8</span>\n",
       "            c_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), data<span style=\"color: #AA22FF; font-weight: bold\">=</span>c<span style=\"color: #AA22FF; font-weight: bold\">.</span>data)\n",
       "            a_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), data<span style=\"color: #AA22FF; font-weight: bold\">=</span>a<span style=\"color: #AA22FF; font-weight: bold\">.</span>data)\n",
       "            b_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>,), data<span style=\"color: #AA22FF; font-weight: bold\">=</span>b<span style=\"color: #AA22FF; font-weight: bold\">.</span>data)\n",
       "            c_1[cse_var_1 : cse_var_1 <span style=\"color: #AA22FF; font-weight: bold\">+</span> <span style=\"color: #008000\">8</span>] <span style=\"color: #AA22FF; font-weight: bold\">=</span> (\n",
       "                a_1[cse_var_1 : cse_var_1 <span style=\"color: #AA22FF; font-weight: bold\">+</span> <span style=\"color: #008000\">8</span>] <span style=\"color: #AA22FF; font-weight: bold\">+</span> b_1[cse_var_1 : cse_var_1 <span style=\"color: #AA22FF; font-weight: bold\">+</span> <span style=\"color: #008000\">8</span>]\n",
       "            )\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tvm.transform.PassContext(config={\"tir.add_lower_pass\":\n",
    "                                       [(1, vectorize)]}):\n",
    "    tvm.lower(sch, [a, b, c]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example():\n",
    "    shape = (1, 64, 54, 54)\n",
    "    c_data = np.empty(shape).astype(\"float32\")\n",
    "    c = relay.const(c_data)\n",
    "    weight = relay.var(\"weight\", shape=(64, 64, 3, 3))\n",
    "    x = relay.var(\"x\", relay.TensorType((1, 64, 56, 56), \"float32\"))\n",
    "    conv = relay.nn.conv2d(x, weight, kernel_size=(3, 3))\n",
    "    y = relay.add(c, c)\n",
    "    y = relay.multiply(y, relay.const(2, \"float32\"))\n",
    "    y = relay.add(conv, y)\n",
    "    z = relay.add(y, c)\n",
    "    z1 = relay.add(y, c)\n",
    "    z2 = relay.add(z, z1)\n",
    "    return relay.Function([x, weight], z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%x: Tensor[(1, 64, 56, 56), float32], %weight: Tensor[(64, 64, 3, 3), float32]) {\n",
      "  %0 = add(meta[relay.Constant][0], meta[relay.Constant][0]);\n",
      "  %1 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0], kernel_size=[3, 3]);\n",
      "  %2 = multiply(%0, 2f);\n",
      "  %3 = add(%1, %2);\n",
      "  %4 = add(%3, meta[relay.Constant][0]);\n",
      "  %5 = add(%3, meta[relay.Constant][0]);\n",
      "  add(%4, %5)\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = example()\n",
    "mod = tvm.IRModule.from_expr(f)\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
      "  %0 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "  %1 = add(%0, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "  %2 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "  %3 = add(%1, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "  add(%2, %3) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = relay.transform.FoldConstant()\n",
    "mod = transform(mod)\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
      "  %4 = fn (%p0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %p1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %p2: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, %p3: Tensor[(1, 64, 54, 54), float32] /* ty=Tensor[(1, 64, 54, 54), float32] */, Primitive=1) -> Tensor[(1, 64, 54, 54), float32] {\n",
      "    %0 = nn.conv2d(%p0, %p1, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "    %1 = add(%0, %p2) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "    %2 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "    %3 = add(%1, %p3) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "    add(%2, %3) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(1, 64, 54, 54), float32], Tensor[(1, 64, 54, 54), float32]) -> Tensor[(1, 64, 54, 54), float32] */;\n",
      "  %4(%x, %weight, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */, meta[relay.Constant][1] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = example()\n",
    "mod = tvm.IRModule.from_expr(f)\n",
    "# Glob 感兴趣的 passes.\n",
    "seq = tvm.transform.Sequential(\n",
    "    [\n",
    "        relay.transform.FoldConstant(),\n",
    "        relay.transform.EliminateCommonSubexpr(),\n",
    "        relay.transform.FuseOps(fuse_opt_level=2),\n",
    "    ]\n",
    ")\n",
    "mod1 = seq(mod)\n",
    "print(mod1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */) -> Tensor[(1, 64, 54, 54), float32] {\n",
      "  %0 = multiply(3f /* ty=float32 */, meta[relay.Constant][0] /* ty=Tensor[(1, 64, 54, 54), float32] */) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "  %1 = add(%0, %0) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "  %2 = multiply(3f /* ty=float32 */, 2f /* ty=float32 */) /* ty=float32 */;\n",
      "  %3 = nn.conv2d(%x, %weight, padding=[0, 0, 0, 0], kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "  %4 = multiply(%1, %2) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "  %5 = add(%3, %4) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "  %6 = add(%5, %0) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "  %7 = add(%5, %0) /* ty=Tensor[(1, 64, 54, 54), float32] */;\n",
      "  add(%6, %7) /* ty=Tensor[(1, 64, 54, 54), float32] */\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@relay.transform.function_pass(opt_level=1)\n",
    "class CustomPipeline:\n",
    "    \"\"\"Simple test function to replace one argument to another.\"\"\"\n",
    "\n",
    "    def __init__(self, multiplier):\n",
    "        self.multiplier = multiplier\n",
    "\n",
    "    # This function can define a pass.\n",
    "    def transform_function(self, func, mod, ctx):\n",
    "        obj = self\n",
    "\n",
    "        class ReplaceConstant(tvm.relay.ExprMutator):\n",
    "            def visit_constant(self, c):\n",
    "                return relay.multiply(obj.multiplier, c)\n",
    "\n",
    "        return ReplaceConstant().visit(func)\n",
    "\n",
    "\n",
    "f = example()\n",
    "mod = tvm.IRModule.from_expr(f)\n",
    "custom_pass = CustomPipeline(multiplier=relay.const(3, \"float32\"))\n",
    "assert custom_pass.info.name == \"CustomPipeline\"\n",
    "mod3 = custom_pass(mod)\n",
    "print(mod3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

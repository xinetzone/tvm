# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-06-06 09:43+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:20004
msgid "2. microTVM TFLite Tutorial"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:20005
msgid "**Author**: [Tom Gall](https://github.com/tom-gall)"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:20007
msgid ""
"This tutorial is an introduction to working with microTVM and a TFLite "
"model with Relay."
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:30002
msgid "Install microTVM Python dependencies"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:30004
msgid ""
"TVM does not include a package for Python serial communication, so we "
"must install one before using microTVM. We will also need TFLite to load "
"models."
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:60002
msgid "Install Zephyr"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:80002
msgid "Import Python dependencies"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:100002
msgid "Using the buffer, transform into a tflite model python object"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:120002
msgid "Print out the version of the model"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:140002
msgid ""
"Parse the python model object to convert it into a relay module and "
"weights. It is important to note that the input tensor name must match "
"what is contained in the model."
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:140007
msgid ""
"If you are unsure what that might be, this can be discovered by using the"
" ``visualize.py`` script within the Tensorflow project. See [How do I "
"inspect a .tflite file?](https://www.tensorflow.org/lite/guide/faq)"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:160002
msgid "Defining the target"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:160004
msgid ""
"Now we create a build config for relay, turning off two options and then "
"calling relay.build which will result in a C source file for the selected"
" TARGET. When running on a simulated target of the same architecture as "
"the host (where this Python script is executed) choose \"crt\" below for "
"the TARGET, the C Runtime as the RUNTIME and a proper board/VM to run it "
"(Zephyr will create the right QEMU VM based on BOARD. In the example "
"below the x86 arch is selected and a x86 VM is picked up accordingly:"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:180002
msgid ""
"Now, compile the model for the target. If you do not specify Executor, by"
" default it uses GraphExecutor."
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:200002
msgid "Inspecting the compilation output"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:200004
msgid ""
"The compilation process has produced some C code implementing the "
"operators in this graph. We can inspect it by printing the CSourceModule "
"contents (for the purposes of this tutorial, let's just print the first "
"10 lines):"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:220002
msgid "Compiling the generated code"
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:220004
msgid ""
"Now we need to incorporate the generated C code into a project that "
"allows us to run inference on the device. The simplest way to do this is "
"to integrate it yourself, using microTVM's standard output format model "
"library format. This is a tarball with a standard layout."
msgstr ""

#: ../../xin/docs/how_to/work_with_microtvm/micro_tflite.ipynb:240002
msgid ""
"Next, establish a session with the simulated device and run the "
"computation. The `with session` line would typically flash an attached "
"microcontroller, but in this tutorial, it simply launches a subprocess to"
" stand in for an attached microcontroller."
msgstr ""

#~ msgid ""
#~ "Click :ref:`here "
#~ "<sphx_glr_download_how_to_work_with_microtvm_micro_tflite.py>` "
#~ "to download the full example code"
#~ msgstr ""

#~ msgid ""
#~ "If you want to run this tutorial"
#~ " on the microTVM Reference VM, "
#~ "download the Jupyter notebook using the"
#~ " link at the bottom of this "
#~ "page and save it into the TVM "
#~ "directory. Then:"
#~ msgstr ""

#~ msgid "Login to the reference VM with a modified ``vagrant ssh`` command:"
#~ msgstr ""

#~ msgid "``$ vagrant ssh -- -L8888:localhost:8888``"
#~ msgstr ""

#~ msgid "Install jupyter:  ``pip install jupyterlab``"
#~ msgstr ""

#~ msgid "``cd`` to the TVM directory."
#~ msgstr ""

#~ msgid "Install tflite: poetry install -E importer-tflite"
#~ msgstr ""

#~ msgid "Launch Jupyter Notebook: ``jupyter notebook``"
#~ msgstr ""

#~ msgid "Copy the localhost URL displayed, and paste it into your browser."
#~ msgstr ""

#~ msgid "Navigate to saved Jupyter Notebook (``.ipynb`` file)."
#~ msgstr ""

#~ msgid "Install TFLite"
#~ msgstr ""

#~ msgid ""
#~ "Get the flatc compiler. Please refer "
#~ "to https://github.com/google/flatbuffers for details"
#~ " and make sure it is properly "
#~ "installed."
#~ msgstr ""

#~ msgid "Install Zephyr (physical hardware only)"
#~ msgstr ""

#~ msgid "Aside: Recreating your own Pre-Trained TFLite model"
#~ msgstr ""

#~ msgid ""
#~ "The tutorial downloads a pretrained "
#~ "TFLite model. When working with "
#~ "microcontrollers you need to be mindful"
#~ " these are highly resource constrained "
#~ "devices as such standard models like "
#~ "MobileNet may not fit into their "
#~ "modest memory."
#~ msgstr ""

#~ msgid ""
#~ "If you wish to replicate the "
#~ "training steps see: "
#~ "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world/train"
#~ msgstr ""

#~ msgid "If you accidentally download the example pretrained model from:"
#~ msgstr ""

#~ msgid ""
#~ "``wget "
#~ "https://storage.googleapis.com/download.tensorflow.org/models/tflite/micro/hello_world_2020_04_13.zip``"
#~ msgstr ""

#~ msgid "this will fail due to an unimplemented opcode (114)"
#~ msgstr ""

#~ msgid ""
#~ ":download:`Download Python source code: "
#~ "micro_tflite.py <micro_tflite.py>`"
#~ msgstr ""

#~ msgid ""
#~ ":download:`Download Jupyter notebook: "
#~ "micro_tflite.ipynb <micro_tflite.ipynb>`"
#~ msgstr ""

#~ msgid ""
#~ "`Gallery generated by Sphinx-Gallery "
#~ "<https://sphinx-gallery.github.io>`_"
#~ msgstr ""

#~ msgid "microTVM with TFLite Models"
#~ msgstr ""

#~ msgid "**Author**: `Tom Gall <https://github.com/tom-gall>`_"
#~ msgstr ""

#~ msgid "Setup"
#~ msgstr ""

#~ msgid "Install TFLite ^^^^^^^^^^^^^^"
#~ msgstr ""

#~ msgid ""
#~ "To get started, TFLite package needs "
#~ "to be installed as prerequisite. You "
#~ "can do this in two ways:"
#~ msgstr ""

#~ msgid "Install tflite with ``pip``"
#~ msgstr ""

#~ msgid ".. code-block:: bash"
#~ msgstr ""

#~ msgid "pip install tflite=2.1.0 --user"
#~ msgstr ""

#~ msgid "Generate the TFLite package yourself. The steps are the following:"
#~ msgstr ""

#~ msgid ""
#~ "Get the flatc compiler.  Please refer"
#~ " to https://github.com/google/flatbuffers for "
#~ "details  and make sure it is "
#~ "properly installed."
#~ msgstr ""

#~ msgid "flatc --version"
#~ msgstr ""

#~ msgid "Get the TFLite schema."
#~ msgstr ""

#~ msgid ""
#~ "wget "
#~ "https://raw.githubusercontent.com/tensorflow/tensorflow/r1.13/tensorflow/lite/schema/schema.fbs"
#~ msgstr ""

#~ msgid "Generate TFLite package."
#~ msgstr ""

#~ msgid "flatc --python schema.fbs"
#~ msgstr ""

#~ msgid ""
#~ "Add the current folder (which contains"
#~ " generated tflite module) to PYTHONPATH."
#~ msgstr ""

#~ msgid "export PYTHONPATH=${PYTHONPATH:+$PYTHONPATH:}$(pwd)"
#~ msgstr ""

#~ msgid ""
#~ "To validate that the TFLite package "
#~ "was installed successfully, ``python -c "
#~ "\"import tflite\"``"
#~ msgstr ""

#~ msgid ""
#~ "Install Zephyr (physical hardware only) "
#~ "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
#~ msgstr ""

#~ msgid ""
#~ "When running this tutorial with a "
#~ "host simulation (the default), you can"
#~ " use the host ``gcc`` to build "
#~ "a firmware image that simulates the "
#~ "device. When compiling to run on "
#~ "physical hardware, you need to install"
#~ " a *toolchain* plus some target-"
#~ "specific dependencies. microTVM allows you "
#~ "to supply any compiler and runtime "
#~ "that can launch the TVM RPC "
#~ "server, but to get started, this "
#~ "tutorial relies on the Zephyr RTOS "
#~ "to provide these pieces."
#~ msgstr ""

#~ msgid ""
#~ "You can install Zephyr by following "
#~ "the `Installation Instructions "
#~ "<https://docs.zephyrproject.org/latest/getting_started/index.html>`_."
#~ msgstr ""

#~ msgid ""
#~ "Aside: Recreating your own Pre-Trained"
#~ " TFLite model  The tutorial downloads "
#~ "a pretrained TFLite model. When working"
#~ " with microcontrollers  you need to "
#~ "be mindful these are highly resource "
#~ "constrained devices as such standard  "
#~ "models like MobileNet may not fit "
#~ "into their modest memory."
#~ msgstr ""

#~ msgid ""
#~ "For this tutorial, we'll make use "
#~ "of one of the TF Micro example "
#~ "models."
#~ msgstr ""

#~ msgid ""
#~ "If you wish to replicate the "
#~ "training steps see:  "
#~ "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world/train"
#~ msgstr ""

#~ msgid ".. note::"
#~ msgstr ""

#~ msgid "Load and prepare the Pre-Trained Model"
#~ msgstr ""

#~ msgid ""
#~ "Load the pretrained TFLite model from"
#~ " a file in your current directory "
#~ "into a buffer"
#~ msgstr ""

#~ msgid ""
#~ "If you are unsure what that might"
#~ " be, this can be discovered by "
#~ "using the ``visualize.py`` script within "
#~ "the Tensorflow project. See `How do "
#~ "I inspect a .tflite file? "
#~ "<https://www.tensorflow.org/lite/guide/faq>`_"
#~ msgstr ""

#~ msgid ""
#~ "Now we create a build config for"
#~ " relay, turning off two options and"
#~ " then calling relay.build which will "
#~ "result in a C source file for "
#~ "the selected TARGET. When running on "
#~ "a simulated target of the same "
#~ "architecture as the host (where this "
#~ "Python script is executed) choose "
#~ "\"host\" below for the TARGET, the "
#~ "C Runtime as the RUNTIME and a "
#~ "proper board/VM to run it (Zephyr "
#~ "will create the right QEMU VM "
#~ "based on BOARD. In the example "
#~ "below the x86 arch is selected and"
#~ " a x86 VM is picked up "
#~ "accordingly:"
#~ msgstr ""

#~ msgid "Now, compile the model for the target:"
#~ msgstr ""


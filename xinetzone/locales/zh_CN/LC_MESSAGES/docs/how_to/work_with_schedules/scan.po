# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-05-05 16:40+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:10002
msgid "扫描和循环 Kernel"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:10004
msgid "**原作者**: [Tianqi Chen](https://tqchen.github.io)"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:10006
msgid "这是关于如何在 TVM 中进行循环计算的介绍材料。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:10008
msgid "循环计算是神经网络中的一种典型模式。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:30002
msgid "TVM 支持 `scan` 算子来描述符号循环。 下面的 `scan` op 计算 X 列的 cumsum。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:30005
msgid ""
"scan 在张量的最高维度上进行。`s_state` 是一个占位符，描述 scan 的变换状态。`s_init` 描述了如何初始化前 k "
"个时间步（timestep）。这里由于 `s_init` 的第一个维度是 1，它描述了如何在第一个时间步初始化状态。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:30007
msgid ""
"`s_update` 描述了如何在时间步骤 t 更新值。值可以通过状态占位符引用回前一个时间步的值。注意，在当前或后续的时间步引用 "
"`s_state` 是无效的。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:30009
msgid ""
"扫描包含状态占位符、初始值和更新描述。还建议（尽管不是必需的）列出 scan cell 的输入。 扫描的结果是张量，在时域更新后给出 "
"`s_state` 的结果。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:50002
msgid "调度 Scan Cell"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:50004
msgid ""
"可以通过分别调度更新和初始化部分来调度扫描主体（body）。注意，调度更新部分的第一个迭代维度是无效的。要在时间迭代上进行分割，用户可以使用 "
"`scan_op.scan_axis` 代替。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:70002
msgid "构建并验证"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:70004
msgid "可以像其他 TVM 内核一样构建扫描内核，这里使用 numpy 来验证结果的正确性。"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:90002
msgid "Multi-Stage Scan Cell"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:90003
msgid ""
"In the above example we described the scan cell using one Tensor "
"computation stage in s_update. It is possible to use multiple Tensor "
"stages in the scan cell."
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:90007
msgid ""
"The following lines demonstrate a scan with two stage operations in the "
"scan cell."
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:110002
msgid ""
"These intermediate tensors can also be scheduled normally. To ensure "
"correctness, TVM creates a group constraint to forbid the body of scan to"
" be compute_at locations outside the scan loop."
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:130002
msgid "Multiple States"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:130003
msgid ""
"For complicated applications like RNN, we might need more than one "
"recurrent state. Scan support multiple recurrent states. The following "
"example demonstrates how we can build recurrence with two states."
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:150002
msgid "Summary"
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:150003
msgid "This tutorial provides a walk through of scan primitive."
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:150005
msgid "Describe scan with init and update."
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:150006
msgid "Schedule the scan cells as normal schedule."
msgstr ""

#: ../../xin/docs/how_to/work_with_schedules/scan.ipynb:150007
msgid "For complicated workload, use multiple states and steps in scan cell."
msgstr ""

#~ msgid ":download:`Download Python source code: scan.py <scan.py>`"
#~ msgstr ""

#~ msgid ":download:`Download Jupyter notebook: scan.ipynb <scan.ipynb>`"
#~ msgstr ""

#~ msgid ""
#~ "`Gallery generated by Sphinx-Gallery "
#~ "<https://sphinx-gallery.github.io>`_"
#~ msgstr ""

#~ msgid ""
#~ "Click :ref:`here "
#~ "<sphx_glr_download_how_to_work_with_schedules_scan.py>` to "
#~ "download the full example code"
#~ msgstr ""

#~ msgid "**Author**: `Tianqi Chen <https://tqchen.github.io>`_"
#~ msgstr ""

#~ msgid ""
#~ "We can schedule the body of the"
#~ " scan by scheduling the update and"
#~ " init part seperately. Note that it"
#~ " is invalid to schedule the first "
#~ "iteration dimension of the update part."
#~ " To split on the time iteration, "
#~ "user can schedule on scan_op.scan_axis "
#~ "instead."
#~ msgstr ""

#~ msgid "Scan and Recurrent Kernel"
#~ msgstr ""

#~ msgid "**Author**: [Tianqi Chen](https://tqchen.github.io)"
#~ msgstr ""

#~ msgid ""
#~ "This is an introduction material on "
#~ "how to do recurrent computing in "
#~ "TVM. Recurrent computing is a typical"
#~ " pattern in neural networks."
#~ msgstr ""

#~ msgid ""
#~ "TVM supports a scan operator to "
#~ "describe symbolic loop. The following "
#~ "scan op computes cumsum over columns "
#~ "of X."
#~ msgstr ""

#~ msgid ""
#~ "The scan is carried over the "
#~ "highest dimension of the tensor. "
#~ ":code:`s_state` is a placeholder that "
#~ "describes the transition state of the"
#~ " scan. :code:`s_init` describes how we "
#~ "can initialize the first k timesteps."
#~ " Here since s_init's first dimension "
#~ "is 1, it describes how we "
#~ "initialize The state at first timestep."
#~ msgstr ""

#~ msgid ""
#~ ":code:`s_update` describes how to update "
#~ "the value at timestep t. The "
#~ "update value can refer back to the"
#~ " values of previous timestep via "
#~ "state placeholder. Note that while it"
#~ " is invalid to refer to "
#~ ":code:`s_state` at current or later "
#~ "timestep."
#~ msgstr ""

#~ msgid ""
#~ "The scan takes in state placeholder, "
#~ "initial value and update description. It"
#~ " is also recommended(although not "
#~ "necessary) to list the inputs to "
#~ "the scan cell. The result of the"
#~ " scan is a tensor, giving the "
#~ "result of :code:`s_state` after the "
#~ "update over the time domain."
#~ msgstr ""

#~ msgid "Schedule the Scan Cell"
#~ msgstr ""

#~ msgid ""
#~ "We can schedule the body of the"
#~ " scan by scheduling the update and"
#~ " init part separately. Note that it"
#~ " is invalid to schedule the first "
#~ "iteration dimension of the update part."
#~ " To split on the time iteration, "
#~ "user can schedule on scan_op.scan_axis "
#~ "instead."
#~ msgstr ""

#~ msgid "Build and Verify"
#~ msgstr ""

#~ msgid ""
#~ "We can build the scan kernel like"
#~ " other TVM kernels, here we use "
#~ "numpy to verify the correctness of "
#~ "the result."
#~ msgstr ""


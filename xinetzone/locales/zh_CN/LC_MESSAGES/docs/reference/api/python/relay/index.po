# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-11-17 09:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../notebook/docs/reference/api/python/relay/index.rst:19
msgid "tvm.relay"
msgstr ""

#~ msgid ":py:obj:`Pattern <tvm.relay.Pattern>`\\ \\(\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`sliding_window <tvm.relay.sliding_window>`\\ "
#~ "\\(data\\, axis\\, window\\_shape\\, strides\\)"
#~ msgstr ""

#~ msgid "Slide a window over the data tensor."
#~ msgstr ""

#~ msgid ""
#~ "What axis the window begins sliding "
#~ "over. Window will be slid over "
#~ "this axis and all following axes. "
#~ "The axis value determines the window "
#~ "shape (and thus, the number of "
#~ "strides): window shape and strides must"
#~ " both be of length `data.ndim-axis`."
#~ msgstr ""

#~ msgid ""
#~ "The window shape to form over the"
#~ " input. Window shape must be of "
#~ "length `data.ndim-axis`."
#~ msgstr ""

#~ msgid ""
#~ "How to stride the window along "
#~ "each dimension. Strides must be of "
#~ "length `data.ndim-axis`."
#~ msgstr ""

#~ msgid ":py:obj:`Pattern <tvm.relay.Pattern>`\\"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`TupleGetItem <tvm.relay.TupleGetItem>`\\ "
#~ "\\(tuple\\_value\\, index\\[\\, span\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`mean_variance <tvm.relay.mean_variance>`\\ "
#~ "\\(data\\[\\, axis\\, keepdims\\, exclude\\]\\)"
#~ msgstr ""

#~ msgid "The Relay IR namespace containing the IR definition and compiler."
#~ msgstr ""

#~ msgid "**Classes:**"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`Call <tvm.relay.Call>`\\ \\(op\\, "
#~ "args\\[\\, attrs\\, type\\_args\\, span\\]\\)"
#~ msgstr ""

#~ msgid "Function call node in Relay."
#~ msgstr ""

#~ msgid ":py:obj:`Clause <tvm.relay.Clause>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Clause for pattern matching in Relay."
#~ msgstr ""

#~ msgid ":py:obj:`Constant <tvm.relay.Constant>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "A constant expression in Relay."
#~ msgstr ""

#~ msgid ":py:obj:`Expr <tvm.relay.Expr>`\\"
#~ msgstr ""

#~ msgid "alias of :py:class:`tvm.ir.expr.RelayExpr`"
#~ msgstr ""

#~ msgid ":py:obj:`ExprFunctor <tvm.relay.ExprFunctor>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "An abstract visitor defined over Expr."
#~ msgstr ""

#~ msgid ":py:obj:`ExprMutator <tvm.relay.ExprMutator>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "A functional visitor over Expr."
#~ msgstr ""

#~ msgid ":py:obj:`ExprVisitor <tvm.relay.ExprVisitor>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "A visitor over Expr."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`Function <tvm.relay.Function>`\\ \\(params\\, "
#~ "body\\[\\, ret\\_type\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "A function declaration expression."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`If <tvm.relay.If>`\\ \\(cond\\, "
#~ "true\\_branch\\, false\\_branch\\)"
#~ msgstr ""

#~ msgid "A conditional expression in Relay."
#~ msgstr ""

#~ msgid ":py:obj:`Let <tvm.relay.Let>`\\ \\(variable\\, value\\, body\\)"
#~ msgstr ""

#~ msgid "Let variable binding expression."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`Match <tvm.relay.Match>`\\ \\(data\\, "
#~ "clauses\\[\\, complete\\]\\)"
#~ msgstr ""

#~ msgid "Pattern matching expression in Relay."
#~ msgstr ""

#~ msgid "Base type for pattern matching constructs."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`PatternConstructor <tvm.relay.PatternConstructor>`\\"
#~ " \\(constructor\\[\\, patterns\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Constructor pattern in Relay: Matches an"
#~ " ADT of the given constructor, binds"
#~ " recursively."
#~ msgstr ""

#~ msgid ":py:obj:`PatternTuple <tvm.relay.PatternTuple>`\\ \\(\\[patterns\\]\\)"
#~ msgstr ""

#~ msgid "Constructor pattern in Relay: Matches a tuple, binds recursively."
#~ msgstr ""

#~ msgid ":py:obj:`PatternVar <tvm.relay.PatternVar>`\\ \\(var\\)"
#~ msgstr ""

#~ msgid ""
#~ "Variable pattern in Relay: Matches "
#~ "anything and binds it to the "
#~ "variable."
#~ msgstr ""

#~ msgid ":py:obj:`PatternWildcard <tvm.relay.PatternWildcard>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Wildcard pattern in Relay: Matches any ADT and binds nothing."
#~ msgstr ""

#~ msgid ":py:obj:`Prelude <tvm.relay.Prelude>`\\ \\(\\[mod\\]\\)"
#~ msgstr ""

#~ msgid "Contains standard definitions."
#~ msgstr ""

#~ msgid ":py:obj:`RefCreate <tvm.relay.RefCreate>`\\ \\(value\\)"
#~ msgstr ""

#~ msgid "Create a new reference from initial value."
#~ msgstr ""

#~ msgid ":py:obj:`RefRead <tvm.relay.RefRead>`\\ \\(ref\\)"
#~ msgstr ""

#~ msgid "Get the value inside the reference."
#~ msgstr ""

#~ msgid ":py:obj:`RefType <tvm.relay.RefType>`\\"
#~ msgstr ""

#~ msgid "alias of :py:class:`tvm.ir.type.RelayRefType`"
#~ msgstr ""

#~ msgid ":py:obj:`RefWrite <tvm.relay.RefWrite>`\\ \\(ref\\, value\\)"
#~ msgstr ""

#~ msgid "Update the value inside the reference."
#~ msgstr ""

#~ msgid ":py:obj:`ScopeBuilder <tvm.relay.ScopeBuilder>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Scope builder class."
#~ msgstr ""

#~ msgid ":py:obj:`Tuple <tvm.relay.Tuple>`\\ \\(fields\\[\\, span\\]\\)"
#~ msgstr ""

#~ msgid "Tuple expression that groups several fields together."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`TupleGetItem <tvm.relay.TupleGetItem>`\\ "
#~ "\\(tuple\\_value\\, index\\)"
#~ msgstr ""

#~ msgid "Get index-th item from a tuple."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`TupleWrapper <tvm.relay.TupleWrapper>`\\ "
#~ "\\(tuple\\_value\\, size\\)"
#~ msgstr ""

#~ msgid "TupleWrapper."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`TypeData <tvm.relay.TypeData>`\\ \\(header\\, "
#~ "type\\_vars\\, constructors\\)"
#~ msgstr ""

#~ msgid "Stores the definition for an Algebraic Data Type (ADT) in Relay."
#~ msgstr ""

#~ msgid ":py:obj:`TypeFunctor <tvm.relay.TypeFunctor>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "An abstract visitor defined over Type."
#~ msgstr ""

#~ msgid ":py:obj:`TypeMutator <tvm.relay.TypeMutator>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "A functional visitor over Type."
#~ msgstr ""

#~ msgid ":py:obj:`TypeVisitor <tvm.relay.TypeVisitor>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "A visitor over Type."
#~ msgstr ""

#~ msgid "**Functions:**"
#~ msgstr ""

#~ msgid ":py:obj:`ShapeVar <tvm.relay.ShapeVar>`\\ \\(name\\)"
#~ msgstr ""

#~ msgid "A helper which constructs a type var of which the shape kind."
#~ msgstr ""

#~ msgid ":py:obj:`abs <tvm.relay.abs>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute element-wise absolute of data."
#~ msgstr ""

#~ msgid ":py:obj:`acos <tvm.relay.acos>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise acos of data."
#~ msgstr ""

#~ msgid ":py:obj:`acosh <tvm.relay.acosh>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise acosh of data."
#~ msgstr ""

#~ msgid ":py:obj:`add <tvm.relay.add>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Addition with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`adv_index <tvm.relay.adv_index>`\\ \\(inputs\\)"
#~ msgstr ""

#~ msgid "Numpy style advanced indexing."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`all <tvm.relay.all>`\\ \\(data\\[\\, "
#~ "axis\\, keepdims\\, exclude\\]\\)"
#~ msgstr ""

#~ msgid "Computes the logical AND of boolean array elements over given axes."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`any <tvm.relay.any>`\\ \\(data\\[\\, "
#~ "axis\\, keepdims\\, exclude\\]\\)"
#~ msgstr ""

#~ msgid "Computes the logical OR of boolean array elements over given axes."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`arange <tvm.relay.arange>`\\ \\(start\\[\\, "
#~ "stop\\, step\\, dtype\\]\\)"
#~ msgstr ""

#~ msgid "Return evenly spaced values within a given interval."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`argmax <tvm.relay.argmax>`\\ \\(data\\[\\, "
#~ "axis\\, keepdims\\, exclude\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Returns the indices of the maximum values along an axis."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`argmin <tvm.relay.argmin>`\\ \\(data\\[\\, "
#~ "axis\\, keepdims\\, exclude\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Returns the indices of the minimum values along an axis."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`argsort <tvm.relay.argsort>`\\ \\(data\\[\\, "
#~ "axis\\, is\\_ascend\\, dtype\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Performs sorting along the given axis"
#~ " and returns an array of indicies "
#~ "having same shape as an input "
#~ "array that index data in sorted "
#~ "order."
#~ msgstr ""

#~ msgid ":py:obj:`argwhere <tvm.relay.argwhere>`\\ \\(condition\\)"
#~ msgstr ""

#~ msgid "Find the indices of elements of a tensor that are non-zero."
#~ msgstr ""

#~ msgid ":py:obj:`asin <tvm.relay.asin>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise asin of data."
#~ msgstr ""

#~ msgid ":py:obj:`asinh <tvm.relay.asinh>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise asinh of data."
#~ msgstr ""

#~ msgid ":py:obj:`atan <tvm.relay.atan>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise atan of data."
#~ msgstr ""

#~ msgid ":py:obj:`atanh <tvm.relay.atanh>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise atanh of data."
#~ msgstr ""

#~ msgid ":py:obj:`bind <tvm.relay.bind>`\\ \\(expr\\, binds\\)"
#~ msgstr ""

#~ msgid "Bind an free variables in expr or function arguments."
#~ msgstr ""

#~ msgid ":py:obj:`bitwise_and <tvm.relay.bitwise_and>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "bitwise AND with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`bitwise_not <tvm.relay.bitwise_not>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute element-wise bitwise not of data."
#~ msgstr ""

#~ msgid ":py:obj:`bitwise_or <tvm.relay.bitwise_or>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "bitwise OR with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`bitwise_xor <tvm.relay.bitwise_xor>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "bitwise XOR with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`broadcast_to <tvm.relay.broadcast_to>`\\ \\(data\\, shape\\)"
#~ msgstr ""

#~ msgid ""
#~ "Return a scalar value array with "
#~ "the same type, broadcast to the "
#~ "provided shape."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`broadcast_to_like <tvm.relay.broadcast_to_like>`\\ "
#~ "\\(data\\, broadcast\\_type\\)"
#~ msgstr ""

#~ msgid ""
#~ "Return a scalar value array with "
#~ "the same shape and type as the "
#~ "input array."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`build <tvm.relay.build>`\\ \\(ir\\_mod\\[\\, "
#~ "target\\, target\\_host\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Helper function that builds a Relay "
#~ "function to run on TVM graph "
#~ "executor."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`build_config <tvm.relay.build_config>`\\ "
#~ "\\(\\[opt\\_level\\, required\\_pass\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Configure the build behavior by setting config variables."
#~ msgstr ""

#~ msgid ":py:obj:`cast <tvm.relay.cast>`\\ \\(data\\, dtype\\)"
#~ msgstr ""

#~ msgid "Cast input tensor to data type."
#~ msgstr ""

#~ msgid ":py:obj:`cast_like <tvm.relay.cast_like>`\\ \\(data\\, dtype\\_like\\)"
#~ msgstr ""

#~ msgid "Cast input tensor to data type of another tensor."
#~ msgstr ""

#~ msgid ":py:obj:`ceil <tvm.relay.ceil>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute element-wise ceil of data."
#~ msgstr ""

#~ msgid ":py:obj:`clip <tvm.relay.clip>`\\ \\(a\\, a\\_min\\, a\\_max\\)"
#~ msgstr ""

#~ msgid "Clip the elements in `a` between `a_min` and `a_max`."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`collapse_sum_like <tvm.relay.collapse_sum_like>`\\ "
#~ "\\(data\\, collapse\\_type\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`collapse_sum_to <tvm.relay.collapse_sum_to>`\\ "
#~ "\\(data\\, shape\\)"
#~ msgstr ""

#~ msgid "Return a summation of data to the specified shape."
#~ msgstr ""

#~ msgid ":py:obj:`concatenate <tvm.relay.concatenate>`\\ \\(data\\, axis\\)"
#~ msgstr ""

#~ msgid "Concatenate the input tensors along the given axis."
#~ msgstr ""

#~ msgid ":py:obj:`const <tvm.relay.const>`\\ \\(value\\[\\, dtype\\]\\)"
#~ msgstr ""

#~ msgid "Create a constant value."
#~ msgstr ""

#~ msgid ":py:obj:`copy <tvm.relay.copy>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Copy a tensor."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`copy_shape_func <tvm.relay.copy_shape_func>`\\ "
#~ "\\(attrs\\, inputs\\, \\_\\)"
#~ msgstr ""

#~ msgid "Shape function for copy op."
#~ msgstr ""

#~ msgid ":py:obj:`cos <tvm.relay.cos>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise cos of data."
#~ msgstr ""

#~ msgid ":py:obj:`cosh <tvm.relay.cosh>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise cosh of data."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`create_executor <tvm.relay.create_executor>`\\ "
#~ "\\(\\[kind\\, mod\\, device\\, target\\, "
#~ "...\\]\\)"
#~ msgstr ""

#~ msgid "Factory function to create an executor."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`cumprod <tvm.relay.cumprod>`\\ \\(data\\[\\, "
#~ "axis\\, dtype\\, exclusive\\]\\)"
#~ msgstr ""

#~ msgid "Numpy style cumprod op."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`cumsum <tvm.relay.cumsum>`\\ \\(data\\[\\, "
#~ "axis\\, dtype\\, exclusive\\]\\)"
#~ msgstr ""

#~ msgid "Numpy style cumsum op."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`device_copy <tvm.relay.device_copy>`\\ \\(data\\,"
#~ " src\\_device\\, dst\\_device\\)"
#~ msgstr ""

#~ msgid "Copy data from the source device to the destination device."
#~ msgstr ""

#~ msgid ":py:obj:`divide <tvm.relay.divide>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Division with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`einsum <tvm.relay.einsum>`\\ \\(data\\, equation\\)"
#~ msgstr ""

#~ msgid "Evaluates the Einstein summation convention on data"
#~ msgstr ""

#~ msgid ":py:obj:`equal <tvm.relay.equal>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Broadcasted elementwise test for (lhs == rhs)."
#~ msgstr ""

#~ msgid ":py:obj:`erf <tvm.relay.erf>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise error function of data."
#~ msgstr ""

#~ msgid ":py:obj:`exp <tvm.relay.exp>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise exp of data."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`expand_dims <tvm.relay.expand_dims>`\\ \\(data\\,"
#~ " axis\\[\\, num\\_newaxis\\]\\)"
#~ msgstr ""

#~ msgid "Insert `num_newaxis` axes at the position given by `axis`."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`fixed_point_multiply "
#~ "<tvm.relay.fixed_point_multiply>`\\ \\(data\\, "
#~ "multiplier\\, shift\\)"
#~ msgstr ""

#~ msgid ""
#~ "Fixed point multiplication between data "
#~ "and a fixed point constant expressed "
#~ "as multiplier * 2^(-shift), where "
#~ "multiplier is a Q-number with 31 "
#~ "fractional bits"
#~ msgstr ""

#~ msgid ":py:obj:`floor <tvm.relay.floor>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute element-wise floor of data."
#~ msgstr ""

#~ msgid ":py:obj:`floor_divide <tvm.relay.floor_divide>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Floor division with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`floor_mod <tvm.relay.floor_mod>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Floor mod with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`full <tvm.relay.full>`\\ \\(fill\\_value\\[\\,"
#~ " shape\\, dtype\\]\\)"
#~ msgstr ""

#~ msgid "Fill array with scalar value."
#~ msgstr ""

#~ msgid ":py:obj:`full_like <tvm.relay.full_like>`\\ \\(data\\, fill\\_value\\)"
#~ msgstr ""

#~ msgid ":py:obj:`gather <tvm.relay.gather>`\\ \\(data\\, axis\\, indices\\)"
#~ msgstr ""

#~ msgid "Gather values along given axis from given indices."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`gather_nd <tvm.relay.gather_nd>`\\ \\(data\\, "
#~ "indices\\[\\, batch\\_dims\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Gather elements or slices from data "
#~ "and store to a tensor whose shape"
#~ " is defined by indices."
#~ msgstr ""

#~ msgid ":py:obj:`greater <tvm.relay.greater>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Broadcasted elementwise test for (lhs > rhs)."
#~ msgstr ""

#~ msgid ":py:obj:`greater_equal <tvm.relay.greater_equal>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Broadcasted elementwise test for (lhs >= rhs)."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`invert_permutation <tvm.relay.invert_permutation>`\\"
#~ " \\(data\\)"
#~ msgstr ""

#~ msgid "Computes the inverse permutation of data."
#~ msgstr ""

#~ msgid ":py:obj:`isfinite <tvm.relay.isfinite>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute element-wise finiteness of data."
#~ msgstr ""

#~ msgid ":py:obj:`isinf <tvm.relay.isinf>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute element-wise infiniteness of data."
#~ msgstr ""

#~ msgid ":py:obj:`isnan <tvm.relay.isnan>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Check nan in input data element-wise."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`layout_transform <tvm.relay.layout_transform>`\\ "
#~ "\\(data\\, src\\_layout\\, dst\\_layout\\)"
#~ msgstr ""

#~ msgid "Transform the layout of a tensor"
#~ msgstr ""

#~ msgid ":py:obj:`left_shift <tvm.relay.left_shift>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Left shift with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`less <tvm.relay.less>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Broadcasted elementwise test for (lhs < rhs)."
#~ msgstr ""

#~ msgid ":py:obj:`less_equal <tvm.relay.less_equal>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Broadcasted elementwise test for (lhs <= rhs)."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`load_param_dict <tvm.relay.load_param_dict>`\\ "
#~ "\\(param\\_bytes\\)"
#~ msgstr ""

#~ msgid "Load parameter dictionary to binary bytes."
#~ msgstr ""

#~ msgid ":py:obj:`log <tvm.relay.log>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise log of data."
#~ msgstr ""

#~ msgid ":py:obj:`log10 <tvm.relay.log10>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise log to the base 10 of data."
#~ msgstr ""

#~ msgid ":py:obj:`log2 <tvm.relay.log2>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise log to the base 2 of data."
#~ msgstr ""

#~ msgid ":py:obj:`logical_and <tvm.relay.logical_and>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "logical AND with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`logical_not <tvm.relay.logical_not>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute element-wise logical not of data."
#~ msgstr ""

#~ msgid ":py:obj:`logical_or <tvm.relay.logical_or>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "logical OR with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`logical_xor <tvm.relay.logical_xor>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "logical XOR with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`logsumexp <tvm.relay.logsumexp>`\\ \\(data\\[\\,"
#~ " axis\\, keepdims\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Compute the log of the sum of "
#~ "exponentials of input elements over "
#~ "given axes."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`matrix_set_diag <tvm.relay.matrix_set_diag>`\\ "
#~ "\\(data\\, diagonal\\[\\, k\\, align\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Returns a tensor with the diagonals "
#~ "of input tensor replaced with the "
#~ "provided diagonal values."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`max <tvm.relay.max>`\\ \\(data\\[\\, "
#~ "axis\\, keepdims\\, exclude\\]\\)"
#~ msgstr ""

#~ msgid "Computes the max of array elements over given axes."
#~ msgstr ""

#~ msgid ":py:obj:`maximum <tvm.relay.maximum>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Maximum with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`mean <tvm.relay.mean>`\\ \\(data\\[\\, "
#~ "axis\\, keepdims\\, exclude\\]\\)"
#~ msgstr ""

#~ msgid "Computes the mean of array elements over given axes."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`mean_std <tvm.relay.mean_std>`\\ \\(data\\[\\,"
#~ " axis\\, keepdims\\, exclude\\]\\)"
#~ msgstr ""

#~ msgid "Computes the mean and standard deviation of data over given axes."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`mean_variance <tvm.relay.mean_variance>`\\ "
#~ "\\(data\\[\\, axis\\, keepdims\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Computes the mean and variance of data over given axes."
#~ msgstr ""

#~ msgid ":py:obj:`meshgrid <tvm.relay.meshgrid>`\\ \\(data\\[\\, indexing\\]\\)"
#~ msgstr ""

#~ msgid "Create coordinate matrices from coordinate vectors."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`min <tvm.relay.min>`\\ \\(data\\[\\, "
#~ "axis\\, keepdims\\, exclude\\]\\)"
#~ msgstr ""

#~ msgid "Computes the min of array elements over given axes."
#~ msgstr ""

#~ msgid ":py:obj:`minimum <tvm.relay.minimum>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Minimum with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`mod <tvm.relay.mod>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Mod with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`multiply <tvm.relay.multiply>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Multiplication with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`ndarray_size <tvm.relay.ndarray_size>`\\ "
#~ "\\(data\\[\\, dtype\\]\\)"
#~ msgstr ""

#~ msgid "Get number of elements of input tensor."
#~ msgstr ""

#~ msgid ":py:obj:`negative <tvm.relay.negative>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute element-wise negative of data."
#~ msgstr ""

#~ msgid ":py:obj:`not_equal <tvm.relay.not_equal>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Broadcasted elementwise test for (lhs != rhs)."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`one_hot <tvm.relay.one_hot>`\\ \\(indices\\, "
#~ "on\\_value\\, off\\_value\\, depth\\, ...\\)"
#~ msgstr ""

#~ msgid ""
#~ "Returns a one-hot tensor where the"
#~ " locations repsented by indices take "
#~ "value on_value, other locations take "
#~ "value off_value."
#~ msgstr ""

#~ msgid ":py:obj:`ones <tvm.relay.ones>`\\ \\(shape\\, dtype\\)"
#~ msgstr ""

#~ msgid "Fill array with ones."
#~ msgstr ""

#~ msgid ":py:obj:`ones_like <tvm.relay.ones_like>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Returns an array of ones, with same type and shape as the input."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`optimize <tvm.relay.optimize>`\\ \\(mod\\[\\, "
#~ "target\\, params\\]\\)"
#~ msgstr ""

#~ msgid "Helper function that optimizes a Relay module."
#~ msgstr ""

#~ msgid ":py:obj:`power <tvm.relay.power>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Power with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`prod <tvm.relay.prod>`\\ \\(data\\[\\, "
#~ "axis\\, keepdims\\, exclude\\]\\)"
#~ msgstr ""

#~ msgid "Computes the products of array elements over given axes."
#~ msgstr ""

#~ msgid ":py:obj:`reinterpret <tvm.relay.reinterpret>`\\ \\(data\\, dtype\\)"
#~ msgstr ""

#~ msgid "Reinterpret input tensor to data type."
#~ msgstr ""

#~ msgid ":py:obj:`repeat <tvm.relay.repeat>`\\ \\(data\\, repeats\\, axis\\)"
#~ msgstr ""

#~ msgid "Repeats elements of an array."
#~ msgstr ""

#~ msgid ":py:obj:`reshape <tvm.relay.reshape>`\\ \\(data\\, newshape\\)"
#~ msgstr ""

#~ msgid "Reshape the input array."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`reshape_like <tvm.relay.reshape_like>`\\ "
#~ "\\(data\\, shape\\_like\\[\\, lhs\\_begin\\, "
#~ "...\\]\\)"
#~ msgstr ""

#~ msgid "Reshapes the input tensor by the size of another tensor."
#~ msgstr ""

#~ msgid ":py:obj:`reverse <tvm.relay.reverse>`\\ \\(data\\, axis\\)"
#~ msgstr ""

#~ msgid ""
#~ "Reverses the order of elements along "
#~ "given axis while preserving array shape."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`reverse_reshape <tvm.relay.reverse_reshape>`\\ "
#~ "\\(data\\, newshape\\)"
#~ msgstr ""

#~ msgid ""
#~ "Reshapes the input array where the "
#~ "special values are inferred from right"
#~ " to left."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`reverse_sequence <tvm.relay.reverse_sequence>`\\ "
#~ "\\(data\\, seq\\_lengths\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Reverse the tensor for variable length slices."
#~ msgstr ""

#~ msgid ":py:obj:`right_shift <tvm.relay.right_shift>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Right shift with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`round <tvm.relay.round>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute element-wise round of data."
#~ msgstr ""

#~ msgid ":py:obj:`rsqrt <tvm.relay.rsqrt>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise rsqrt of data."
#~ msgstr ""

#~ msgid ":py:obj:`save_param_dict <tvm.relay.save_param_dict>`\\ \\(params\\)"
#~ msgstr ""

#~ msgid "Save parameter dictionary to binary bytes."
#~ msgstr ""

#~ msgid ":py:obj:`scalar_type <tvm.relay.scalar_type>`\\ \\(dtype\\)"
#~ msgstr ""

#~ msgid "Creates a scalar type."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`scatter <tvm.relay.scatter>`\\ \\(data\\, "
#~ "indices\\, updates\\, axis\\)"
#~ msgstr ""

#~ msgid "Update data at positions defined by indices with values in updates"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`scatter_add <tvm.relay.scatter_add>`\\ \\(data\\,"
#~ " indices\\, updates\\, axis\\)"
#~ msgstr ""

#~ msgid "Update data by adding values in updates at positions defined by indices"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`scatter_nd <tvm.relay.scatter_nd>`\\ \\(data\\,"
#~ " indices\\, updates\\[\\, mode\\]\\)"
#~ msgstr ""

#~ msgid "Scatter values from an array and update."
#~ msgstr ""

#~ msgid ":py:obj:`script <tvm.relay.script>`\\ \\(pyfunc\\)"
#~ msgstr ""

#~ msgid "Decorate a python function function as hybrid script."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`searchsorted <tvm.relay.searchsorted>`\\ "
#~ "\\(sorted\\_sequence\\, values\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Find indices where elements should be inserted to maintain order."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`segment_sum <tvm.relay.segment_sum>`\\ \\(data\\,"
#~ " segment\\_ids\\[\\, num\\_segments\\]\\)"
#~ msgstr ""

#~ msgid "Computes the sum along segment_ids along axis 0."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`sequence_mask <tvm.relay.sequence_mask>`\\ "
#~ "\\(data\\, valid\\_length\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Sets all elements outside the expected"
#~ " length of the sequence to a "
#~ "constant value."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`setrecursionlimit <tvm.relay.setrecursionlimit>`\\ "
#~ "\\(limit\\, \\/\\)"
#~ msgstr ""

#~ msgid "Set the maximum depth of the Python interpreter stack to n."
#~ msgstr ""

#~ msgid ":py:obj:`shape_of <tvm.relay.shape_of>`\\ \\(data\\[\\, dtype\\]\\)"
#~ msgstr ""

#~ msgid "Get shape of a tensor."
#~ msgstr ""

#~ msgid ":py:obj:`sigmoid <tvm.relay.sigmoid>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise sigmoid of data."
#~ msgstr ""

#~ msgid ":py:obj:`sign <tvm.relay.sign>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid ":py:obj:`sin <tvm.relay.sin>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise sin of data."
#~ msgstr ""

#~ msgid ":py:obj:`sinh <tvm.relay.sinh>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise sinh of data."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`slice_like <tvm.relay.slice_like>`\\ \\(data\\,"
#~ " shape\\_like\\[\\, axes\\]\\)"
#~ msgstr ""

#~ msgid "Slice the first input with respect to the second input."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`sort <tvm.relay.sort>`\\ \\(data\\[\\, "
#~ "axis\\, is\\_ascend\\]\\)"
#~ msgstr ""

#~ msgid "Performs sorting along the given axis and returns data in sorted order."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`sparse_fill_empty_rows "
#~ "<tvm.relay.sparse_fill_empty_rows>`\\ \\(sparse\\_indices\\, "
#~ "...\\)"
#~ msgstr ""

#~ msgid "Fill rows in a sparse matrix that do no contain any values."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`sparse_reshape <tvm.relay.sparse_reshape>`\\ "
#~ "\\(sparse\\_indices\\, prev\\_shape\\, ...\\)"
#~ msgstr ""

#~ msgid "Reshape a Sparse Tensor."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`sparse_to_dense <tvm.relay.sparse_to_dense>`\\ "
#~ "\\(sparse\\_indices\\, ...\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Converts a sparse representation into a dense tensor."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`split <tvm.relay.split>`\\ \\(data\\, "
#~ "indices\\_or\\_sections\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid "Split input tensor along axis by sections or indices."
#~ msgstr ""

#~ msgid ":py:obj:`sqrt <tvm.relay.sqrt>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise sqrt of data."
#~ msgstr ""

#~ msgid ":py:obj:`squeeze <tvm.relay.squeeze>`\\ \\(data\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid "Squeeze axes in the array."
#~ msgstr ""

#~ msgid ":py:obj:`stack <tvm.relay.stack>`\\ \\(data\\, axis\\)"
#~ msgstr ""

#~ msgid "Join a sequence of arrays along a new axis."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`std <tvm.relay.std>`\\ \\(data\\[\\, "
#~ "axis\\, keepdims\\, exclude\\, unbiased\\]\\)"
#~ msgstr ""

#~ msgid "Computes the standard deviation of data over given axes."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`strided_set <tvm.relay.strided_set>`\\ \\(data\\,"
#~ " v\\, begin\\, end\\[\\, strides\\]\\)"
#~ msgstr ""

#~ msgid "Strided set of an array."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`strided_slice <tvm.relay.strided_slice>`\\ "
#~ "\\(data\\, begin\\, end\\[\\, strides\\, "
#~ "...\\]\\)"
#~ msgstr ""

#~ msgid "Strided slice of an array."
#~ msgstr ""

#~ msgid ":py:obj:`subtract <tvm.relay.subtract>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Subtraction with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`sum <tvm.relay.sum>`\\ \\(data\\[\\, "
#~ "axis\\, keepdims\\, exclude\\]\\)"
#~ msgstr ""

#~ msgid "Computes the sum of array elements over given axes."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`take <tvm.relay.take>`\\ \\(data\\, "
#~ "indices\\[\\, axis\\, batch\\_dims\\, mode\\]\\)"
#~ msgstr ""

#~ msgid "Take elements from an array along an axis."
#~ msgstr ""

#~ msgid ":py:obj:`tan <tvm.relay.tan>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute elementwise tan of data."
#~ msgstr ""

#~ msgid ":py:obj:`tanh <tvm.relay.tanh>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute element-wise tanh of data."
#~ msgstr ""

#~ msgid ":py:obj:`tile <tvm.relay.tile>`\\ \\(data\\, reps\\)"
#~ msgstr ""

#~ msgid "Repeats the whole array multiple times."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`topk <tvm.relay.topk>`\\ \\(data\\[\\, k\\,"
#~ " axis\\, ret\\_type\\, is\\_ascend\\, dtype\\]\\)"
#~ msgstr ""

#~ msgid "Get the top k elements in an input tensor along the given axis."
#~ msgstr ""

#~ msgid ":py:obj:`transpose <tvm.relay.transpose>`\\ \\(data\\[\\, axes\\]\\)"
#~ msgstr ""

#~ msgid "Permutes the dimensions of an array."
#~ msgstr ""

#~ msgid ":py:obj:`trunc <tvm.relay.trunc>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Compute element-wise trunc of data."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`unique <tvm.relay.unique>`\\ \\(data\\[\\, "
#~ "is\\_sorted\\, return\\_counts\\]\\)"
#~ msgstr ""

#~ msgid "Find the unique elements of a 1-D tensor."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`unravel_index <tvm.relay.unravel_index>`\\ "
#~ "\\(indices\\, shape\\)"
#~ msgstr ""

#~ msgid ""
#~ "Convert a flat index or array of"
#~ " flat indices into a tuple of "
#~ "coordinate arrays."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`var <tvm.relay.var>`\\ \\(name\\_hint\\[\\, "
#~ "type\\_annotation\\, shape\\, dtype\\]\\)"
#~ msgstr ""

#~ msgid "Create a new tvm.relay.Var."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`variance <tvm.relay.variance>`\\ \\(data\\[\\,"
#~ " axis\\, keepdims\\, exclude\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Computes the variance of data over given axes."
#~ msgstr ""

#~ msgid ":py:obj:`where <tvm.relay.where>`\\ \\(condition\\, x\\, y\\)"
#~ msgstr ""

#~ msgid ""
#~ "Selecting elements from either x or "
#~ "y depending on the value of the"
#~ " condition."
#~ msgstr ""

#~ msgid ":py:obj:`zeros <tvm.relay.zeros>`\\ \\(shape\\, dtype\\)"
#~ msgstr ""

#~ msgid "Fill array with zeros."
#~ msgstr ""

#~ msgid ":py:obj:`zeros_like <tvm.relay.zeros_like>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Returns an array of zeros, with same type and shape as the input."
#~ msgstr ""

#~ msgid ""
#~ "Call node corresponds the operator "
#~ "application node in computational graph "
#~ "terminology."
#~ msgstr ""

#~ msgid "参数"
#~ msgstr ""

#~ msgid "The operation to be called."
#~ msgstr ""

#~ msgid "The arguments to the call."
#~ msgstr ""

#~ msgid "Attributes to the call, can be None"
#~ msgstr ""

#~ msgid ""
#~ "The additional type arguments, this is"
#~ " only used in advanced usecase of "
#~ "template functions."
#~ msgstr ""

#~ msgid "Span that points to original source code"
#~ msgstr ""

#~ msgid "The data content of the constant expression."
#~ msgstr ""

#~ msgid ":py:obj:`checked_type <tvm.relay.Expr.checked_type>`\\"
#~ msgstr ""

#~ msgid "Get the checked type of tvm.relay.Expr."
#~ msgstr ""

#~ msgid ""
#~ "Defines the default dispatch over "
#~ "expressions, and implements memoization."
#~ msgstr ""

#~ msgid "**Methods:**"
#~ msgstr ""

#~ msgid ":py:obj:`visit <tvm.relay.ExprFunctor.visit>`\\ \\(expr\\)"
#~ msgstr ""

#~ msgid "Apply the visitor to an expression."
#~ msgstr ""

#~ msgid ""
#~ "The default behavior recursively traverses "
#~ "the AST and reconstructs the AST."
#~ msgstr ""

#~ msgid "The default behavior recursively traverses the AST."
#~ msgstr ""

#~ msgid "List of input parameters to the function."
#~ msgstr ""

#~ msgid "The body of the function."
#~ msgstr ""

#~ msgid "The return type annotation of the function."
#~ msgstr ""

#~ msgid ""
#~ "The additional type parameters, this is"
#~ " only used in advanced usecase of "
#~ "template functions."
#~ msgstr ""

#~ msgid "The condition."
#~ msgstr ""

#~ msgid "The expression evaluated when condition is true."
#~ msgstr ""

#~ msgid "The expression evaluated when condition is false."
#~ msgstr ""

#~ msgid "The local variable to be bound."
#~ msgstr ""

#~ msgid "The value to be bound."
#~ msgstr ""

#~ msgid "The body of the let binding."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_ctor <tvm.relay.Prelude.get_ctor>`\\ "
#~ "\\(ty\\_name\\, canonical\\, dtype\\)"
#~ msgstr ""

#~ msgid "Get constructor corresponding to the canonical name"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_ctor_static <tvm.relay.Prelude.get_ctor_static>`\\"
#~ " \\(ty\\_name\\, name\\, dtype\\, shape\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_global_var <tvm.relay.Prelude.get_global_var>`\\"
#~ " \\(canonical\\, dtype\\)"
#~ msgstr ""

#~ msgid "Get global var corresponding to the canonical name"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_global_var_static "
#~ "<tvm.relay.Prelude.get_global_var_static>`\\ \\(canonical\\, "
#~ "dtype\\, shape\\)"
#~ msgstr ""

#~ msgid "Get var corresponding to the canonical name"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_name <tvm.relay.Prelude.get_name>`\\ "
#~ "\\(canonical\\, dtype\\)"
#~ msgstr ""

#~ msgid "Get name corresponding to the canonical name"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_name_static <tvm.relay.Prelude.get_name_static>`\\"
#~ " \\(canonical\\, dtype\\, shape\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_tensor_ctor_static "
#~ "<tvm.relay.Prelude.get_tensor_ctor_static>`\\ \\(name\\, "
#~ "dtype\\, shape\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_type <tvm.relay.Prelude.get_type>`\\ "
#~ "\\(canonical\\, dtype\\)"
#~ msgstr ""

#~ msgid "Get type corresponding to the canonical name"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_type_static <tvm.relay.Prelude.get_type_static>`\\"
#~ " \\(canonical\\, dtype\\, shape\\)"
#~ msgstr ""

#~ msgid ":py:obj:`load_prelude <tvm.relay.Prelude.load_prelude>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Parses the Prelude from Relay's text format into a module."
#~ msgstr ""

#~ msgid ""
#~ "Create a new reference from initial "
#~ "value. :param value: The initial value."
#~ " :type value: tvm.relay.Expr"
#~ msgstr ""

#~ msgid ""
#~ "Get the value inside the reference. "
#~ ":param ref: The reference. :type ref:"
#~ " tvm.relay.Expr"
#~ msgstr ""

#~ msgid ""
#~ "Update the value inside the reference."
#~ " The whole expression will evaluate "
#~ "to an empty tuple. :param ref: The"
#~ " reference. :type ref: tvm.relay.Expr "
#~ ":param value: The new value. :type "
#~ "value: tvm.relay.Expr"
#~ msgstr ""

#~ msgid "Enables users to build up a nested scope(let, if) expression easily."
#~ msgstr ""

#~ msgid "实际案例"
#~ msgstr ""

#~ msgid ":py:obj:`else_scope <tvm.relay.ScopeBuilder.else_scope>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Create a new else scope."
#~ msgstr ""

#~ msgid ":py:obj:`get <tvm.relay.ScopeBuilder.get>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Get the generated result."
#~ msgstr ""

#~ msgid ":py:obj:`if_scope <tvm.relay.ScopeBuilder.if_scope>`\\ \\(cond\\)"
#~ msgstr ""

#~ msgid "Create a new if scope."
#~ msgstr ""

#~ msgid ":py:obj:`let <tvm.relay.ScopeBuilder.let>`\\ \\(var\\, value\\)"
#~ msgstr ""

#~ msgid "Create a new let binding."
#~ msgstr ""

#~ msgid ":py:obj:`ret <tvm.relay.ScopeBuilder.ret>`\\ \\(value\\)"
#~ msgstr ""

#~ msgid "Set the return value of this scope."
#~ msgstr ""

#~ msgid ":py:obj:`type_of <tvm.relay.ScopeBuilder.type_of>`\\ \\(expr\\)"
#~ msgstr ""

#~ msgid "Compute the type of an expression."
#~ msgstr ""

#~ msgid "返回"
#~ msgstr ""

#~ msgid "**scope** -- The if scope."
#~ msgstr ""

#~ msgid "返回类型"
#~ msgstr ""

#~ msgid "**value** -- The final result of the expression."
#~ msgstr ""

#~ msgid "The condition"
#~ msgstr ""

#~ msgid "The user must follows with an else scope."
#~ msgstr ""

#~ msgid "The variable or name of variable."
#~ msgstr ""

#~ msgid "The value to be bound"
#~ msgstr ""

#~ msgid "The return value."
#~ msgstr ""

#~ msgid "The expression to compute the type of."
#~ msgstr ""

#~ msgid "**type_var** -- The shape variable."
#~ msgstr ""

#~ msgid "The fields in the tuple."
#~ msgstr ""

#~ msgid ":py:obj:`astype <tvm.relay.Tuple.astype>`\\ \\(\\_\\)"
#~ msgstr ""

#~ msgid "Cast the content type of the current data to dtype."
#~ msgstr ""

#~ msgid "The target data type."
#~ msgstr ""

#~ msgid "This function only works for TensorType Exprs."
#~ msgstr ""

#~ msgid "**result** -- The result expression."
#~ msgstr ""

#~ msgid "The input tuple expression."
#~ msgstr ""

#~ msgid "The index."
#~ msgstr ""

#~ msgid ""
#~ "This class is a Python wrapper for"
#~ " a Relay tuple of known size. "
#~ "It allows for accessing the fields "
#~ "of the Relay tuple as though it"
#~ " were a Python tuple."
#~ msgstr ""

#~ msgid "The input tuple"
#~ msgstr ""

#~ msgid "The size of the tuple."
#~ msgstr ""

#~ msgid ":py:obj:`astext <tvm.relay.TupleWrapper.astext>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Get the text format of the tuple expression."
#~ msgstr ""

#~ msgid ":py:obj:`astuple <tvm.relay.TupleWrapper.astuple>`\\ \\(\\)"
#~ msgstr ""

#~ msgid ""
#~ "Returns the underlying Relay tuple if"
#~ " this wrapper is passed as an "
#~ "argument to an FFI function."
#~ msgstr ""

#~ msgid "**text** -- The text format of the tuple expression."
#~ msgstr ""

#~ msgid ""
#~ "Note that ADT definitions are treated"
#~ " as type-level functions because the"
#~ " type parameters need to be given "
#~ "for an instance of the ADT. Thus,"
#~ " any global type var that is an"
#~ " ADT header needs to be wrapped "
#~ "in a type call that passes in "
#~ "the type params."
#~ msgstr ""

#~ msgid ""
#~ "The name of the ADT. ADTs with "
#~ "the same constructors but different "
#~ "names are treated as different types."
#~ msgstr ""

#~ msgid "Type variables that appear in constructors."
#~ msgstr ""

#~ msgid "The constructors for the ADT."
#~ msgstr ""

#~ msgid "Defines the default dispatch over types."
#~ msgstr ""

#~ msgid ":py:obj:`visit <tvm.relay.TypeFunctor.visit>`\\ \\(typ\\)"
#~ msgstr ""

#~ msgid "Apply the visitor to a type."
#~ msgstr ""

#~ msgid "The input data"
#~ msgstr ""

#~ msgid "**result** -- The computed result."
#~ msgstr ""

#~ msgid "The left hand side input data"
#~ msgstr ""

#~ msgid "The right hand side input data"
#~ msgstr ""

#~ msgid "Numpy style advanced indexing. Index with a list of tensors."
#~ msgstr ""

#~ msgid ""
#~ "Input tensor and indices. The first "
#~ "tensor is input data and rests are"
#~ " indices."
#~ msgstr ""

#~ msgid "**result** -- Output tensor."
#~ msgstr ""

#~ msgid "The input boolean tensor"
#~ msgstr ""

#~ msgid ""
#~ "Axis or axes along which a sum "
#~ "is performed. The default, axis=None, "
#~ "will sum all of the elements of"
#~ " the input array. If axis is "
#~ "negative it counts from the last "
#~ "to the first axis."
#~ msgstr ""

#~ msgid ""
#~ "If this is set to True, the "
#~ "axes which are reduced are left in"
#~ " the result as dimensions with size"
#~ " one. With this option, the result"
#~ " will broadcast correctly against the "
#~ "input array."
#~ msgstr ""

#~ msgid ""
#~ "If `exclude` is true, reduction will "
#~ "be performed on the axes that are"
#~ " NOT in axis instead."
#~ msgstr ""

#~ msgid ""
#~ "Similar to ``numpy.arange``, when only "
#~ "one argument is given, it is used"
#~ " as `stop` instead of `start` while"
#~ " `start` takes default value 0."
#~ msgstr ""

#~ msgid ""
#~ "Warning: Undefined behavior when dtype "
#~ "is incompatible with start/stop/step. It "
#~ "could lead to different results compared"
#~ " to numpy, MXNet, pytorch, etc."
#~ msgstr ""

#~ msgid ""
#~ "Start of interval. The interval includes"
#~ " this value. The default start value"
#~ " is 0."
#~ msgstr ""

#~ msgid "Stop of interval. The interval does not include this value."
#~ msgstr ""

#~ msgid "Spacing between values. The default step size is 1."
#~ msgstr ""

#~ msgid "**result** -- The resulting tensor."
#~ msgstr ""

#~ msgid ""
#~ "Axis or axes along which a argmax"
#~ " operation is performed. The default, "
#~ "axis=None, will find the indices of "
#~ "the maximum element of the elements "
#~ "of the input array. If axis is "
#~ "negative it counts from the last "
#~ "to the first axis."
#~ msgstr ""

#~ msgid ""
#~ "Whether to select the last index "
#~ "or the first index if the max "
#~ "element appears in multiple indices, "
#~ "default is False (first index)."
#~ msgstr ""

#~ msgid ""
#~ "Axis or axes along which a argmin"
#~ " operation is performed. The default, "
#~ "axis=None, will find the indices of "
#~ "minimum element all of the elements "
#~ "of the input array. If axis is "
#~ "negative it counts from the last "
#~ "to the first axis."
#~ msgstr ""

#~ msgid ""
#~ "Whether to select the last index "
#~ "or the first index if the min "
#~ "element appears in multiple indices, "
#~ "default is False (first index)."
#~ msgstr ""

#~ msgid "The input data tensor."
#~ msgstr ""

#~ msgid "The number of valid elements to be sorted."
#~ msgstr ""

#~ msgid "Axis long which to sort the input tensor."
#~ msgstr ""

#~ msgid "Whether to sort in ascending or descending order."
#~ msgstr ""

#~ msgid "The data type of the output indices."
#~ msgstr ""

#~ msgid "**out** -- Tensor with same shape as data."
#~ msgstr ""

#~ msgid "The input condition tensor."
#~ msgstr ""

#~ msgid "**out** -- Tensor with the indices of elements that are non-zero."
#~ msgstr ""

#~ msgid "We can bind parameters expr if it is a function."
#~ msgstr ""

#~ msgid "The input expression."
#~ msgstr ""

#~ msgid "The specific bindings."
#~ msgstr ""

#~ msgid "**result** -- The expression or function after binding."
#~ msgstr ""

#~ msgid "The input tensor."
#~ msgstr ""

#~ msgid "Provide the shape to broadcast to."
#~ msgstr ""

#~ msgid "Provide the type to broadcast to."
#~ msgstr ""

#~ msgid "The IR module to build. Using relay.Function is deprecated."
#~ msgstr ""

#~ msgid ""
#~ "For heterogeneous compilation, it is a"
#~ " dictionary indicating context to target"
#~ " mapping. For homogeneous compilation, it"
#~ " is a build target."
#~ msgstr ""

#~ msgid ""
#~ "Host compilation target, if target is"
#~ " device. When TVM compiles device "
#~ "specific program such as CUDA, we "
#~ "also need host(CPU) side code to "
#~ "interact with the driver setup the "
#~ "dimensions and parameters correctly. "
#~ "target_host is used to specify the "
#~ "host side codegen target. By default,"
#~ " llvm is used if it is enabled,"
#~ " otherwise a stackvm interpreter is "
#~ "used."
#~ msgstr ""

#~ msgid ""
#~ "The executor configuration with which to"
#~ " build the model. Defaults to "
#~ "\"graph\" if no executor specified."
#~ msgstr ""

#~ msgid ""
#~ "Runtime configuration to use when "
#~ "building the model. Defaults to \"cpp\""
#~ " if no runtime specified."
#~ msgstr ""

#~ msgid ""
#~ "Input parameters to the graph that "
#~ "do not change during inference time. "
#~ "Used for constant folding."
#~ msgstr ""

#~ msgid "The module name we will build"
#~ msgstr ""

#~ msgid "**factory_module** -- The runtime factory for the TVM graph executor."
#~ msgstr ""

#~ msgid ""
#~ "Configure the build behavior by setting"
#~ " config variables. This function will "
#~ "be deprecated in TVM v0.7. Instead, "
#~ "we should directly use "
#~ "tvm.transform.PassContext."
#~ msgstr ""

#~ msgid ""
#~ "Optimization level. The optimization pass "
#~ "name and level are as the "
#~ "following:  .. code-block:: python      "
#~ "OPT_PASS_LEVEL = {         \"SimplifyInference\":"
#~ " 0,         \"OpFusion\": 1,         "
#~ "\"FoldConstant\": 2,         \"FoldScaleAxis\": 3,"
#~ "         \"AlterOpLayout\": 3,         "
#~ "\"CanonicalizeOps\": 3,         \"CanonicalizeCast\": "
#~ "3,         \"EliminateCommonSubexpr\": 3,         "
#~ "\"CombineParallelConv2D\": 4,         "
#~ "\"CombineParallelDense\": 4,         "
#~ "\"CombineParallelBatchMatmul\": 4,         \"FastMath\":"
#~ " 4     }"
#~ msgstr ""

#~ msgid ""
#~ "Optimization level. The optimization pass "
#~ "name and level are as the "
#~ "following:"
#~ msgstr ""

#~ msgid "Optimization passes that are required regardless of optimization level."
#~ msgstr ""

#~ msgid "Optimization passes to be disabled during optimization."
#~ msgstr ""

#~ msgid "A tracing function for debugging or introspection."
#~ msgstr ""

#~ msgid "**pass_context** -- The pass context for optimizations."
#~ msgstr ""

#~ msgid "The input data to the operator."
#~ msgstr ""

#~ msgid "The target data type"
#~ msgstr ""

#~ msgid "**result** -- The casted result."
#~ msgstr ""

#~ msgid "The tensor to cast to."
#~ msgstr ""

#~ msgid ""
#~ "Clip the elements in `a` between "
#~ "`a_min` and `a_max`. `a_min` and `a_max`"
#~ " are cast to `a`'s dtype."
#~ msgstr ""

#~ msgid "The clip minimum."
#~ msgstr ""

#~ msgid "The clip maximum."
#~ msgstr ""

#~ msgid "**result** -- `a` with elements clipped between `a_min` and `a_max`."
#~ msgstr ""

#~ msgid "Provide the type to collapse to."
#~ msgstr ""

#~ msgid "Shape to collapse to."
#~ msgstr ""

#~ msgid "A list of tensors."
#~ msgstr ""

#~ msgid "The axis along which the tensors are concatenated."
#~ msgstr ""

#~ msgid "**result** -- The concatenated tensor."
#~ msgstr ""

#~ msgid "The constant value."
#~ msgstr ""

#~ msgid "The data type of the resulting constant."
#~ msgstr ""

#~ msgid "When dtype is None, we use the following rule:"
#~ msgstr ""

#~ msgid "int maps to \"int32\""
#~ msgstr ""

#~ msgid "float maps to \"float32\""
#~ msgstr ""

#~ msgid "bool maps to \"bool\""
#~ msgstr ""

#~ msgid "other using the same default rule as numpy."
#~ msgstr ""

#~ msgid "The tensor to be copied."
#~ msgstr ""

#~ msgid "**result** -- The copied result."
#~ msgstr ""

#~ msgid "示例"
#~ msgstr ""

#~ msgid ""
#~ "The type of executor. Avaliable options"
#~ " are `debug` for the interpreter, "
#~ "`graph` for the graph executor, and "
#~ "`vm` for the virtual machine."
#~ msgstr ""

#~ msgid "The Relay module containing collection of functions"
#~ msgstr ""

#~ msgid "The device to execute the code."
#~ msgstr ""

#~ msgid "The corresponding context"
#~ msgstr ""

#~ msgid "Input parameters to the graph that do not change during inference time."
#~ msgstr ""

#~ msgid "**executor**"
#~ msgstr ""

#~ msgid ":py:class:`~tvm.relay.backend.interpreter.Executor`"
#~ msgstr ""

#~ msgid ""
#~ "Numpy style cumprod op. Return the "
#~ "cumulative inclusive product of the "
#~ "elements along a given axis."
#~ msgstr ""

#~ msgid ""
#~ "Axis along which the cumulative product"
#~ " is computed. The default (None) is"
#~ " to compute the cumprod over the "
#~ "flattened array."
#~ msgstr ""

#~ msgid ""
#~ "Type of the returned array and of"
#~ " the accumulator in which the "
#~ "elements are multiplied. If dtype is "
#~ "not specified, it defaults to the "
#~ "dtype of data."
#~ msgstr ""

#~ msgid ""
#~ "If true will return exclusive product"
#~ " in which the first element is "
#~ "not included. In other terms, if "
#~ "true, the j-th output element would "
#~ "be the product of the first (j-1)"
#~ " elements. Otherwise, it would be the"
#~ " product of the first j elements. "
#~ "The product of zero elements will "
#~ "be 1."
#~ msgstr ""

#~ msgid ""
#~ "**result** -- The result has the "
#~ "same size as data, and the same"
#~ " shape as data if axis is not"
#~ " None. If axis is None, the "
#~ "result is a 1-d array."
#~ msgstr ""

#~ msgid ""
#~ "Numpy style cumsum op. Return the "
#~ "cumulative inclusive sum of the elements"
#~ " along a given axis."
#~ msgstr ""

#~ msgid ""
#~ "Axis along which the cumulative sum "
#~ "is computed. The default (None) is "
#~ "to compute the cumsum over the "
#~ "flattened array."
#~ msgstr ""

#~ msgid ""
#~ "Type of the returned array and of"
#~ " the accumulator in which the "
#~ "elements are summed. If dtype is "
#~ "not specified, it defaults to the "
#~ "dtype of data."
#~ msgstr ""

#~ msgid ""
#~ "If true will return exclusive sum "
#~ "in which the first element is not"
#~ " included. In other terms, if true,"
#~ " the j-th output element would be "
#~ "the sum of the first (j-1) "
#~ "elements. Otherwise, it would be the "
#~ "sum of the first j elements."
#~ msgstr ""

#~ msgid ""
#~ "Copy data from the source device "
#~ "to the destination device. This operator"
#~ " helps data transferring between difference"
#~ " devices for heterogeneous execution."
#~ msgstr ""

#~ msgid "The source device where the data is copied from."
#~ msgstr ""

#~ msgid "The destination device where the data is copied to."
#~ msgstr ""

#~ msgid "The einsum expression string."
#~ msgstr ""

#~ msgid "**result** -- The output tensor from the einsum op."
#~ msgstr ""

#~ msgid ""
#~ "The axis at which the input array"
#~ " is expanded. Should lie in range "
#~ "`[-data.ndim - 1, data.ndim]`. If `axis"
#~ " < 0`, it is the first axis "
#~ "inserted; If `axis >= 0`, it is"
#~ " the last axis inserted in Python's"
#~ " negative indexing."
#~ msgstr ""

#~ msgid "Number of axes to be inserted. Should be >= 0."
#~ msgstr ""

#~ msgid "**result** -- The reshaped result."
#~ msgstr ""

#~ msgid "The integer multiplier of the fixed point constant."
#~ msgstr ""

#~ msgid "The integer shift of the fixed point constant."
#~ msgstr ""

#~ msgid "**result** -- The output of the fixed point multiplication"
#~ msgstr ""

#~ msgid "The value to fill. Must be a scalar."
#~ msgstr ""

#~ msgid "The shape of the target."
#~ msgstr ""

#~ msgid "The data type of the target."
#~ msgstr ""

#~ msgid "The scalar value to fill."
#~ msgstr ""

#~ msgid "E.g. for a 3D tensor, output is computed as:"
#~ msgstr ""

#~ msgid ""
#~ "``indices`` must have same shape as "
#~ "``data``, except at dimension ``axis`` "
#~ "which must just be not null. "
#~ "Output will have same shape as "
#~ "``indices``."
#~ msgstr ""

#~ msgid "The axis along which to index. negative axis is supported."
#~ msgstr ""

#~ msgid "The indices of values to gather."
#~ msgstr ""

#~ msgid "The shape of output tensor."
#~ msgstr ""

#~ msgid "The number of batch dimensions."
#~ msgstr ""

#~ msgid ""
#~ "The size of an indexing tuple, "
#~ "which is a fixed value and the "
#~ "same as indices.shape[0] Only needed "
#~ "when other dimensions of indices are "
#~ "dynamic."
#~ msgstr ""

#~ msgid "**ret** -- The computed result."
#~ msgstr ""

#~ msgid ""
#~ "Computes the inverse permutation of "
#~ "data. This operation computes the "
#~ "inverse of an index permutation. It "
#~ "takes a 1-D integer tensor x, "
#~ "which represents the indices of a "
#~ "zero-based array and swaps each value"
#~ " with its index position."
#~ msgstr ""

#~ msgid ""
#~ "For an output tensor y and an "
#~ "input tensor x, this operation computes"
#~ " the following: y[x[i]] = i for "
#~ "i in [0, 1, ..., len(x) - 1]"
#~ msgstr ""

#~ msgid "The source data to be invert permuated."
#~ msgstr ""

#~ msgid "**ret** -- Invert permuated data. Has the same type as data."
#~ msgstr ""

#~ msgid "The source tensor to be transformed"
#~ msgstr ""

#~ msgid "The source layout.  (e.g NCHW)"
#~ msgstr ""

#~ msgid "The destination layout.  (e.g. NCHW16c)"
#~ msgstr ""

#~ msgid "**ret** -- The transformed tensor."
#~ msgstr ""

#~ msgid "Use :py:func:`tvm.runtime.load_param_dict` instead."
#~ msgstr ""

#~ msgid "Serialized parameters."
#~ msgstr ""

#~ msgid "**params** -- The parameter dictionary."
#~ msgstr ""

#~ msgid ""
#~ "This function is more numerically stable"
#~ " than log(sum(exp(input))). It avoids "
#~ "overflows caused by taking the exp "
#~ "of large inputs and underflows caused"
#~ " by taking the log of small "
#~ "inputs."
#~ msgstr ""

#~ msgid ""
#~ "Axis or axes along which a "
#~ "standard deviation operation is performed. "
#~ "The default, axis=None, will compute the"
#~ " log of the sum of exponentials "
#~ "of all elements in the input "
#~ "array. If axis is negative it "
#~ "counts from the last to the first"
#~ " axis."
#~ msgstr ""

#~ msgid ""
#~ "If this is set to True, the "
#~ "axes which are reduced are left in"
#~ " the result as dimensions with size"
#~ " one."
#~ msgstr ""

#~ msgid "Input Tensor."
#~ msgstr ""

#~ msgid "Values to be filled in the diagonal."
#~ msgstr ""

#~ msgid ""
#~ "Diagonal Offset(s). The diagonal or "
#~ "range of diagonals to set. (0 by"
#~ " default) Positive value means "
#~ "superdiagonal, 0 refers to the main "
#~ "diagonal, and negative value means "
#~ "subdiagonals. k can be a single "
#~ "integer (for a single diagonal) or "
#~ "a pair of integers specifying the "
#~ "low and high ends of a matrix "
#~ "band. k[0] must not be larger than"
#~ " k[1]."
#~ msgstr ""

#~ msgid ""
#~ "Some diagonals are shorter than "
#~ "max_diag_len and need to be padded. "
#~ "align is a string specifying how "
#~ "superdiagonals and subdiagonals should be "
#~ "aligned, respectively. There are four "
#~ "possible alignments: \"RIGHT_LEFT\" (default), "
#~ "\"LEFT_RIGHT\", \"LEFT_LEFT\", and \"RIGHT_RIGHT\"."
#~ " \"RIGHT_LEFT\" aligns superdiagonals to "
#~ "the right (left-pads the row) and"
#~ " subdiagonals to the left (right-pads"
#~ " the row). It is the packing "
#~ "format LAPACK uses. cuSPARSE uses "
#~ "\"LEFT_RIGHT\", which is the opposite "
#~ "alignment."
#~ msgstr ""

#~ msgid "**result** -- New tensor with given diagonal values."
#~ msgstr ""

#~ msgid ""
#~ "Axis or axes along which the max"
#~ " operation is performed. The default, "
#~ "axis=None, will find the max element "
#~ "from all of the elements of the"
#~ " input array. If axis is negative "
#~ "it counts from the last to the "
#~ "first axis."
#~ msgstr ""

#~ msgid ""
#~ "Axis or axes along which a mean"
#~ " operation is performed. The default, "
#~ "axis=None, will compute the mean of "
#~ "all elements in the input array. "
#~ "If axis is negative it counts from"
#~ " the last to the first axis."
#~ msgstr ""

#~ msgid ""
#~ "Axis or axes along which a mean"
#~ " and standard deviation operation is "
#~ "performed. The default, axis=None, will "
#~ "compute the mean and standard deviation"
#~ " of all elements in the input "
#~ "array. If axis is negative it "
#~ "counts from the last to the first"
#~ " axis."
#~ msgstr ""

#~ msgid ""
#~ "Axis or axes along which a mean"
#~ " and variance operation is performed. "
#~ "The default, axis=None, will compute the"
#~ " mean and variance of all elements"
#~ " in the input array. If axis is"
#~ " negative it counts from the last "
#~ "to the first axis."
#~ msgstr ""

#~ msgid "If this is set to True, the unbiased estimation will be used."
#~ msgstr ""

#~ msgid "Similar to ``numpy.meshgrid``."
#~ msgstr ""

#~ msgid "A list of tensors, which must be either scalars or 1-D vectors."
#~ msgstr ""

#~ msgid ""
#~ "Indexing mode, either \"ij\" for matrix"
#~ " indexing or \"xy\" for Cartesian "
#~ "indexing."
#~ msgstr ""

#~ msgid ""
#~ "Axis or axes along which a minimum"
#~ " operation is performed. The default, "
#~ "axis=None, will find the minimum element"
#~ " from all of the elements of "
#~ "the input array. If axis is "
#~ "negative it counts from the last "
#~ "to the first axis."
#~ msgstr ""

#~ msgid "**result** -- The number of elements of input tensor."
#~ msgstr ""

#~ msgid ""
#~ "Returns a one-hot tensor where the"
#~ " locations repsented by indices take "
#~ "value on_value, other locations take "
#~ "value off_value. Final dimension is "
#~ "<indices outer dimensions> x depth x "
#~ "<indices inner dimensions>."
#~ msgstr ""

#~ msgid "Locations to set to on_value."
#~ msgstr ""

#~ msgid "Value to fill at indices."
#~ msgstr ""

#~ msgid "Value to fill at all other positions besides indices."
#~ msgstr ""

#~ msgid "Depth of the one-hot dimension."
#~ msgstr ""

#~ msgid "Axis to fill."
#~ msgstr ""

#~ msgid "Data type of the output tensor."
#~ msgstr ""

#~ msgid "**ret** -- The one-hot tensor."
#~ msgstr ""

#~ msgid "The module to build. Using relay.Function is deprecated."
#~ msgstr ""

#~ msgid ""
#~ "* **mod** (:py:class:`~tvm.IRModule`) -- The"
#~ " optimized relay module. * **params** "
#~ "(*dict*) -- The parameters of the "
#~ "final graph."
#~ msgstr ""

#~ msgid "**mod** (:py:class:`~tvm.IRModule`) -- The optimized relay module."
#~ msgstr ""

#~ msgid "**params** (*dict*) -- The parameters of the final graph."
#~ msgstr ""

#~ msgid ""
#~ "Axis or axes along which a product"
#~ " is performed. The default, axis=None, "
#~ "will find the indices of minimum "
#~ "element all of the elements of the"
#~ " input array. If axis is negative "
#~ "it counts from the last to the "
#~ "first axis."
#~ msgstr ""

#~ msgid "**result** -- The reinterpreted result."
#~ msgstr ""

#~ msgid ""
#~ "Repeats elements of an array. By "
#~ "default, repeat flattens the input array"
#~ " into 1-D and then repeats the "
#~ "elements."
#~ msgstr ""

#~ msgid "repeats"
#~ msgstr ""

#~ msgid "int"
#~ msgstr ""

#~ msgid "The number of repetitions for each element."
#~ msgstr ""

#~ msgid "axis: int"
#~ msgstr ""

#~ msgid ""
#~ "The axis along which to repeat "
#~ "values. The negative numbers are "
#~ "interpreted counting from the backward. "
#~ "By default, use the flattened input "
#~ "array, and return a flat output "
#~ "array."
#~ msgstr ""

#~ msgid ""
#~ "To give user more convenience in "
#~ "without doing manual shape inference, "
#~ "some dimensions of the shape can "
#~ "take special values from the set "
#~ "{0, -1, -2, -3, -4}. The "
#~ "significance of each is explained below:"
#~ msgstr ""

#~ msgid "``0`` copy this dimension from the input to the output shape."
#~ msgstr ""

#~ msgid ""
#~ "``-1`` infers the dimension of the "
#~ "output shape by using the remainder "
#~ "of the input dimensions keeping the "
#~ "size of the new array same as "
#~ "that of the input array. At most"
#~ " one dimension of shape can be "
#~ "-1."
#~ msgstr ""

#~ msgid "``-2`` copy all/remainder of the input dimensions to the output shape."
#~ msgstr ""

#~ msgid ""
#~ "``-3`` use the product of two "
#~ "consecutive dimensions of the input "
#~ "shape as the output dimension."
#~ msgstr ""

#~ msgid ""
#~ "``-4`` split one dimension of the "
#~ "input into two dimensions passed "
#~ "subsequent to -4 in shape (can "
#~ "contain -1)."
#~ msgstr ""

#~ msgid "The new shape. Should be compatible with the original shape."
#~ msgstr ""

#~ msgid ""
#~ "Reshapes the input tensor by the "
#~ "size of another tensor. For an "
#~ "input tensor with shape ``(d0, d1, "
#~ "..., d(k-1))``, `reshape_like` operation "
#~ "reshapes the input tensor into an "
#~ "output tensor with the same shape "
#~ "as the second input tensor, in "
#~ "particular reshaping the dimensions of "
#~ "`data` in `[lhs_begin, lhs_end)` using "
#~ "the dimensions from `shape_like` in "
#~ "`[rhs_begin, rhs_end)`."
#~ msgstr ""

#~ msgid "Sizes for `data` and the output tensor should be compatible."
#~ msgstr ""

#~ msgid ""
#~ "The tensor to reshape data like. "
#~ "Should be compatible with the original"
#~ " shape on the reshaped dimensions."
#~ msgstr ""

#~ msgid "The axis of data to begin reshaping. Default is 0."
#~ msgstr ""

#~ msgid ""
#~ "The axis of data where reshaping "
#~ "should stop, exclusive. Default is None"
#~ " which reshapes to the end."
#~ msgstr ""

#~ msgid "The axis of shape_like where the target shape begins. Default is 0."
#~ msgstr ""

#~ msgid ""
#~ "The axis of shape_like where the "
#~ "target shape ends, exclusive. Default is"
#~ " None which extends to the end."
#~ msgstr ""

#~ msgid ""
#~ "Reverses the order of elements along "
#~ "given axis while preserving array shape."
#~ " By default, repeat flattens the "
#~ "input array into 1-D and then "
#~ "repeats the elements."
#~ msgstr ""

#~ msgid "The axis along which to reverse elements."
#~ msgstr ""

#~ msgid ""
#~ "The special values have the same "
#~ "semantics as :py:class:`tvm.relay.reshape`. The "
#~ "difference is that special values are"
#~ " inferred from right to left. It "
#~ "can be explained in the example "
#~ "below."
#~ msgstr ""

#~ msgid ""
#~ "Reverse the tensor for variable length"
#~ " slices. Input is first sliced along"
#~ " batch axis and then elements are "
#~ "reversed along seq axis."
#~ msgstr ""

#~ msgid "The tensor to be reversed."
#~ msgstr ""

#~ msgid ""
#~ "A 1D Tensor with length "
#~ "a.dims[batch_axis] Must be one of the"
#~ " following types: int32, int64 if "
#~ "seq_lengths[i] > a.dims[seq_axis], it is "
#~ "rounded to a.dims[seq_axis] if seq_lengths[i]"
#~ " < 1, it is rounded to 1"
#~ msgstr ""

#~ msgid "The axis along which the elements will be reversed. Default is 1."
#~ msgstr ""

#~ msgid "The axis along which the tensor will be sliced. Default is 0."
#~ msgstr ""

#~ msgid "**ret** -- The computed result of same shape and type as of input."
#~ msgstr ""

#~ msgid "1/sqrt(x)"
#~ msgstr ""

#~ msgid ""
#~ "The result binary bytes can be "
#~ "loaded by the GraphModule with API "
#~ "\"load_params\"."
#~ msgstr ""

#~ msgid "Use :py:func:`tvm.runtime.save_param_dict` instead."
#~ msgstr ""

#~ msgid "The parameter dictionary."
#~ msgstr ""

#~ msgid "**param_bytes** -- Serialized parameters."
#~ msgstr ""

#~ msgid "This function returns TensorType((), dtype)"
#~ msgstr ""

#~ msgid "The content data type."
#~ msgstr ""

#~ msgid "**s_type** -- The result type."
#~ msgstr ""

#~ msgid "The index locations to update."
#~ msgstr ""

#~ msgid "The values to update."
#~ msgstr ""

#~ msgid "The axis to scatter on"
#~ msgstr ""

#~ msgid "The values to add."
#~ msgstr ""

#~ msgid "The axis to scatter_add on"
#~ msgstr ""

#~ msgid "See :py:func:`tvm.topi.scatter` for how data is scattered."
#~ msgstr ""

#~ msgid "The accumulation mode for scatter. \"update\" or \"add\""
#~ msgstr ""

#~ msgid ""
#~ "The hybrid function support emulation "
#~ "mode and parsing to the internal "
#~ "language IR."
#~ msgstr ""

#~ msgid "**hybrid_func** -- A decorated hybrid script function."
#~ msgstr ""

#~ msgid ""
#~ "If `sorted_sequence` is N-dimensional, the "
#~ "innermost dimension of `values` are "
#~ "searched in the corresponding dimension "
#~ "of `sorted_sequence`."
#~ msgstr ""

#~ msgid ""
#~ "N-D or 1-D Tensor, containing "
#~ "monotonically increasing sequence on the "
#~ "innermost dimension."
#~ msgstr ""

#~ msgid ""
#~ "N-D Tensor containing the search values."
#~ " When `sorted_sequence` is 1-D, the "
#~ "shape of `values` can be arbitrary. "
#~ "Otherwise, ranks of `sorted_sequence` and "
#~ "`values` must be the same, and "
#~ "outer N-1 axes must have the same"
#~ " size."
#~ msgstr ""

#~ msgid ""
#~ "Controls which index is returned if "
#~ "a value lands exactly on one of"
#~ " sorted values. If False, the index"
#~ " of the first suitable location found"
#~ " is given. If true, return the "
#~ "last such index. If there is no"
#~ " suitable index, return either 0 or"
#~ " N (where N is the size of "
#~ "the innermost dimension)."
#~ msgstr ""

#~ msgid ""
#~ "**indices** -- Tensor with same shape"
#~ " as values, representing the indices "
#~ "of elements of `values` if they "
#~ "are inserted in `sorted_sequence`."
#~ msgstr ""

#~ msgid ""
#~ "Computes the sum along segment_ids along"
#~ " axis 0. If multiple segment_ids "
#~ "reference the same location their "
#~ "contributions add up. result[index, j, "
#~ "k, ...] = Σi... data[i, j, k,..]"
#~ " where index = segment_ids[i] This op"
#~ " is much better understood with "
#~ "visualization articulated in the following "
#~ "links and examples at the end of"
#~ " this docstring."
#~ msgstr ""

#~ msgid ""
#~ "https://www.tensorflow.org/api_docs/python/tf/math/unsorted_segment_sum"
#~ " https://caffe2.ai/docs/sparse-operations.html"
#~ "#null__unsorted-segment-reduction-ops"
#~ msgstr ""

#~ msgid "Input Tensor. It can be of any type and multi-dimensional"
#~ msgstr ""

#~ msgid ""
#~ "A 1-D int32/int64 tensor containing the"
#~ " segment_ids of the rows to calculate"
#~ " the output sum upon. It defines "
#~ "a mapping from the zeroth dimension "
#~ "of data onto segment_ids. The "
#~ "segment_ids tensor should be the size"
#~ " of the first dimension, d0, with "
#~ "consecutive IDs in the range 0 to"
#~ " k, where k<d0. In particular, a "
#~ "segmentation of a matrix tensor is "
#~ "a mapping of rows to segments. "
#~ "This tensor doesn't need to be "
#~ "sorted"
#~ msgstr ""

#~ msgid ""
#~ "An integer describing the shape of "
#~ "the zeroth dimension. If unspecified, "
#~ "its calculated equivalent to the number"
#~ " of unique segment_ids"
#~ msgstr ""

#~ msgid ""
#~ "This function takes an n-dimensional "
#~ "input array of the form [MAX_LENGTH, "
#~ "batch_size, ...] or [batch_size, MAX_LENGTH,"
#~ " ...] and returns an array of "
#~ "the same shape."
#~ msgstr ""

#~ msgid "The input data."
#~ msgstr ""

#~ msgid "The expected (valid) length of each sequence in the tensor."
#~ msgstr ""

#~ msgid "The masking value."
#~ msgstr ""

#~ msgid "The axis of the length dimension."
#~ msgstr ""

#~ msgid ""
#~ "This limit prevents infinite recursion "
#~ "from causing an overflow of the C"
#~ " stack and crashing Python.  The "
#~ "highest possible limit is platform- "
#~ "dependent."
#~ msgstr ""

#~ msgid "**result** -- The shape tensor."
#~ msgstr ""

#~ msgid ""
#~ "For an input array with shape "
#~ "``(d1, d2, ..., dk)``, `slice_like` "
#~ "operation slices the the input array "
#~ "corresponding size of second array. By"
#~ " default will slice on all axes."
#~ msgstr ""

#~ msgid "The source array."
#~ msgstr ""

#~ msgid "The new shape."
#~ msgstr ""

#~ msgid ""
#~ "List of axes on which input data"
#~ " will be sliced according to the "
#~ "corresponding size of the second input."
#~ " By default will slice on all "
#~ "axes. Negative axes mean counting in "
#~ "reverse."
#~ msgstr ""

#~ msgid ""
#~ "Fill rows in a sparse matrix that"
#~ " do no contain any values. Values "
#~ "are placed in the first column of"
#~ " empty rows. The sparse array is "
#~ "in COO format. It returns a "
#~ "TupleWrapper with 3 outputs"
#~ msgstr ""

#~ msgid ""
#~ "A 2-D tensor[N, ndims] of integers "
#~ "containing location of sparse values, "
#~ "where N is the number of sparse"
#~ " values and n_dim is the number "
#~ "of dimensions of the dense_shape. The"
#~ " first column of this relay parameter"
#~ " must be sorted in ascending order."
#~ msgstr ""

#~ msgid "A 1-D tensor[N] containing the sparse values for the sparse indices."
#~ msgstr ""

#~ msgid "A 1-D tensor[ndims] which contains shape of the dense output tensor."
#~ msgstr ""

#~ msgid ""
#~ "A 1-D tensor[1] containing the default"
#~ " value for the remaining locations."
#~ msgstr ""

#~ msgid ""
#~ "* **new_sparse_indices** (*relay.Expr*) -- A"
#~ " 2-D tensor[?, ndims] of integers "
#~ "containing location of new sparse   "
#~ "indices. The first column outputs must"
#~ " be sorted in ascending order. * "
#~ "**new_sparse_values** (*relay.Expr*) -- A 1-D"
#~ " tensor[?] containing the sparse values "
#~ "for the sparse indices. * "
#~ "**empty_row_indicator** (*relay.Expr*) -- A "
#~ "1-D tensor[dense_shape[0]] filled with zeros"
#~ " and ones   indicating whether the "
#~ "particular row is empty or full "
#~ "respectively"
#~ msgstr ""

#~ msgid ""
#~ "**new_sparse_indices** (*relay.Expr*) -- A 2-D"
#~ " tensor[?, ndims] of integers containing"
#~ " location of new sparse indices. The"
#~ " first column outputs must be sorted"
#~ " in ascending order."
#~ msgstr ""

#~ msgid ""
#~ "**new_sparse_values** (*relay.Expr*) -- A 1-D"
#~ " tensor[?] containing the sparse values "
#~ "for the sparse indices."
#~ msgstr ""

#~ msgid ""
#~ "**empty_row_indicator** (*relay.Expr*) -- A "
#~ "1-D tensor[dense_shape[0]] filled with zeros"
#~ " and ones indicating whether the "
#~ "particular row is empty or full "
#~ "respectively"
#~ msgstr ""

#~ msgid ""
#~ "This op exactly follows the "
#~ "documentation here: "
#~ "https://www.tensorflow.org/api_docs/python/tf/sparse/fill_empty_rows"
#~ " There are two exceptions: 1. Input"
#~ " Sparse Indices are expected to be"
#~ " in row-major order. 2. Empty "
#~ "Row Indicator has int64 output type "
#~ "with 1(for True) and 0(for False)."
#~ msgstr ""

#~ msgid "Reshape a Sparse Tensor. The sparse array is in COO format."
#~ msgstr ""

#~ msgid ""
#~ "A 2-D tensor[N, n_dim] of integers "
#~ "containing location of sparse values, "
#~ "where N is the number of sparse"
#~ " values and n_dim is the number "
#~ "of dimensions of the dense_shape"
#~ msgstr ""

#~ msgid "A 1-D tensor containing the previous shape of the dense tensor"
#~ msgstr ""

#~ msgid "A 1-D tensor containing the new shape of the dense tensor"
#~ msgstr ""

#~ msgid ""
#~ "Example:: -   sparse_to_dense([[0, 0], [1, "
#~ "1]], [2, 2], [3, 3], 0) = "
#~ "[[3, 0], [0, 3]]"
#~ msgstr ""

#~ msgid ""
#~ "A 0-D, 1-D, or 2-D tensor of "
#~ "integers containing location of sparse "
#~ "values."
#~ msgstr ""

#~ msgid "A list of integers. Shape of the dense output tensor."
#~ msgstr ""

#~ msgid ""
#~ "A 0-D or 1-D tensor containing the"
#~ " sparse values for the sparse "
#~ "indices."
#~ msgstr ""

#~ msgid ""
#~ "A 0-D tensor containing the default "
#~ "value for the remaining locations. "
#~ "Defaults to 0."
#~ msgstr ""

#~ msgid ""
#~ "**result** -- Dense tensor of shape "
#~ "output_shape. Has the same type as "
#~ "sparse_values."
#~ msgstr ""

#~ msgid ""
#~ "If indices_or_sections is an integer, "
#~ "the input will be divided equally "
#~ "along given axis. If such a split"
#~ " is not possible, an error is "
#~ "raised."
#~ msgstr ""

#~ msgid ""
#~ "If indices_or_sections is a tuple of "
#~ "sorted integers, the entries indicate "
#~ "where along axis the array is "
#~ "split."
#~ msgstr ""

#~ msgid "Indices or sections to split into. Accepts an int or a tuple"
#~ msgstr ""

#~ msgid "The axis over which to split."
#~ msgstr ""

#~ msgid ""
#~ "The set of axes to remove. If "
#~ "axis = None, remove all axis of"
#~ " dimensions 1. If any specified axis"
#~ " has dimension that does not equal"
#~ " 1, it is an error."
#~ msgstr ""

#~ msgid "**result** -- The squeezed result."
#~ msgstr ""

#~ msgid ""
#~ "A list of tensors or a Relay "
#~ "expression that evaluates to a tuple "
#~ "of tensors."
#~ msgstr ""

#~ msgid "The axis in the result array along which the input arrays are stacked."
#~ msgstr ""

#~ msgid "**ret** -- The stacked tensor."
#~ msgstr ""

#~ msgid ""
#~ "Axis or axes along which a "
#~ "standard deviation operation is performed. "
#~ "The default, axis=None, will compute the"
#~ " standard deviation of all elements "
#~ "in the input array. If axis is "
#~ "negative it counts from the last "
#~ "to the first axis."
#~ msgstr ""

#~ msgid "The source array to be sliced."
#~ msgstr ""

#~ msgid "The data to be set."
#~ msgstr ""

#~ msgid "The indices to begin with in the slicing."
#~ msgstr ""

#~ msgid "Indices indicating end of the slice."
#~ msgstr ""

#~ msgid ""
#~ "Specifies the stride values, it can "
#~ "be negative in that case, the "
#~ "input tensor will be reversed in "
#~ "that particular axis."
#~ msgstr ""

#~ msgid ""
#~ "Axes along which slicing is applied. "
#~ "When it is specified, the length "
#~ "of begin, end, strides, and axes "
#~ "must be equal. Moreover, begin, end, "
#~ "strides, and axes must be static "
#~ "(cannot be relay.Expr). Axes argument "
#~ "for dynamic parameter slicing is not "
#~ "supported yet."
#~ msgstr ""

#~ msgid ""
#~ "The slice mode [end, size]. end: "
#~ "The ending indices for the slice "
#~ "[default]. size: The input strides will"
#~ " be ignored, input end in this "
#~ "mode indicates the size of a slice"
#~ " starting at the location specified "
#~ "by begin. If end[i] is -1, all "
#~ "remaining elements in that dimension are"
#~ " included in the slice."
#~ msgstr ""

#~ msgid "The indices of the values to extract."
#~ msgstr ""

#~ msgid ""
#~ "The axis over which to select "
#~ "values. By default, the flattened input"
#~ " array is used."
#~ msgstr ""

#~ msgid "The number of batch dimensions. By default is 0."
#~ msgstr ""

#~ msgid ""
#~ "Specifies how out-of-bound indices "
#~ "will behave [clip, wrap, fast]. clip:"
#~ " clip to the range (default). wrap:"
#~ " wrap around the indices. fast: no"
#~ " clip or wrap around (user must "
#~ "make sure indices are in-bound)."
#~ msgstr ""

#~ msgid "The number of times repeating the tensor data."
#~ msgstr ""

#~ msgid "提示"
#~ msgstr ""

#~ msgid ""
#~ "Each dim size of reps must be "
#~ "a positive integer. If reps has "
#~ "length d, the result will have "
#~ "dimension of max(d, data.ndim); If "
#~ "data.ndim < d, data is promoted to"
#~ " be d-dimensional by prepending new "
#~ "axes. If data.ndim >=  d, reps is"
#~ " promoted to a.ndim by pre-pending"
#~ " 1's to it."
#~ msgstr ""

#~ msgid ""
#~ "ret_type specifies the return type, can"
#~ " be one of (\"both\", \"values\", "
#~ "\"indices\")."
#~ msgstr ""

#~ msgid "Number of top elements to select. Return all elements if k < 1."
#~ msgstr ""

#~ msgid ""
#~ "The return type [both, values, indices]."
#~ " \"both\": return both top k data "
#~ "and indices. \"values\": return top k"
#~ " data only. \"indices\": return top k"
#~ " indices only."
#~ msgstr ""

#~ msgid "The data type of the indices output."
#~ msgstr ""

#~ msgid "**out** -- The computed result."
#~ msgstr ""

#~ msgid "The target axes order, reverse order if not specified."
#~ msgstr ""

#~ msgid "**result** -- The transposed result."
#~ msgstr ""

#~ msgid ""
#~ "Find the unique elements of a 1-D"
#~ " tensor. Please note `output` and "
#~ "`counts` are all padded to have "
#~ "the same length of `data` and "
#~ "element with index >= num_unique[0] has"
#~ " undefined value."
#~ msgstr ""

#~ msgid "A 1-D tensor of integers."
#~ msgstr ""

#~ msgid ""
#~ "Whether to sort the unique elements "
#~ "in ascending order before returning as"
#~ " output."
#~ msgstr ""

#~ msgid "Whether to return the count of each unique element."
#~ msgstr ""

#~ msgid ""
#~ "* **unique** (*relay.Expr*) -- A 1-D "
#~ "tensor containing the unique elements of"
#~ " the input data tensor. * **indices**"
#~ " (*relay.Expr*) -- A 1-D tensor "
#~ "containing the index of each data "
#~ "element in the output tensor. * "
#~ "**inverse_indices** (*relay.Expr*) -- A 1-D"
#~ " tensor. For each entry in data, "
#~ "it contains the index of that data"
#~ " element in the   unique array. * "
#~ "**num_unique** (*relay.Expr*) -- A 1-D "
#~ "tensor with size=1 containing the number"
#~ " of unique elements in the input "
#~ "data tensor. * **counts (optional)** "
#~ "(*relay.Expr*) -- A 1-D tensor "
#~ "containing the count of each unique "
#~ "element in the output."
#~ msgstr ""

#~ msgid ""
#~ "**unique** (*relay.Expr*) -- A 1-D "
#~ "tensor containing the unique elements of"
#~ " the input data tensor."
#~ msgstr ""

#~ msgid ""
#~ "**indices** (*relay.Expr*) -- A 1-D "
#~ "tensor containing the index of each "
#~ "data element in the output tensor."
#~ msgstr ""

#~ msgid ""
#~ "**inverse_indices** (*relay.Expr*) -- A 1-D"
#~ " tensor. For each entry in data, "
#~ "it contains the index of that data"
#~ " element in the unique array."
#~ msgstr ""

#~ msgid ""
#~ "**num_unique** (*relay.Expr*) -- A 1-D "
#~ "tensor with size=1 containing the number"
#~ " of unique elements in the input "
#~ "data tensor."
#~ msgstr ""

#~ msgid ""
#~ "**counts (optional)** (*relay.Expr*) -- A "
#~ "1-D tensor containing the count of "
#~ "each unique element in the output."
#~ msgstr ""

#~ msgid ""
#~ "Example:: -   unravel_index([22, 41, 37], "
#~ "[7, 6]) = [[3, 6, 6],[4, 5, "
#~ "1]]"
#~ msgstr ""

#~ msgid "An integer array containing indices."
#~ msgstr ""

#~ msgid "The shape of the array."
#~ msgstr ""

#~ msgid "**result** -- The tuple of coordinate arrays."
#~ msgstr ""

#~ msgid ""
#~ "This is a simple wrapper function "
#~ "that allows specify shape and dtype "
#~ "directly."
#~ msgstr ""

#~ msgid ""
#~ "The name of the variable. This "
#~ "name only acts as a hint, and "
#~ "is not used for equality."
#~ msgstr ""

#~ msgid ""
#~ "The type annotation on the variable. "
#~ "When type_annotation is a str, we "
#~ "will create a scalar variable."
#~ msgstr ""

#~ msgid "The shape of the tensor type."
#~ msgstr ""

#~ msgid "The data type of the tensor."
#~ msgstr ""

#~ msgid ""
#~ "Axis or axes along which a "
#~ "variance operation is performed. The "
#~ "default, axis=None, will compute the "
#~ "variance of all elements in the "
#~ "input array. If axis is negative "
#~ "it counts from the last to the "
#~ "first axis."
#~ msgstr ""

#~ msgid ""
#~ "Shapes of condition, x, and y must"
#~ " be broadcastable to a common shape."
#~ " Semantics follow numpy where function "
#~ "https://numpy.org/doc/stable/reference/generated/numpy.where.html"
#~ msgstr ""

#~ msgid "Where True, yield x, otherwise yield y"
#~ msgstr ""

#~ msgid "The first array or scalar to be selected."
#~ msgstr ""

#~ msgid "The second array or scalar to be selected."
#~ msgstr ""

#~ msgid ""
#~ "**result** -- The selected array. The"
#~ " output shape is the broadcasted "
#~ "shape from condition, x, and y."
#~ msgstr ""

#~ msgid ":py:obj:`Constant <tvm.relay.Constant>`\\ \\(data\\[\\, span\\]\\)"
#~ msgstr ""

#~ msgid ":py:class:`~tvm.ir.expr.RelayExpr` 的别名"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`If <tvm.relay.If>`\\ \\(cond\\, "
#~ "true\\_branch\\, false\\_branch\\[\\, span\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`Let <tvm.relay.Let>`\\ \\(variable\\, "
#~ "value\\, body\\[\\, span\\]\\)"
#~ msgstr ""

#~ msgid ":py:obj:`RefCreate <tvm.relay.RefCreate>`\\ \\(value\\[\\, span\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Create a new reference from initial "
#~ "value. Parameters ---------- value: "
#~ "tvm.relay.Expr    The initial value."
#~ msgstr ""

#~ msgid ":py:obj:`RefRead <tvm.relay.RefRead>`\\ \\(ref\\[\\, span\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Get the value inside the reference. "
#~ "Parameters ---------- ref: tvm.relay.Expr      "
#~ "The reference."
#~ msgstr ""

#~ msgid ":py:class:`~tvm.ir.type.RelayRefType` 的别名"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`RefWrite <tvm.relay.RefWrite>`\\ \\(ref\\, "
#~ "value\\[\\, span\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Update the value inside the reference."
#~ " The whole expression will evaluate "
#~ "to an empty tuple. Parameters ----------"
#~ " ref: tvm.relay.Expr     The reference."
#~ msgstr ""

#~ msgid ":py:obj:`SequentialSpan <tvm.relay.SequentialSpan>`\\ \\(spans\\)"
#~ msgstr ""

#~ msgid "A sequence of source spans"
#~ msgstr ""

#~ msgid ":py:obj:`SpanCheck <tvm.relay.SpanCheck>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "A debugging utility for reporting missing span information."
#~ msgstr ""

#~ msgid ""
#~ "Performs sorting along the given axis"
#~ " and returns an array of indices "
#~ "having same shape as an input "
#~ "array that index data in sorted "
#~ "order."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`astext <tvm.relay.astext>`\\ \\(obj\\[\\, "
#~ "show\\_meta\\_data\\, annotate\\]\\)"
#~ msgstr ""

#~ msgid "Get the text format of the expression."
#~ msgstr ""

#~ msgid ""
#~ "Return a scalar value array with "
#~ "the same type, broadcasted to the "
#~ "provided shape."
#~ msgstr ""

#~ msgid ":py:obj:`const <tvm.relay.const>`\\ \\(value\\[\\, dtype\\, span\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`dft <tvm.relay.dft>`\\ \\(re\\_data\\, "
#~ "im\\_data\\[\\, inverse\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Computes the discrete Fourier transform "
#~ "of input (calculation along the last "
#~ "axis)."
#~ msgstr ""

#~ msgid ""
#~ "Gather elements or slices from data "
#~ "and store them to a tensor whose"
#~ " shape is defined by indices."
#~ msgstr ""

#~ msgid "Transform the layout of a tensor."
#~ msgstr ""

#~ msgid ""
#~ "Returns a one-hot tensor where the"
#~ " locations represented by indices take "
#~ "value on_value, and other locations take"
#~ " value off_value."
#~ msgstr ""

#~ msgid ":py:obj:`pretty_print <tvm.relay.pretty_print>`\\ \\(obj\\)"
#~ msgstr ""

#~ msgid "Pretty print the object."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`reshape <tvm.relay.reshape>`\\ \\(data\\, "
#~ "newshape\\[\\, allowzero\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`scatter_elements <tvm.relay.scatter_elements>`\\ "
#~ "\\(data\\, indices\\, updates\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Scatter elements with updating data by"
#~ " reduction of values in updates at"
#~ " positions defined by indices."
#~ msgstr ""

#~ msgid "Decorate a python function as hybrid script."
#~ msgstr ""

#~ msgid "Fill rows in a sparse matrix that do not contain any values."
#~ msgstr ""

#~ msgid "Reshape a sparse tensor."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`stft <tvm.relay.stft>`\\ \\(data\\, "
#~ "n\\_fft\\[\\, hop\\_length\\, win\\_length\\, "
#~ "...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "The STFT computes the Fourier transform"
#~ " of short overlapping windows of the"
#~ " input."
#~ msgstr ""

#~ msgid ":py:obj:`trilu <tvm.relay.trilu>`\\ \\(data\\, k\\[\\, upper\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Given a 2-D matrix or batches of"
#~ " 2-D matrices, returns the upper or"
#~ " lower triangular part of the tensor."
#~ msgstr ""

#~ msgid ":py:obj:`trunc_divide <tvm.relay.trunc_divide>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Trunc division with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ":py:obj:`trunc_mod <tvm.relay.trunc_mod>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Trunc mod with numpy-style broadcasting."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`var <tvm.relay.var>`\\ \\(name\\_hint\\[\\, "
#~ "type\\_annotation\\, shape\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Parameters"
#~ msgstr ""

#~ msgid "op: tvm.ir.Op or any tvm.relay.Expr with function type."
#~ msgstr ""

#~ msgid "args: List[tvm.relay.Expr]"
#~ msgstr ""

#~ msgid "attrs: Optional[tvm.Attrs]"
#~ msgstr ""

#~ msgid "type_args: Optional[List[tvm.relay.Type]]"
#~ msgstr ""

#~ msgid "span: Optional[tvm.relay.Span]"
#~ msgstr ""

#~ msgid "Span that points to original source code."
#~ msgstr ""

#~ msgid ":py:obj:`__init__ <tvm.relay.Clause.__init__>`\\ \\(lhs\\, rhs\\)"
#~ msgstr ""

#~ msgid "Construct a clause."
#~ msgstr ""

#~ msgid "lhs: tvm.relay.Pattern"
#~ msgstr ""

#~ msgid "Left-hand side of match clause."
#~ msgstr ""

#~ msgid "rhs: tvm.relay.Expr"
#~ msgstr ""

#~ msgid "Right-hand side of match clause."
#~ msgstr ""

#~ msgid "Returns"
#~ msgstr ""

#~ msgid "clause: Clause"
#~ msgstr ""

#~ msgid "The Clause."
#~ msgstr ""

#~ msgid "data"
#~ msgstr ""

#~ msgid "tvm.nd.NDArray"
#~ msgstr ""

#~ msgid ":py:obj:`struct_info <tvm.relay.Expr.struct_info>`\\"
#~ msgstr ""

#~ msgid "Get the struct info field"
#~ msgstr ""

#~ msgid "params: List[tvm.relay.Var]"
#~ msgstr ""

#~ msgid "body: tvm.relay.Expr"
#~ msgstr ""

#~ msgid "ret_type: Optional[tvm.relay.Type]"
#~ msgstr ""

#~ msgid "type_params: Optional[List[tvm.relay.TypeParam]]"
#~ msgstr ""

#~ msgid ":py:obj:`__call__ <tvm.relay.Function.__call__>`\\ \\(\\*args\\)"
#~ msgstr ""

#~ msgid "Invoke the global function."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`astext <tvm.relay.Function.astext>`\\ "
#~ "\\(\\[show\\_meta\\_data\\, annotate\\]\\)"
#~ msgstr ""

#~ msgid "args: List[relay.Expr]"
#~ msgstr ""

#~ msgid "Arguments."
#~ msgstr ""

#~ msgid "show_meta_data"
#~ msgstr ""

#~ msgid "bool"
#~ msgstr ""

#~ msgid "Whether to include meta data section in the text if there is meta data."
#~ msgstr ""

#~ msgid "annotate: Optional[Object->str]"
#~ msgstr ""

#~ msgid ""
#~ "Optionally annotate function to provide "
#~ "additional information in the comment "
#~ "block."
#~ msgstr ""

#~ msgid "text"
#~ msgstr ""

#~ msgid "str"
#~ msgstr ""

#~ msgid "The text format of the expression."
#~ msgstr ""

#~ msgid "Notes"
#~ msgstr ""

#~ msgid ""
#~ "The meta data section is necessary "
#~ "to fully parse the text format. "
#~ "However, it can contain dumps that "
#~ "are big (e.g constant weights), so "
#~ "it can be helpful to skip printing"
#~ " the meta data section."
#~ msgstr ""

#~ msgid "cond: tvm.relay.Expr"
#~ msgstr ""

#~ msgid "true_branch: tvm.relay.Expr"
#~ msgstr ""

#~ msgid "false_branch: tvm.relay.Expr"
#~ msgstr ""

#~ msgid "variable: tvm.relay.Var"
#~ msgstr ""

#~ msgid "value: tvm.relay.Expr"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`__init__ <tvm.relay.Match.__init__>`\\ \\(data\\,"
#~ " clauses\\[\\, complete\\]\\)"
#~ msgstr ""

#~ msgid "Construct a Match."
#~ msgstr ""

#~ msgid "data: tvm.relay.Expr"
#~ msgstr ""

#~ msgid "The value being deconstructed and matched."
#~ msgstr ""

#~ msgid "clauses: List[tvm.relay.Clause]"
#~ msgstr ""

#~ msgid "The pattern match clauses."
#~ msgstr ""

#~ msgid "complete: Optional[Bool]"
#~ msgstr ""

#~ msgid ""
#~ "Should the match be complete (cover "
#~ "all cases)? If yes, the type "
#~ "checker will generate an error if "
#~ "there are any missing cases."
#~ msgstr ""

#~ msgid "match: tvm.relay.Expr"
#~ msgstr ""

#~ msgid "The match expression."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`__init__ <tvm.relay.PatternConstructor.__init__>`\\ "
#~ "\\(constructor\\[\\, patterns\\]\\)"
#~ msgstr ""

#~ msgid "Construct a constructor pattern."
#~ msgstr ""

#~ msgid "constructor: Constructor"
#~ msgstr ""

#~ msgid "The constructor."
#~ msgstr ""

#~ msgid "patterns: Optional[List[Pattern]]"
#~ msgstr ""

#~ msgid ""
#~ "Optional subpatterns: for each field of"
#~ " the constructor, match to the given"
#~ " subpattern (treated as a variable "
#~ "pattern by default)."
#~ msgstr ""

#~ msgid "wildcard: PatternWildcard"
#~ msgstr ""

#~ msgid "a wildcard pattern."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`__init__ <tvm.relay.PatternTuple.__init__>`\\ "
#~ "\\(\\[patterns\\]\\)"
#~ msgstr ""

#~ msgid "Construct a tuple pattern."
#~ msgstr ""

#~ msgid ":py:obj:`__init__ <tvm.relay.PatternVar.__init__>`\\ \\(var\\)"
#~ msgstr ""

#~ msgid "Construct a variable pattern."
#~ msgstr ""

#~ msgid "var: tvm.relay.Var"
#~ msgstr ""

#~ msgid "pv: PatternVar"
#~ msgstr ""

#~ msgid "A variable pattern."
#~ msgstr ""

#~ msgid ":py:obj:`__init__ <tvm.relay.PatternWildcard.__init__>`\\ \\(\\)"
#~ msgstr ""

#~ msgid "Constructs a wildcard pattern."
#~ msgstr ""

#~ msgid "None"
#~ msgstr ""

#~ msgid ""
#~ "Create a new reference from initial "
#~ "value. Parameters ---------- value: "
#~ "tvm.relay.Expr"
#~ msgstr ""

#~ msgid "The initial value."
#~ msgstr ""

#~ msgid ""
#~ "Get the value inside the reference. "
#~ "Parameters ---------- ref: tvm.relay.Expr"
#~ msgstr ""

#~ msgid "The reference."
#~ msgstr ""

#~ msgid ""
#~ "Update the value inside the reference."
#~ " The whole expression will evaluate "
#~ "to an empty tuple. Parameters ----------"
#~ " ref: tvm.relay.Expr"
#~ msgstr ""

#~ msgid "The new value."
#~ msgstr ""

#~ msgid "Examples"
#~ msgstr ""

#~ msgid "scope: WithScope"
#~ msgstr ""

#~ msgid "The if scope."
#~ msgstr ""

#~ msgid "value: tvm.relay.expr.Expr"
#~ msgstr ""

#~ msgid "The final result of the expression."
#~ msgstr ""

#~ msgid "cond: tvm.relay.expr.Expr"
#~ msgstr ""

#~ msgid "Note"
#~ msgstr ""

#~ msgid "var: Union[Tuple[str, relay.Type], tvm.relay.Var]"
#~ msgstr ""

#~ msgid "expr: relay.Expr"
#~ msgstr ""

#~ msgid ""
#~ "This span is specific for an "
#~ "expression, which is from multiple "
#~ "expressions after an IR transform."
#~ msgstr ""

#~ msgid "spans"
#~ msgstr ""

#~ msgid "Array"
#~ msgstr ""

#~ msgid "The array of spans."
#~ msgstr ""

#~ msgid "name : str"
#~ msgstr ""

#~ msgid "type_var"
#~ msgstr ""

#~ msgid "tvm.relay.TypeVar"
#~ msgstr ""

#~ msgid "The shape variable."
#~ msgstr ""

#~ msgid "fields"
#~ msgstr ""

#~ msgid "List[tvm.relay.Expr]"
#~ msgstr ""

#~ msgid "dtype"
#~ msgstr ""

#~ msgid "result"
#~ msgstr ""

#~ msgid "tvm.relay.Expr"
#~ msgstr ""

#~ msgid "The result expression."
#~ msgstr ""

#~ msgid "tuple_value: tvm.relay.Expr"
#~ msgstr ""

#~ msgid "index: int"
#~ msgstr ""

#~ msgid "size: int"
#~ msgstr ""

#~ msgid "The text format of the tuple expression."
#~ msgstr ""

#~ msgid "header: GlobalTypeVar"
#~ msgstr ""

#~ msgid "type_vars: List[TypeVar]"
#~ msgstr ""

#~ msgid "constructors: List[Constructor]"
#~ msgstr ""

#~ msgid "relay.Expr"
#~ msgstr ""

#~ msgid "The computed result."
#~ msgstr ""

#~ msgid "lhs"
#~ msgstr ""

#~ msgid "rhs"
#~ msgstr ""

#~ msgid "inputs"
#~ msgstr ""

#~ msgid "Union(List[relay.Expr], Tuple[relay.Expr])"
#~ msgstr ""

#~ msgid ""
#~ "Input tensor and indices. The first "
#~ "tensor is the input data and the"
#~ " rest are the indices."
#~ msgstr ""

#~ msgid "Output tensor."
#~ msgstr ""

#~ msgid "axis"
#~ msgstr ""

#~ msgid "None or int or tuple of int"
#~ msgstr ""

#~ msgid "keepdims"
#~ msgstr ""

#~ msgid "exclude"
#~ msgstr ""

#~ msgid ""
#~ "Similar to ``numpy.arange``. When only "
#~ "one argument is given, it is used"
#~ " as `stop` instead of `start` while"
#~ " `start` takes default value 0."
#~ msgstr ""

#~ msgid "start"
#~ msgstr ""

#~ msgid "relay.Expr, optional"
#~ msgstr ""

#~ msgid "stop"
#~ msgstr ""

#~ msgid "step"
#~ msgstr ""

#~ msgid "str, optional"
#~ msgstr ""

#~ msgid "The resulting tensor."
#~ msgstr ""

#~ msgid "select_last_index"
#~ msgstr ""

#~ msgid "valid_count"
#~ msgstr ""

#~ msgid "tvm.te.Tensor"
#~ msgstr ""

#~ msgid "int, optional"
#~ msgstr ""

#~ msgid "is_ascend"
#~ msgstr ""

#~ msgid "boolean, optional"
#~ msgstr ""

#~ msgid "string, optional"
#~ msgstr ""

#~ msgid "out"
#~ msgstr ""

#~ msgid "Tensor with same shape as data."
#~ msgstr ""

#~ msgid "condition"
#~ msgstr ""

#~ msgid "Tensor with the indices of elements that are non-zero."
#~ msgstr ""

#~ msgid "obj"
#~ msgstr ""

#~ msgid "Object"
#~ msgstr ""

#~ msgid "The object to be printed."
#~ msgstr ""

#~ msgid "expr"
#~ msgstr ""

#~ msgid "binds"
#~ msgstr ""

#~ msgid "Map[tvm.relay.Var, tvm.relay.Expr]"
#~ msgstr ""

#~ msgid "The expression or function after binding."
#~ msgstr ""

#~ msgid "shape"
#~ msgstr ""

#~ msgid "tuple of int or relay.Expr"
#~ msgstr ""

#~ msgid "broadcast_type"
#~ msgstr ""

#~ msgid "ir_mod : :py:class:`~tvm.IRModule`"
#~ msgstr ""

#~ msgid "IRModule"
#~ msgstr ""

#~ msgid "target"
#~ msgstr ""

#~ msgid "None, or any multi-target like object, see Target.canon_multi_target"
#~ msgstr ""

#~ msgid ""
#~ "For homogeneous compilation, the unique "
#~ "build target. For heterogeneous compilation,"
#~ " a dictionary or list of possible "
#~ "build targets. Defaults to the current"
#~ " target in the environment if None."
#~ msgstr ""

#~ msgid "target_host"
#~ msgstr ""

#~ msgid "None, or any target like object, see Target.canon_target"
#~ msgstr ""

#~ msgid "Host compilation target, if target is device."
#~ msgstr ""

#~ msgid "executor"
#~ msgstr ""

#~ msgid "Optional[Executor]"
#~ msgstr ""

#~ msgid "runtime"
#~ msgstr ""

#~ msgid "Optional[Runtime]"
#~ msgstr ""

#~ msgid "workspace_memory_pools"
#~ msgstr ""

#~ msgid "Optional[WorkspaceMemoryPools]"
#~ msgstr ""

#~ msgid ""
#~ "The object that contains an Array "
#~ "of WorkspacePoolInfo objects that hold "
#~ "properties of read-write workspace pools"
#~ " that could be used by the "
#~ "inference."
#~ msgstr ""

#~ msgid "constant_memory_pools"
#~ msgstr ""

#~ msgid "Optional[ConstantMemoryPools]"
#~ msgstr ""

#~ msgid ""
#~ "The object that contains an Array "
#~ "of ConstantPoolInfo objects that hold "
#~ "properties of read-only pools that "
#~ "could be used by the inference."
#~ msgstr ""

#~ msgid "params"
#~ msgstr ""

#~ msgid "dict of str to NDArray"
#~ msgstr ""

#~ msgid "mod_name: Optional[str]"
#~ msgstr ""

#~ msgid "factory_module"
#~ msgstr ""

#~ msgid "tvm.relay.backend.executor_factory.ExecutorFactoryModule"
#~ msgstr ""

#~ msgid "The runtime factory for the TVM graph executor."
#~ msgstr ""

#~ msgid "opt_level: int, optional"
#~ msgstr ""

#~ msgid "required_pass: set of str, optional"
#~ msgstr ""

#~ msgid "disabled_pass: set of str, optional"
#~ msgstr ""

#~ msgid "trace: Callable[[IRModule, PassInfo, bool], None]"
#~ msgstr ""

#~ msgid "pass_context: PassContext"
#~ msgstr ""

#~ msgid "The pass context for optimizations."
#~ msgstr ""

#~ msgid "The casted result."
#~ msgstr ""

#~ msgid "dtype_like"
#~ msgstr ""

#~ msgid "a"
#~ msgstr ""

#~ msgid "a_min"
#~ msgstr ""

#~ msgid "float"
#~ msgstr ""

#~ msgid "a_max"
#~ msgstr ""

#~ msgid "`a` with elements clipped between `a_min` and `a_max`."
#~ msgstr ""

#~ msgid "collapse_type"
#~ msgstr ""

#~ msgid "Provide the shape to collapse to."
#~ msgstr ""

#~ msgid "result: relay.Expr"
#~ msgstr ""

#~ msgid "The concatenated tensor."
#~ msgstr ""

#~ msgid "value: Union[bool, int, float, numpy.ndarray, tvm.nd.NDArray]"
#~ msgstr ""

#~ msgid "dtype: str, optional"
#~ msgstr ""

#~ msgid "The copied result."
#~ msgstr ""

#~ msgid "Example"
#~ msgstr ""

#~ msgid "kind"
#~ msgstr ""

#~ msgid ""
#~ "The type of executor. Avaliable options"
#~ " are `debug` for the interpreter, "
#~ "`graph` for the graph executor, `aot`"
#~ " for the aot executor, and `vm` "
#~ "for the virtual machine."
#~ msgstr ""

#~ msgid "mod : :py:class:`~tvm.IRModule`"
#~ msgstr ""

#~ msgid "device : :py:class:`Device`"
#~ msgstr ""

#~ msgid "Device"
#~ msgstr ""

#~ msgid "any multi-target like object, see Target.canon_multi_target"
#~ msgstr ""

#~ msgid ""
#~ "For homogeneous compilation, the unique "
#~ "build target. For heterogeneous compilation,"
#~ " a dictionary or list of possible "
#~ "build targets. CAUTION: Though this API"
#~ " allows multiple targets, it does not"
#~ " allow multiple devices, so heterogenous"
#~ " compilation is not yet supported."
#~ msgstr ""

#~ msgid "executor : :py:class:`~tvm.relay.backend.interpreter.Executor`"
#~ msgstr ""

#~ msgid "exclusive"
#~ msgstr ""

#~ msgid "bool, optional"
#~ msgstr ""

#~ msgid ""
#~ "The result has the same size as"
#~ " data, and the same shape as "
#~ "data if axis is not None. If "
#~ "axis is None, the result is a "
#~ "1-d array."
#~ msgstr ""

#~ msgid "src_device : Union[:py:class:`Device`, str]"
#~ msgstr ""

#~ msgid "Union["
#~ msgstr ""

#~ msgid "dst_device : Union[:py:class:`Device`, str]"
#~ msgstr ""

#~ msgid ""
#~ "Computes the discrete Fourier transform "
#~ "of input (calculation along the last "
#~ "axis). This gives frequency components "
#~ "of the signal as they change over"
#~ " time."
#~ msgstr ""

#~ msgid "re_data"
#~ msgstr ""

#~ msgid "N-D tensor, real part of the input signal."
#~ msgstr ""

#~ msgid "im_data"
#~ msgstr ""

#~ msgid ""
#~ "N-D tensor, imaginary part of the "
#~ "input signal. If the signal is "
#~ "real, then the values of this "
#~ "tensor are zeros."
#~ msgstr ""

#~ msgid "inverse"
#~ msgstr ""

#~ msgid "Whether to perform the inverse discrete fourier transform."
#~ msgstr ""

#~ msgid "re_output"
#~ msgstr ""

#~ msgid "The Fourier Transform of the input (Real part)."
#~ msgstr ""

#~ msgid "im_output"
#~ msgstr ""

#~ msgid "The Fourier Transform of the input (Imaginary part)."
#~ msgstr ""

#~ msgid "equation"
#~ msgstr ""

#~ msgid "The output tensor from the einsum op."
#~ msgstr ""

#~ msgid "Union[int, Expr]"
#~ msgstr ""

#~ msgid "num_newaxis"
#~ msgstr ""

#~ msgid "The reshaped result."
#~ msgstr ""

#~ msgid "multiplier"
#~ msgstr ""

#~ msgid "shift"
#~ msgstr ""

#~ msgid "The output of the fixed point multiplication"
#~ msgstr ""

#~ msgid "fill_value"
#~ msgstr ""

#~ msgid "tuple of int or relay.Expr, optional"
#~ msgstr ""

#~ msgid "data type, optional (defaults to data type of the fill value)"
#~ msgstr ""

#~ msgid ""
#~ "``indices`` must have the same shape "
#~ "as ``data``, except at dimension "
#~ "``axis`` which must just be not "
#~ "null. Output will have the same "
#~ "shape as ``indices``."
#~ msgstr ""

#~ msgid "The axis along which to index. Negative axis is supported."
#~ msgstr ""

#~ msgid "indices"
#~ msgstr ""

#~ msgid "batch_dims"
#~ msgstr ""

#~ msgid "index_rank"
#~ msgstr ""

#~ msgid ""
#~ "The size of an indexing tuple, "
#~ "which is a fixed value and the "
#~ "same as indices.shape[0]. Only needed "
#~ "when other dimensions of indices are "
#~ "dynamic."
#~ msgstr ""

#~ msgid "ret"
#~ msgstr ""

#~ msgid "The source data to be invert permuted."
#~ msgstr ""

#~ msgid "Invert permuted data. Has the same type as data."
#~ msgstr ""

#~ msgid "The source tensor to be transformed."
#~ msgstr ""

#~ msgid "src_layout"
#~ msgstr ""

#~ msgid "dst_layout"
#~ msgstr ""

#~ msgid "The transformed tensor."
#~ msgstr ""

#~ msgid "param_bytes: bytearray"
#~ msgstr ""

#~ msgid "Input tensor."
#~ msgstr ""

#~ msgid "diagonal"
#~ msgstr ""

#~ msgid "k"
#~ msgstr ""

#~ msgid "int or tuple of int, optional"
#~ msgstr ""

#~ msgid ""
#~ "Diagonal offset(s). The diagonal or "
#~ "range of diagonals to set. (0 by"
#~ " default) Positive value means "
#~ "superdiagonal, 0 refers to the main "
#~ "diagonal, and negative value means "
#~ "subdiagonals. k can be a single "
#~ "integer (for a single diagonal) or "
#~ "a pair of integers specifying the "
#~ "low and high ends of a matrix "
#~ "band. k[0] must not be larger than"
#~ " k[1]."
#~ msgstr ""

#~ msgid "align"
#~ msgstr ""

#~ msgid "New tensor with given diagonal values."
#~ msgstr ""

#~ msgid "unbiased"
#~ msgstr ""

#~ msgid "indexing"
#~ msgstr ""

#~ msgid "relay.Tuple([relay.Expr, relay.Expr])"
#~ msgstr ""

#~ msgid "The number of elements of input tensor."
#~ msgstr ""

#~ msgid ""
#~ "Returns a one-hot tensor where the"
#~ " locations represented by indices take "
#~ "value on_value, and other locations take"
#~ " value off_value. Final dimension is "
#~ "<indices outer dimensions> x depth x "
#~ "<indices inner dimensions>."
#~ msgstr ""

#~ msgid "on_value"
#~ msgstr ""

#~ msgid "off_value"
#~ msgstr ""

#~ msgid "depth"
#~ msgstr ""

#~ msgid "int or relay.Expr"
#~ msgstr ""

#~ msgid "The one-hot tensor."
#~ msgstr ""

#~ msgid "data type"
#~ msgstr ""

#~ msgid "The optimized relay module."
#~ msgstr ""

#~ msgid "dict"
#~ msgstr ""

#~ msgid "The parameters of the final graph."
#~ msgstr ""

#~ msgid "The reinterpreted result."
#~ msgstr ""

#~ msgid ""
#~ "Note: If the parameter allowzero is "
#~ "manually set to true, it specifies "
#~ "a special case where 0 actually "
#~ "means a true empty tensor."
#~ msgstr ""

#~ msgid "newshape"
#~ msgstr ""

#~ msgid "Union[int, Tuple[int], List[int]] or relay.Expr"
#~ msgstr ""

#~ msgid "allowzero"
#~ msgstr ""

#~ msgid "Bool, optional"
#~ msgstr ""

#~ msgid ""
#~ "If true, then treat zero as true"
#~ " empty tensor rather than a copy "
#~ "instruction."
#~ msgstr ""

#~ msgid "shape_like"
#~ msgstr ""

#~ msgid "lhs_begin"
#~ msgstr ""

#~ msgid "lhs_end"
#~ msgstr ""

#~ msgid "int or None, optional"
#~ msgstr ""

#~ msgid "rhs_begin"
#~ msgstr ""

#~ msgid "rhs_end"
#~ msgstr ""

#~ msgid "Union[int, Tuple[int], List[int]]"
#~ msgstr ""

#~ msgid "seq_lengths"
#~ msgstr ""

#~ msgid ""
#~ "A 1D Tensor with length "
#~ "a.dims[batch_axis]. Must be one of the"
#~ " following types: int32, int64. If "
#~ "seq_lengths[i] > a.dims[seq_axis], it is "
#~ "rounded to a.dims[seq_axis]. If seq_lengths[i]"
#~ " < 1, it is rounded to 1."
#~ msgstr ""

#~ msgid "seq_axis"
#~ msgstr ""

#~ msgid "batch_axis"
#~ msgstr ""

#~ msgid "The computed result of same shape and type as of input."
#~ msgstr ""

#~ msgid "s_type"
#~ msgstr ""

#~ msgid "tvm.relay.TensorType"
#~ msgstr ""

#~ msgid "The result type."
#~ msgstr ""

#~ msgid "updates"
#~ msgstr ""

#~ msgid "The axis to scatter elements on. It is zero by default."
#~ msgstr ""

#~ msgid "reduction"
#~ msgstr ""

#~ msgid ""
#~ "The reduction mode for scatter. Choise"
#~ " is from [\"update\", \"add\", \"mul\", "
#~ "\"mean\", \"min\", max\"] If update, the"
#~ " update values will replace the input"
#~ " data If add, the update values "
#~ "will be added to the input data"
#~ " If mul, the input data will be"
#~ " multiplied on the update values If"
#~ " mean, the input data will be "
#~ "mean between the update values and "
#~ "the input data If min, there is"
#~ " choice of minimal between the update"
#~ " values and the input data If "
#~ "max, there is choice of maximal "
#~ "between the update values and the "
#~ "input data It is \"update\" by "
#~ "default"
#~ msgstr ""

#~ msgid "mode"
#~ msgstr ""

#~ msgid ""
#~ "The accumulation mode for scatter. "
#~ "\"update\", \"add\", \"mul\", \"min\" or "
#~ "\"max\" If update, the update values "
#~ "will replace the input data If "
#~ "add, the update values will be "
#~ "added to the input data If mul,"
#~ " the update values will be multiply"
#~ " to the input data If min, "
#~ "there is choice of minimal between "
#~ "the update values and the input "
#~ "data If max, there is choice of"
#~ " maximal between the update values "
#~ "and the input data It is "
#~ "\"update\" by default"
#~ msgstr ""

#~ msgid "hybrid_func"
#~ msgstr ""

#~ msgid "function"
#~ msgstr ""

#~ msgid "A decorated hybrid script function."
#~ msgstr ""

#~ msgid "sorted_sequence"
#~ msgstr ""

#~ msgid "values"
#~ msgstr ""

#~ msgid "right"
#~ msgstr ""

#~ msgid ""
#~ "Tensor with same shape as values, "
#~ "representing the indices of elements of"
#~ " `values` if they are inserted in "
#~ "`sorted_sequence`."
#~ msgstr ""

#~ msgid "Input tensor. It can be of any type and multi-dimensional."
#~ msgstr ""

#~ msgid "segment_ids"
#~ msgstr ""

#~ msgid ""
#~ "A 1-D int32/int64 tensor containing the"
#~ " segment_ids of the rows to calculate"
#~ " the output sum upon. It defines "
#~ "a mapping from the zeroth dimension "
#~ "of data onto segment_ids. The "
#~ "segment_ids tensor should be the size"
#~ " of the first dimension, d0, with "
#~ "consecutive IDs in the range 0 to"
#~ " k, where k<d0. In particular, a "
#~ "segmentation of a matrix tensor is "
#~ "a mapping of rows to segments. "
#~ "This tensor doesn't need to be "
#~ "sorted."
#~ msgstr ""

#~ msgid "num_segments"
#~ msgstr ""

#~ msgid ""
#~ "An integer describing the shape of "
#~ "the zeroth dimension. If unspecified, it"
#~ " is calculated equivalent to the "
#~ "number of unique segment_ids."
#~ msgstr ""

#~ msgid "valid_length"
#~ msgstr ""

#~ msgid "mask_value"
#~ msgstr ""

#~ msgid "float, optional"
#~ msgstr ""

#~ msgid "The shape tensor."
#~ msgstr ""

#~ msgid ""
#~ "For an input array with shape "
#~ "``(d1, d2, ..., dk)``, `slice_like` "
#~ "operation slices the input array "
#~ "corresponding to the size of the "
#~ "second array. By default will slice "
#~ "on all axes."
#~ msgstr ""

#~ msgid "An array based on which shape, the result shape is computed."
#~ msgstr ""

#~ msgid "axes"
#~ msgstr ""

#~ msgid "Tuple[int] or List[int], optional"
#~ msgstr ""

#~ msgid "window_shape"
#~ msgstr ""

#~ msgid "List[int]"
#~ msgstr ""

#~ msgid "strides"
#~ msgstr ""

#~ msgid ""
#~ "Fill rows in a sparse matrix that"
#~ " do not contain any values. Values"
#~ " are placed in the first column "
#~ "of empty rows. The sparse array is"
#~ " in COO format. It returns a "
#~ "TupleWrapper with 3 outputs."
#~ msgstr ""

#~ msgid "sparse_indices"
#~ msgstr ""

#~ msgid ""
#~ "A 2-D tensor[N, ndims] of integers "
#~ "containing the locations of sparse "
#~ "values, where N is the number of"
#~ " sparse values and n_dim is the "
#~ "number of dimensions of the dense_shape."
#~ " The first column of this parameter"
#~ " must be sorted in ascending order."
#~ msgstr ""

#~ msgid "sparse_values"
#~ msgstr ""

#~ msgid "dense_shape"
#~ msgstr ""

#~ msgid ""
#~ "A 1-D tensor[ndims] which contains the"
#~ " shape of the dense output tensor."
#~ msgstr ""

#~ msgid "default_value"
#~ msgstr ""

#~ msgid "new_sparse_indices"
#~ msgstr ""

#~ msgid ""
#~ "A 2-D tensor[?, ndims] of integers "
#~ "containing location of new sparse "
#~ "indices. The first column outputs must"
#~ " be sorted in ascending order."
#~ msgstr ""

#~ msgid "new_sparse_values"
#~ msgstr ""

#~ msgid "A 1-D tensor[?] containing the sparse values for the sparse indices."
#~ msgstr ""

#~ msgid "empty_row_indicator"
#~ msgstr ""

#~ msgid ""
#~ "A 1-D tensor[dense_shape[0]] filled with "
#~ "zeros and ones indicating whether the"
#~ " particular row is empty or full "
#~ "respectively."
#~ msgstr ""

#~ msgid "Reshape a sparse tensor. The sparse array is in COO format."
#~ msgstr ""

#~ msgid ""
#~ "A 2-D tensor[N, n_dim] of integers "
#~ "containing location of sparse values, "
#~ "where N is the number of sparse"
#~ " values and n_dim is the number "
#~ "of dimensions of the dense_shape."
#~ msgstr ""

#~ msgid "prev_shape"
#~ msgstr ""

#~ msgid "A 1-D tensor containing the previous shape of the dense tensor."
#~ msgstr ""

#~ msgid "new_shape"
#~ msgstr ""

#~ msgid "A 1-D tensor containing the new shape of the dense tensor."
#~ msgstr ""

#~ msgid "output_shape"
#~ msgstr ""

#~ msgid "Dense tensor of shape output_shape. Has the same type as sparse_values."
#~ msgstr ""

#~ msgid "indices_or_sections"
#~ msgstr ""

#~ msgid "int or tuple of int"
#~ msgstr ""

#~ msgid "Indices or sections to split into. Accepts an int or a tuple."
#~ msgstr ""

#~ msgid "Union[None, int, Tuple[int], List[int]] or Expr"
#~ msgstr ""

#~ msgid ""
#~ "The set of axes to remove. If "
#~ "axis = None, remove all axes of"
#~ " dimension 1. If any specified axis"
#~ " has dimension that does not equal"
#~ " 1, it is an error."
#~ msgstr ""

#~ msgid "The squeezed result."
#~ msgstr ""

#~ msgid "Union(List[relay.Expr], relay.Expr)"
#~ msgstr ""

#~ msgid "The stacked tensor."
#~ msgstr ""

#~ msgid ""
#~ "The STFT computes the Fourier transform"
#~ " of short overlapping windows of the"
#~ " input. This gives frequency components "
#~ "of the signal as they change over"
#~ " time."
#~ msgstr ""

#~ msgid "Either a 1-D tensor or a 2-D batch tensor."
#~ msgstr ""

#~ msgid "n_fft"
#~ msgstr ""

#~ msgid "The size of Fourier transform."
#~ msgstr ""

#~ msgid "hop_length"
#~ msgstr ""

#~ msgid ""
#~ "The distance between neighboring sliding "
#~ "window frames. If is None, it is"
#~ " treated as equal to floor(n_fft /"
#~ " 4)."
#~ msgstr ""

#~ msgid "win_length"
#~ msgstr ""

#~ msgid ""
#~ "The size of window frame and STFT"
#~ " filter. If is None, it is "
#~ "treated as equal to n_fft."
#~ msgstr ""

#~ msgid "window"
#~ msgstr ""

#~ msgid ""
#~ "A 1-D tensor window frame. If is"
#~ " None (default), it is treated as "
#~ "if having 1 everywhere in the "
#~ "window."
#~ msgstr ""

#~ msgid "normalized"
#~ msgstr ""

#~ msgid "Whether to return the normalized STFT results. Default value is False."
#~ msgstr ""

#~ msgid "onesided"
#~ msgstr ""

#~ msgid ""
#~ "Whether to return onesided result or "
#~ "fill with conjugate symmetry. Default "
#~ "value is True."
#~ msgstr ""

#~ msgid "output"
#~ msgstr ""

#~ msgid ""
#~ "Tensor containing the STFT result with"
#~ " shape [batch, N, T, 2], where "
#~ "N is the number of frequencies "
#~ "where STFT is applied and T is "
#~ "the total number of frames used."
#~ msgstr ""

#~ msgid "v"
#~ msgstr ""

#~ msgid "begin"
#~ msgstr ""

#~ msgid "relay.Expr, Tuple[int], or List[int]"
#~ msgstr ""

#~ msgid "end"
#~ msgstr ""

#~ msgid "strides: relay.Expr, Tuple[int], or List[int], optional"
#~ msgstr ""

#~ msgid ""
#~ "Specifies the stride values. It can "
#~ "be negative. In that case, the "
#~ "input tensor will be reversed in "
#~ "that particular axis."
#~ msgstr ""

#~ msgid "relay.Expr, Tuple[int], or List[int], optional"
#~ msgstr ""

#~ msgid "slice_mode"
#~ msgstr ""

#~ msgid ""
#~ "The slice mode [end, size]. end: "
#~ "The ending indices for the slice "
#~ "[default]. size: The input strides will"
#~ " be ignored. Input end in this "
#~ "mode indicates the size of a slice"
#~ " starting at the location specified "
#~ "by begin. If end[i] is -1, all "
#~ "remaining elements in that dimension are"
#~ " included in the slice."
#~ msgstr ""

#~ msgid "reps"
#~ msgstr ""

#~ msgid "int or relay.Expr, optional"
#~ msgstr ""

#~ msgid "ret_type: str, optional"
#~ msgstr ""

#~ msgid "relay.Expr or List[relay.Expr]"
#~ msgstr ""

#~ msgid "None or List[int]"
#~ msgstr ""

#~ msgid "The transposed result."
#~ msgstr ""

#~ msgid ""
#~ "The tensor that trilu will be "
#~ "applied to. Must be either a 2D"
#~ " matrix or a tensor of batches "
#~ "of 2D matrices."
#~ msgstr ""

#~ msgid ""
#~ "The number of diagonals above or "
#~ "below the main diagonal to exclude "
#~ "or include."
#~ msgstr ""

#~ msgid "upper: bool, optional"
#~ msgstr ""

#~ msgid ""
#~ "If True, only upper triangular values"
#~ " of input are kept, if False, "
#~ "the lower triangular values are kept."
#~ msgstr ""

#~ msgid "The new tensor with appropriate diagonals set to zero."
#~ msgstr ""

#~ msgid "is_sorted"
#~ msgstr ""

#~ msgid "return_counts"
#~ msgstr ""

#~ msgid "unique"
#~ msgstr ""

#~ msgid "A 1-D tensor containing the unique elements of the input data tensor."
#~ msgstr ""

#~ msgid ""
#~ "A 1-D tensor containing the indeces "
#~ "of the first occurence of each "
#~ "unique value in the input tensor."
#~ msgstr ""

#~ msgid "inverse_indices"
#~ msgstr ""

#~ msgid ""
#~ "A 1-D tensor. For each entry in"
#~ " data, it contains the index of "
#~ "that data element in the unique "
#~ "array."
#~ msgstr ""

#~ msgid "num_unique"
#~ msgstr ""

#~ msgid ""
#~ "A 1-D tensor with size=1 containing "
#~ "the number of unique elements in "
#~ "the input data tensor."
#~ msgstr ""

#~ msgid "counts"
#~ msgstr ""

#~ msgid "A 1-D tensor containing the count of each unique element in the output."
#~ msgstr ""

#~ msgid "The tuple of coordinate arrays."
#~ msgstr ""

#~ msgid "name_hint: str"
#~ msgstr ""

#~ msgid "type_annotation: Optional[tvm.relay.Type, str]"
#~ msgstr ""

#~ msgid "shape: Optional[List[tvm.Expr]]"
#~ msgstr ""

#~ msgid "with_mean"
#~ msgstr ""

#~ msgid "Optional[relay.Expr]"
#~ msgstr ""

#~ msgid "To compute variance given an already computed mean"
#~ msgstr ""

#~ msgid "x"
#~ msgstr ""

#~ msgid "y"
#~ msgstr ""

#~ msgid ""
#~ "The selected array. The output shape "
#~ "is the broadcasted shape from condition,"
#~ " x, and y."
#~ msgstr ""


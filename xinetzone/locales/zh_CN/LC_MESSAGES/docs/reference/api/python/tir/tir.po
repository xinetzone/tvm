# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-09-17 13:18+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../doc/docs/reference/api/python/tir/tir.rst:19
msgid "tvm.tir"
msgstr ""

#: of tvm.tir:1
msgid "Namespace for Tensor-level IR"
msgstr ""

#: of tvm.tir.expr.Add:1
msgid "Add node."
msgstr ""

#: ../../doc/docs/reference/api/python/tir/tir.rst
msgid "参数"
msgstr ""

#: of tvm.tir.expr.Add:3 tvm.tir.expr.And:3 tvm.tir.expr.Div:3
#: tvm.tir.expr.EQ:3 tvm.tir.expr.FloorDiv:3 tvm.tir.expr.FloorMod:3
#: tvm.tir.expr.GE:3 tvm.tir.expr.GT:3 tvm.tir.expr.LE:3 tvm.tir.expr.LT:3
#: tvm.tir.expr.Max:3 tvm.tir.expr.Min:3 tvm.tir.expr.Mod:3 tvm.tir.expr.Mul:3
#: tvm.tir.expr.NE:3 tvm.tir.expr.Or:3 tvm.tir.expr.Sub:3
msgid "The left hand operand."
msgstr ""

#: of tvm.tir.expr.Add:5 tvm.tir.expr.And:5 tvm.tir.expr.Div:5
#: tvm.tir.expr.EQ:5 tvm.tir.expr.FloorDiv:5 tvm.tir.expr.FloorMod:5
#: tvm.tir.expr.GE:5 tvm.tir.expr.GT:5 tvm.tir.expr.LE:5 tvm.tir.expr.LT:5
#: tvm.tir.expr.Max:5 tvm.tir.expr.Min:5 tvm.tir.expr.Mod:5 tvm.tir.expr.Mul:5
#: tvm.tir.expr.NE:5 tvm.tir.expr.Or:5 tvm.tir.expr.Sub:5
msgid "The right hand operand."
msgstr ""

#: of tvm.tir.expr.Add:7 tvm.tir.expr.And:7 tvm.tir.expr.Broadcast:7
#: tvm.tir.expr.BufferLoad:7 tvm.tir.expr.Call:10 tvm.tir.expr.Cast:7
#: tvm.tir.expr.CommReducer:11 tvm.tir.expr.Div:7 tvm.tir.expr.EQ:7
#: tvm.tir.expr.FloatImm:7 tvm.tir.expr.FloorDiv:7 tvm.tir.expr.FloorMod:7
#: tvm.tir.expr.GE:7 tvm.tir.expr.GT:7 tvm.tir.expr.IntImm:7
#: tvm.tir.expr.IterVar:13 tvm.tir.expr.LE:7 tvm.tir.expr.LT:7
#: tvm.tir.expr.Let:9 tvm.tir.expr.Max:7 tvm.tir.expr.Min:7 tvm.tir.expr.Mod:7
#: tvm.tir.expr.Mul:7 tvm.tir.expr.NE:7 tvm.tir.expr.Not:5 tvm.tir.expr.Or:7
#: tvm.tir.expr.ProducerLoad:7 tvm.tir.expr.Ramp:9 tvm.tir.expr.Reduce:15
#: tvm.tir.expr.Select:16 tvm.tir.expr.Shuffle:7 tvm.tir.expr.SizeVar:8
#: tvm.tir.expr.StringImm:5 tvm.tir.expr.Sub:7 tvm.tir.expr.Var:7
msgid "The location of this expression in the source code."
msgstr ""

#: of tvm.tir.stmt.Allocate:1
msgid "Allocate node."
msgstr ""

#: of tvm.tir.stmt.Allocate:3 tvm.tir.stmt.AllocateConst:3
msgid "The buffer variable."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:10 tvm.tir.stmt.Allocate:5
#: tvm.tir.stmt.AllocateConst:5
msgid "The data type of the buffer."
msgstr ""

#: of tvm.tir.stmt.Allocate:7 tvm.tir.stmt.AllocateConst:7
msgid "The extents of the allocate"
msgstr ""

#: of tvm.tir.stmt.Allocate:9
msgid "The condition."
msgstr ""

#: of tvm.tir.stmt.Allocate:11 tvm.tir.stmt.AllocateConst:14
#: tvm.tir.stmt.AssertStmt:7 tvm.tir.stmt.AttrStmt:9 tvm.tir.stmt.For:11
#: tvm.tir.stmt.LetStmt:7 tvm.tir.stmt.While:5
msgid "The body statement."
msgstr ""

#: of tvm.tir.stmt.Allocate:13
msgid "Additional annotation hints"
msgstr ""

#: of tvm.tir.stmt.Allocate:15 tvm.tir.stmt.AllocateConst:18
#: tvm.tir.stmt.AssertStmt:9 tvm.tir.stmt.AttrStmt:11
#: tvm.tir.stmt.BufferRealize:11 tvm.tir.stmt.BufferStore:13
#: tvm.tir.stmt.Evaluate:5 tvm.tir.stmt.For:18 tvm.tir.stmt.IfThenElse:9
#: tvm.tir.stmt.LetStmt:9 tvm.tir.stmt.SeqStmt:5 tvm.tir.stmt.While:7
msgid "The location of the stmt in the source code."
msgstr ""

#: of tvm.tir.stmt.AllocateConst:1
msgid "Allocate constant node."
msgstr ""

#: of tvm.tir.stmt.AllocateConst:9
msgid ""
"If an Tensor, this is the const data associated with the constant.  If an"
" integer, this is the index into the \"constants\" attribute of the "
"`IRModule` that contains the `AllocateConst`."
msgstr ""

#: of tvm.tir.stmt.AllocateConst:16
msgid "Additional annotations about the allocation."
msgstr ""

#: of tvm.tir.expr.And:1
msgid "And node."
msgstr ""

#: of tvm.tir.stmt.AssertStmt:1
msgid "AssertStmt node."
msgstr ""

#: of tvm.tir.stmt.AssertStmt:3
msgid "The assert condition."
msgstr ""

#: of tvm.tir.stmt.AssertStmt:5
msgid "The error message."
msgstr ""

#: of tvm.tir.stmt.AttrStmt:1
msgid "AttrStmt node."
msgstr ""

#: of tvm.tir.stmt.AttrStmt:3
msgid "The node to annotate the attribute"
msgstr ""

#: of tvm.tir.stmt.AttrStmt:5
msgid "Attribute type key."
msgstr ""

#: of tvm.tir.stmt.AttrStmt:7
msgid "The value of the attribute"
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout:1
msgid ""
"Bijective mapping for two layouts (src-layout and dst-layout). It "
"provides shape and index conversion between each other."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout:4
msgid ""
"Do not construct directly, use :any:`bijective_layout` instead. See the "
"documentation of :any:`bijective_layout` for more details."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout:7
#: tvm.tir.data_layout.bijective_layout:3
msgid "source layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout:9
#: tvm.tir.data_layout.bijective_layout:5
msgid "destination layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout:14
msgid ":py:obj:`bijective_layout`"
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout:15 tvm.tir.data_layout.Layout:11
msgid "Declare a layout"
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.backward_index:1
msgid "Given the indices of the dst-layout, infer the src index."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.backward_index:3
msgid "The indices in dst-layout."
msgstr ""

#: ../../doc/docs/reference/api/python/tir/tir.rst
msgid "返回"
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.backward_index:6
msgid "**src_index** -- The inferred indices in src-layout."
msgstr ""

#: ../../doc/docs/reference/api/python/tir/tir.rst
msgid "返回类型"
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.backward_shape:1
msgid "Given the shape of the dst-layout, infer the src shape."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.backward_shape:3
msgid "The shape in dst-layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.backward_shape:6
msgid "**src_shape** -- The inferred shape in src-layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.forward_index:1
msgid "Given the indices of the src-layout, infer the dst index."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.forward_index:3
msgid "The indices in src-layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.forward_index:6
msgid "**dst_index** -- The inferred indices in dst-layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.forward_shape:1
msgid "Given the shape of the src-layout, infer the dst shape."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.forward_shape:3
msgid "The shape in src-layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.forward_shape:6
msgid "**dst_shape** -- The inferred shape in dst-layout."
msgstr ""

#: of tvm.tir.stmt.Block:1
msgid "Block node."
msgstr ""

#: of tvm.tir.stmt.Block:3
msgid "The block Variable."
msgstr ""

#: of tvm.tir.stmt.Block:5
msgid "The read buffer regions of the block."
msgstr ""

#: of tvm.tir.stmt.Block:7
msgid "The write buffer regions of the block."
msgstr ""

#: of tvm.tir.stmt.Block:9
msgid "the name_hint of the block."
msgstr ""

#: of tvm.tir.stmt.Block:11
msgid "The body of the block."
msgstr ""

#: of tvm.tir.stmt.Block:13
msgid "The init block of the reduction block"
msgstr ""

#: of tvm.tir.stmt.Block:15
msgid "The buffer allocations"
msgstr ""

#: of tvm.tir.stmt.Block:17
msgid "The subregion buffer match"
msgstr ""

#: of tvm.tir.stmt.Block:19 tvm.tir.stmt.For:16
msgid "Additional annotation hints."
msgstr ""

#: of tvm.tir.stmt.Block:21
msgid "The location of this block in the source code."
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo:1
msgid ""
"An object that helps build and query block level dependences using the 2 "
"core objects BlockScope and StmtSRef"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo:4
msgid ""
"The data structures exposed are: 1) sref2scope: Mapping from the srefs to"
" its corresponding BlockScope 2) stmt2ref: Mapping from blocks to "
"corresponding StmtSRefs"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo:8
msgid ""
"Note that this object does not store SRefs to loops as the purpose is "
"only to expose block level dependences. This provides the advantage that "
"the scope block (parent block) for a given block sref can be directly "
"accessed as sref->parent"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo.get_block_scope:1
msgid "Get the BlockScope correpsonding to the block sref"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo.get_block_scope:3
msgid "The block sref to be retrieved"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo.get_block_scope:6
msgid "**scope** -- The corresponding BlockScope"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo.get_sref:1
msgid "Return the corresponding sref that points to the block"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo.get_sref:3
msgid "The block for which the sref is to be retrived"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo.get_sref:6
msgid "**sref** -- The corresponding sref"
msgstr ""

#: of tvm.tir.stmt.BlockRealize:1
msgid "BlockRealize node."
msgstr ""

#: of tvm.tir.stmt.BlockRealize:3
msgid "The binding values of the block var."
msgstr ""

#: of tvm.tir.stmt.BlockRealize:5
msgid "The predicate of the block."
msgstr ""

#: of tvm.tir.stmt.BlockRealize:7
msgid "The block to realize"
msgstr ""

#: of tvm.tir.stmt.BlockRealize:9
msgid "The location of this block_realize in the source code."
msgstr ""

#: of tvm.tir.expr.Broadcast:1
msgid "Broadcast node."
msgstr ""

#: of tvm.tir.expr.Broadcast:3
msgid "The value of the expression."
msgstr ""

#: of tvm.tir.expr.Broadcast:5 tvm.tir.expr.Ramp:7
msgid "The lanes of the expression."
msgstr ""

#: of tvm.tir.buffer.Buffer:1
msgid "Symbolic data buffer in TVM."
msgstr ""

#: of tvm.tir.buffer.Buffer:3
msgid ""
"Buffer provide a way to represent data layout specialization of data "
"structure in TVM."
msgstr ""

#: of tvm.tir.buffer.Buffer:6
msgid ""
"Do not construct directly, use :py:func:`~decl_buffer` instead. See the "
"documentation of :py:func:`decl_buffer` for more details."
msgstr ""

#: of tvm.tir.buffer.Buffer:11
msgid ":py:obj:`decl_buffer`"
msgstr ""

#: of tvm.tir.buffer.Buffer:12
msgid "Declare a buffer"
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:1
msgid "Get an access pointer to the head of buffer."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:3
msgid ""
"This is the recommended method to get buffer data ptress when interacting"
" with external functions."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:6
msgid ""
"The access pattern MASK. Indicate whether the access will read or write "
"to the data content."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:9
msgid ""
"The data type of the result pointer. Do not specify unless we want to "
"cast pointer to specific type."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:12
msgid ""
"The number of lanes for the data type. This value is greater than one for"
" vector types."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:15
msgid ""
"The offset of pointer. We can use it to offset by the number of elements "
"from the address of ptr."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:18 tvm.tir.op.tvm_access_ptr:9
msgid "The extent of pointer."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:22
#: tvm.tir.function.IndexMap.non_surjective_inverse:14
#: tvm.tir.function.PrimFunc.specialize:7 tvm.tir.op.comm_reducer:17
#: tvm.tir.op.comm_reducer.<locals>.reducer:14
msgid "示例"
msgstr ""

#: of tvm.tir.buffer.Buffer.get_flattened_buffer:1
msgid "Generate a Buffer that is a flattened version of this buffer."
msgstr ""

#: of tvm.tir.buffer.Buffer.get_flattened_buffer:3
msgid "**flattened** -- The corresponding flat buffer."
msgstr ""

#: of tvm.tir.buffer.Buffer.offset_of:1
msgid "Determine the offset of the provided indices in the flattened buffer."
msgstr ""

#: of tvm.tir.buffer.Buffer.offset_of:3
msgid "The indices of the element in the original buffer."
msgstr ""

#: of tvm.tir.buffer.Buffer.offset_of:6
msgid ""
"**flattened_indices** -- The offset indices of the element in the "
"flattened buffer."
msgstr ""

#: of tvm.tir.buffer.Buffer.scope:1
msgid ""
"Return the storage scope associated with this buffer. :returns: **scope**"
" -- The storage scope associated with this buffer. :rtype: str"
msgstr ""

#: of tvm.tir.buffer.Buffer.vload:1
msgid "Generate an Expr that loads dtype from begin index."
msgstr ""

#: of tvm.tir.buffer.Buffer.vload:3 tvm.tir.buffer.Buffer.vstore:3
msgid "The beginning index in unit of Buffer.dtype"
msgstr ""

#: of tvm.tir.buffer.Buffer.vload:5
msgid ""
"The data type to be loaded, can be vector type which have lanes that is "
"multiple of Buffer.dtype"
msgstr ""

#: of tvm.tir.buffer.Buffer.vload:8 tvm.tir.expr.BufferLoad:9
msgid ""
"A vector mask of boolean values indicating which lanes of a vector are to"
" be loaded. The number lanes of the mask must be equal to the number of "
"lanes being loaded."
msgstr ""

#: of tvm.tir.buffer.Buffer.vload:12
msgid "**load** -- The corresponding load expression."
msgstr ""

#: of tvm.tir.buffer.Buffer.vstore:1
msgid "Generate a Stmt that store value into begin index."
msgstr ""

#: of tvm.tir.buffer.Buffer.vstore:5
msgid "The value to be stored."
msgstr ""

#: of tvm.tir.buffer.Buffer.vstore:7 tvm.tir.stmt.BufferStore:9
msgid ""
"A vector mask of boolean values indicating which lanes of a vector are to"
" be stored. The number lanes of the mask must be equal to the number of "
"lanes in value."
msgstr ""

#: of tvm.tir.buffer.Buffer.vstore:12
msgid "**store** -- The corresponding store stmt."
msgstr ""

#: of tvm.tir.expr.BufferLoad:1
msgid "Buffer load node."
msgstr ""

#: of tvm.tir.expr.BufferLoad:3 tvm.tir.expr.ProducerLoad:3
msgid "The buffer to be loaded."
msgstr ""

#: of tvm.tir.expr.BufferLoad:5
msgid "The buffer indices to load values from."
msgstr ""

#: of tvm.tir.stmt.BufferRealize:1
msgid "Buffer realize node."
msgstr ""

#: of tvm.tir.stmt.BufferRealize:3 tvm.tir.stmt.BufferStore:3
msgid "The buffer."
msgstr ""

#: of tvm.tir.stmt.BufferRealize:5 tvm.tir.stmt.BufferStore:5
msgid "The value we to be stored."
msgstr ""

#: of tvm.tir.stmt.BufferRealize:7
msgid "The realize condition."
msgstr ""

#: of tvm.tir.stmt.BufferRealize:9
msgid "The body of the statement."
msgstr ""

#: of tvm.tir.stmt.BufferRegion:1
msgid "BufferRegion node."
msgstr ""

#: of tvm.tir.stmt.BufferRegion:3
msgid "The buffer of the buffer region"
msgstr ""

#: of tvm.tir.stmt.BufferRegion:5
msgid "The region array of the buffer region"
msgstr ""

#: of tvm.tir.stmt.BufferStore:1
msgid "Buffer store node."
msgstr ""

#: of tvm.tir.stmt.BufferStore:7
msgid "The indices location to be stored."
msgstr ""

#: of tvm.tir.expr.Call:1
msgid "Call node."
msgstr ""

#: of tvm.tir.expr.Call:3
msgid "The return data type"
msgstr ""

#: of tvm.tir.expr.Call:5
msgid "The function to be called, or the name to the global tvm.Op"
msgstr ""

#: of tvm.tir.expr.Call:8
msgid "The input arguments to the call"
msgstr ""

#: of tvm.tir.expr.CallEffectKind:1
msgid "Possible kinds of Call effects."
msgstr ""

#: of tvm.tir.expr.Cast:1
msgid "Cast expression."
msgstr ""

#: of tvm.tir.expr.Cast:3 tvm.tir.expr.FloatImm:3 tvm.tir.expr.IntImm:3
#: tvm.tir.expr.SizeVar:6 tvm.tir.expr.Var:5
msgid "The data type"
msgstr ""

#: of tvm.tir.expr.Cast:5 tvm.tir.expr.StringImm:3
msgid "The value of the function."
msgstr ""

#: of tvm.tir.expr.CommReducer:1
msgid "Commutative reduce operator"
msgstr ""

#: of tvm.tir.expr.CommReducer:3
msgid "The left arguments of the reducer."
msgstr ""

#: of tvm.tir.expr.CommReducer:5
msgid "The right arguments of the reducer."
msgstr ""

#: of tvm.tir.expr.CommReducer:7
msgid "The reduction results."
msgstr ""

#: of tvm.tir.expr.CommReducer:9
msgid "The identity elements."
msgstr ""

#: of tvm.tir.stmt.DeclBuffer:1
msgid "DeclBuffer node."
msgstr ""

#: of tvm.tir.stmt.DeclBuffer:3
msgid "The buffer being declared."
msgstr ""

#: of tvm.tir.stmt.DeclBuffer:5
msgid "The body statement to be executed."
msgstr ""

#: of tvm.tir.stmt.DeclBuffer:7
msgid "The location of this DeclBuffer in the source code."
msgstr ""

#: of tvm.tir.expr.Div:1
msgid "Div node."
msgstr ""

#: of tvm.tir.expr.EQ:1
msgid "EQ node."
msgstr ""

#: of tvm.tir.stmt.Evaluate:1
msgid "Evaluate node."
msgstr ""

#: of tvm.tir.stmt.Evaluate:3
msgid "The expression to be evaluated."
msgstr ""

#: of tvm.tir.expr.FloatImm:1
msgid "Float constant."
msgstr ""

#: of tvm.tir.expr.FloatImm:5 tvm.tir.expr.IntImm:5
msgid "The constant value."
msgstr ""

#: of tvm.tir.expr.FloorDiv:1
msgid "FloorDiv node."
msgstr ""

#: of tvm.tir.expr.FloorMod:1
msgid "FloorMod node."
msgstr ""

#: of tvm.tir.stmt.For:1
msgid "For node."
msgstr ""

#: of tvm.tir.stmt.For:3
msgid "The loop variable."
msgstr ""

#: of tvm.tir.stmt.For:5
msgid "The beginning value."
msgstr ""

#: of tvm.tir.stmt.For:7
msgid "The length of the loop."
msgstr ""

#: of tvm.tir.stmt.For:9
msgid "The type of the for."
msgstr ""

#: of tvm.tir.stmt.For:13
msgid "The thread this loop binds to. Only valid if kind is ThreadBinding"
msgstr ""

#: of tvm.tir.stmt.ForKind:1
msgid "The kind of the for loop."
msgstr ""

#: of tvm.tir.stmt.ForKind:5
msgid ""
"ForKind can change the control flow semantics of the loop and need to be "
"considered in all TIR passes."
msgstr ""

#: of tvm.tir.expr.GE:1
msgid "GE node."
msgstr ""

#: of tvm.tir.expr.GT:1
msgid "GT node."
msgstr ""

#: of tvm.tir.stmt.IfThenElse:1
msgid "IfThenElse node."
msgstr ""

#: of tvm.tir.stmt.IfThenElse:3
msgid "The expression"
msgstr ""

#: of tvm.tir.stmt.IfThenElse:5
msgid "The statement to execute if condition is true."
msgstr ""

#: of tvm.tir.stmt.IfThenElse:7
msgid "The statement to execute if condition is false."
msgstr ""

#: of tvm.tir.function.IndexMap:1
msgid ""
"A mapping from multi-dimensional indices to another set of multi-"
"dimensional indices"
msgstr ""

#: of tvm.tir.function.IndexMap:3
msgid "Variables representing the indices prior to remapping."
msgstr ""

#: of tvm.tir.function.IndexMap:5
msgid "Expressions defining the indices after remapping."
msgstr ""

#: of tvm.tir.function.IndexMap:7 tvm.tir.function.IndexMap.from_func:15
#: tvm.tir.function.IndexMap.from_func_with_separators:17
msgid ""
"The optional pre-defined inverse index map. When this is defined, "
"IndexMap::Inverse will return the pre-defined inverse index map. "
"Otherwise, the inverse index map will be computed on the fly. It is the "
"user's responsibility to ensure the correctness of the pre-defined "
"inverse index map."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func:1
#: tvm.tir.function.IndexMap.from_func_with_separators:1
msgid "Create an index map from a function"
msgstr ""

#: of tvm.tir.function.IndexMap.from_func:3
msgid ""
"The function to map from source indices to target indices. The function "
"should accept `tir.Var` parameters and return a either a `tir.PrimExpr`, "
"or a list of `tir.PrimExpr`. Returning a `tir.PrimExpr` is equivalent to "
"returning a list of length 1 containing that `tir.PrimExpr`."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func:9
msgid ""
"The dimensionality of the buffer to which this transformation should be "
"applied.  If mapping_function uses variadic argument `*args`, `ndim` must"
" be specified.  If mapping_function does not use variadic arguments, ndim"
" is optional."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func:22
msgid "**index_map** -- Returns an IndexMap representing the `mapping_function`."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func_with_separators:3
msgid ""
"The function to map from source indices to target indices. The function "
"should accept tir.Var parameters and return either a `tir.PrimExpr` or a "
"list.  Each element of the returned list should be either a "
"`tir.PrimExpr` or the object `IndexMap.AXIS_SEPARATOR`.  Returning a "
"`tir.PrimExpr` is equivalent to returning a list of length 1 containing "
"that `tir.PrimExpr`."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func_with_separators:11
msgid ""
"The dimensionality of the buffer to which this transformation should be "
"applied.  If mapping_function uses variadic argument `*args`, ndim must "
"be specified.  If mapping_function does not use variadic arguments, ndim "
"is optional."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func_with_separators:23
msgid "The default index dtype to use for input iters in the mapping function."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func_with_separators:26
msgid ""
"**ret** -- Returns a tuple whose first element is an IndexMap "
"representing the `mapping_function`, and whose second index is a list of "
"indices at which `IndexMap.AXIS_SEPARATOR` occurred."
msgstr ""

#: of tvm.tir.function.IndexMap.inverse:1
#: tvm.tir.function.IndexMap.non_surjective_inverse:1
msgid "Return the inverse of the map"
msgstr ""

#: of tvm.tir.function.IndexMap.inverse:3
msgid "Throws an error if the function is not bijective."
msgstr ""

#: of tvm.tir.function.IndexMap.inverse:5
msgid ""
"The region over which the inverse should be determined. Used for "
"validating that the mapping is bijective over this range."
msgstr ""

#: of tvm.tir.function.IndexMap.inverse:10
msgid "**inverse** -- The inverse"
msgstr ""

#: of tvm.tir.function.IndexMap.is_equivalent_to:1
msgid "Return if the index maps are equivalent."
msgstr ""

#: of tvm.tir.function.IndexMap.is_equivalent_to:3
msgid "The IndexMap to which the comparison should be made."
msgstr ""

#: of tvm.tir.function.IndexMap.is_equivalent_to:6
msgid ""
"**is_equivalent** -- True if the two mappings represent the same "
"transformation, otherwise False"
msgstr ""

#: of tvm.tir.function.IndexMap.map_indices:1
msgid "Apply the index map to a set of indices"
msgstr ""

#: of tvm.tir.function.IndexMap.map_indices:3
msgid "The indices to be mapped"
msgstr ""

#: of tvm.tir.function.IndexMap.map_indices:6
msgid "**result** -- The mapped indices"
msgstr ""

#: of tvm.tir.function.IndexMap.map_shape:1
msgid "Apply the index map to a buffer shape"
msgstr ""

#: of tvm.tir.function.IndexMap.map_shape:3
msgid "The buffer shape to be mapped"
msgstr ""

#: of tvm.tir.function.IndexMap.map_shape:6
msgid "**result** -- The mapped shape"
msgstr ""

#: of tvm.tir.function.IndexMap.map_tensor:1
msgid "Apply thie index map to transform the layout of the input Tensor"
msgstr ""

#: of tvm.tir.function.IndexMap.map_tensor:3
msgid "The Tensor to be transformed"
msgstr ""

#: of tvm.tir.function.IndexMap.map_tensor:6
msgid "**arr_dst** -- The transformed Tensor"
msgstr ""

#: of tvm.tir.function.IndexMap.non_surjective_inverse:3
msgid "Can be applied to transformations that introduce padding."
msgstr ""

#: of tvm.tir.function.IndexMap.non_surjective_inverse:5
msgid ""
"The region over which the inverse should be determined. Used for "
"determining the predicate."
msgstr ""

#: of tvm.tir.function.IndexMap.non_surjective_inverse:9
msgid ""
"**result** -- The inverse, and a predicate for which the inverse maps to "
"a valid index in the input range."
msgstr ""

#: of tvm.tir.expr.IntImm:1
msgid "Int constant."
msgstr ""

#: of tvm.tir.expr.IterVar:1
msgid "Represent iteration variable."
msgstr ""

#: of tvm.tir.expr.IterVar:3
msgid "IterVar represents axis iterations in the computation."
msgstr ""

#: of tvm.tir.expr.IterVar:5
msgid "The domain of the iteration."
msgstr ""

#: of tvm.tir.expr.IterVar:7
msgid "The internal variable that is used for iteration."
msgstr ""

#: of tvm.tir.expr.IterVar:9
msgid "The iteration type."
msgstr ""

#: of tvm.tir.expr.IterVar:11
msgid "The thread type tag."
msgstr ""

#: of tvm.tir.expr.IterVar:18
msgid ":py:obj:`te.thread_axis`"
msgstr ""

#: of tvm.tir.expr.IterVar:19
msgid "Create thread axis IterVar."
msgstr ""

#: of tvm.tir.expr.IterVar:21
msgid ":py:obj:`te.reduce_axis`"
msgstr ""

#: of tvm.tir.expr.IterVar:22
msgid "Create reduce axis IterVar."
msgstr ""

#: of tvm.tir.expr.LE:1
msgid "LE node."
msgstr ""

#: of tvm.tir.expr.LT:1
msgid "LT node."
msgstr ""

#: of tvm.tir.data_layout.Layout:1
msgid ""
"Layout is composed of upper cases, lower cases and numbers, where upper "
"case indicates a primal axis and the corresponding lower case with factor"
" size indicates the subordinate axis. For example, NCHW16c can describe a"
" 5-D tensor of [batch_size, channel, height, width, channel_block]. Here "
"subordinate axis channel_block=16 is the factor size of the primal axis C"
" (channel)."
msgstr ""

#: of tvm.tir.data_layout.Layout:10
msgid ":py:obj:`layout`"
msgstr ""

#: of tvm.tir.data_layout.Layout.factor_of:1
msgid "Get the factor size of the subordinate axis."
msgstr ""

#: of tvm.tir.data_layout.Layout.factor_of:3
#: tvm.tir.data_layout.Layout.index_of:3
msgid "The axis name, need to be [a-z,A-Z]"
msgstr ""

#: of tvm.tir.data_layout.Layout.factor_of:6
msgid ""
"**factor** -- the size of the subordinate-axis of axis (if axis is a "
"primal-axis), or the size of axis itself (if axis is a subordinate-axis)."
" Return -1 if axis is not in the layout."
msgstr ""

#: of tvm.tir.data_layout.Layout.index_of:1
msgid "Get the index of an axis"
msgstr ""

#: of tvm.tir.data_layout.Layout.index_of:6
msgid "**index** -- The index of the axis, -1 if not found."
msgstr ""

#: of tvm.tir.expr.Let:1
msgid "Let node."
msgstr ""

#: of tvm.tir.expr.Let:3 tvm.tir.stmt.LetStmt:3
msgid "The variable in the binding."
msgstr ""

#: of tvm.tir.expr.Let:5 tvm.tir.stmt.LetStmt:5
msgid "The value in to be bound."
msgstr ""

#: of tvm.tir.expr.Let:7
msgid "The body expression."
msgstr ""

#: of tvm.tir.stmt.LetStmt:1
msgid "LetStmt node."
msgstr ""

#: of tvm.tir.stmt.MatchBufferRegion:1
msgid "MatchBufferRegion node."
msgstr ""

#: of tvm.tir.stmt.MatchBufferRegion:3
msgid "The target buffer"
msgstr ""

#: of tvm.tir.stmt.MatchBufferRegion:5
msgid "The region of source buffer"
msgstr ""

#: of tvm.tir.expr.Max:1
msgid "Max node."
msgstr ""

#: of tvm.tir.expr.Min:1
msgid "Min node."
msgstr ""

#: of tvm.tir.expr.Mod:1
msgid "Mod node."
msgstr ""

#: of tvm.tir.expr.Mul:1
msgid "Mul node."
msgstr ""

#: of tvm.tir.expr.NE:1
msgid "NE node."
msgstr ""

#: of tvm.tir.expr.Not:1
msgid "Not node."
msgstr ""

#: of tvm.tir.expr.Not:3
msgid "The input value"
msgstr ""

#: of tvm.tir.expr.Or:1
msgid "Or node."
msgstr ""

#: of tvm.tir.function.PrimFunc:1
msgid "A function declaration expression."
msgstr ""

#: of tvm.tir.function.PrimFunc:3
msgid "List of input parameters to the function."
msgstr ""

#: of tvm.tir.function.PrimFunc:5
msgid "The body of the function."
msgstr ""

#: of tvm.tir.function.PrimFunc:7
msgid "The return type annotation of the function."
msgstr ""

#: of tvm.tir.function.PrimFunc:9
msgid "The buffer binding map."
msgstr ""

#: of tvm.tir.function.PrimFunc:11
msgid "Attributes of the function, can be None"
msgstr ""

#: of tvm.tir.function.PrimFunc:13 tvm.tir.function.PrimFunc.with_body:5
msgid "The location of this itervar in the source code."
msgstr ""

#: of tvm.tir.function.PrimFunc.specialize:1
msgid "Specialize parameters of PrimFunc"
msgstr ""

#: of tvm.tir.function.PrimFunc.specialize:3
msgid "The mapping from function params to the instance"
msgstr ""

#: of tvm.tir.function.PrimFunc.specialize:8
msgid "We can define a Meta TIR function with symbolic shape:"
msgstr ""

#: of tvm.tir.function.PrimFunc.specialize:22
msgid "Then we can make it specialized with given shapes or buffers."
msgstr ""

#: of tvm.tir.function.PrimFunc.specialize:31
msgid "The specialized function:"
msgstr ""

#: of tvm.tir.function.PrimFunc.specialize:45
msgid "**func** -- The new function with parameter specialized"
msgstr ""

#: of tvm.tir.function.PrimFunc.with_body:1
msgid "Create a new PrimFunc with the same set signatures but a new body."
msgstr ""

#: of tvm.tir.function.PrimFunc.with_body:3
msgid "The new body."
msgstr ""

#: of tvm.tir.function.PrimFunc.with_body:8
msgid "**new_func** -- The created new function."
msgstr ""

#: of tvm.tir.expr.ProducerLoad:1
msgid "Producer load node."
msgstr ""

#: of tvm.tir.expr.ProducerLoad:5
msgid "The buffer indices."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator:1
msgid ""
"A Python StmtExprMutator to define custom mutator for both Stmt and "
"PrimExpr."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator:3 tvm.tir.functor.PyStmtExprVisitor:3
msgid "Users can customize any of the visit function."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_add_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_add_:1
msgid "Visit Add."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_add_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_add_:3
msgid ""
"Users can customize this function to overwrite VisitAdd_(const AddNode* "
"op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_add_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_add_:6
msgid "The Add to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_add_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_and_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_broadcast_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_buffer_load_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_call_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_cast_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_div_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_eq_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_expr:8
#: tvm.tir.functor.PyStmtExprMutator.visit_float_imm_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_floor_div_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_floor_mod_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_ge_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_gt_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_int_imm_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_le_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_let_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_lt_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_max_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_min_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_mod_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_mul_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_ne_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_not_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_or_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_producer_load_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_ramp_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_reduce_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_select_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_shuffle_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_size_var_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_string_imm_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_sub_:9
#: tvm.tir.functor.PyStmtExprMutator.visit_var_:9
msgid "**result** -- The mutated PrimExpr."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_allocate_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_allocate_:1
msgid ""
"Visit Allocate. Users can customize this function to overwrite "
"VisitStmt_(const AllocateNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_allocate_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_allocate_:5
msgid "The Allocate to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_allocate_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_allocate_const_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_assert_stmt_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_attr_stmt_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_block_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_block_realize_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_buffer_realize_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_buffer_store_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_decl_buffer_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_evaluate_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_for_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_if_then_else_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_let_stmt_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_seq_stmt_:8
#: tvm.tir.functor.PyStmtExprMutator.visit_stmt:8
#: tvm.tir.functor.PyStmtExprMutator.visit_while_:8
msgid "**result** -- The mutated Stmt."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_allocate_const_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_allocate_const_:1
msgid ""
"Visit AllocateConst. Users can customize this function to overwrite "
"VisitStmt_(const AllocateConstNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_allocate_const_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_allocate_const_:5
msgid "The AllocateConst to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_and_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_and_:1
msgid "Visit And."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_and_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_and_:3
msgid ""
"Users can customize this function to overwrite VisitAnd_(const AndNode* "
"op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_and_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_and_:6
msgid "The And to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_assert_stmt_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_assert_stmt_:1
msgid ""
"Visit AssertStmt. Users can customize this function to overwrite "
"VisitStmt_(const AssertStmtNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_assert_stmt_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_assert_stmt_:5
msgid "The AssertStmt to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_attr_stmt_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_attr_stmt_:1
msgid ""
"Visit AttrStmt. Users can customize this function to overwrite "
"VisitStmt_(const AttrStmtNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_attr_stmt_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_attr_stmt_:5
msgid "The AttrStmt to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_block_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_block_:1
msgid ""
"Visit Block. Users can customize this function to overwrite "
"VisitStmt_(const BlockNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_block_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_block_:5
msgid "The Block to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_block_realize_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_block_realize_:1
msgid ""
"Visit BlockRealize. Users can customize this function to overwrite "
"VisitStmt_(const BlockRealizeNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_block_realize_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_block_realize_:5
msgid "The BlockRealize to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_broadcast_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_broadcast_:1
msgid "Visit Broadcast."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_broadcast_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_broadcast_:3
msgid ""
"Users can customize this function to overwrite VisitBroadcast_(const "
"BroadcastNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_broadcast_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_broadcast_:6
msgid "The Broadcast to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_buffer_load_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_buffer_load_:1
msgid "Visit BufferLoad."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_buffer_load_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_buffer_load_:3
msgid ""
"Users can customize this function to overwrite VisitBufferLoad_(const "
"BufferLoadNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_buffer_load_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_buffer_load_:6
msgid "The BufferLoad to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_buffer_realize_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_buffer_realize_:1
msgid ""
"Visit BufferRealize. Users can customize this function to overwrite "
"VisitStmt_(const BufferRealizeNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_buffer_realize_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_buffer_realize_:5
msgid "The BufferRealize to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_buffer_store_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_buffer_store_:1
msgid ""
"Visit BufferStore. Users can customize this function to overwrite "
"VisitStmt_(const BufferStoreNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_buffer_store_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_buffer_store_:5
msgid "The BufferStore to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_call_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_call_:1
msgid "Visit Call."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_call_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_call_:3
msgid ""
"Users can customize this function to overwrite VisitCall_(const CallNode*"
" op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_call_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_call_:6
msgid "The Call to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_cast_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_cast_:1
msgid "Visit Cast."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_cast_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_cast_:3
msgid ""
"Users can customize this function to overwrite VisitCast_(const CastNode*"
" op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_cast_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_cast_:6
msgid "The Cast to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_decl_buffer_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_decl_buffer_:1
msgid ""
"Visit DeclBuffer. Users can customize this function to overwrite "
"VisitStmt_(const DeclBufferNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_decl_buffer_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_decl_buffer_:5
msgid "The DeclBuffer to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_div_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_div_:1
msgid "Visit Div."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_div_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_div_:3
msgid ""
"Users can customize this function to overwrite VisitDiv_(const DivNode* "
"op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_div_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_div_:6
msgid "The Div to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_eq_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_eq_:1
msgid "Visit EQ."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_eq_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_eq_:3
msgid ""
"Users can customize this function to overwrite VisitEQ_(const EQNode* op)"
" on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_eq_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_eq_:6
msgid "The EQ to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_evaluate_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_evaluate_:1
msgid ""
"Visit Evaluate. Users can customize this function to overwrite "
"VisitStmt_(const EvaluateNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_evaluate_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_evaluate_:5
msgid "The Evaluate to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_expr:1
msgid ""
"Visit PrimExpr. Users can customize this function to overwrite "
"VisitExpr(const PrimExpr& expr) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_expr:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_expr:3
msgid "The PrimExpr to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_float_imm_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_float_imm_:1
msgid "Visit FloatImm."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_float_imm_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_float_imm_:3
msgid ""
"Users can customize this function to overwrite VisitFloatImm_(const "
"FloatImmNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_float_imm_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_float_imm_:6
msgid "The FloatImm to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_floor_div_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_floor_div_:1
msgid "Visit FloorDiv."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_floor_div_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_floor_div_:3
msgid ""
"Users can customize this function to overwrite VisitFloorDiv_(const "
"FloorDivNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_floor_div_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_floor_div_:6
msgid "The FloorDiv to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_floor_mod_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_floor_mod_:1
msgid "Visit FloorMod."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_floor_mod_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_floor_mod_:3
msgid ""
"Users can customize this function to overwrite VisitFloorMod_(const "
"FloorModNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_floor_mod_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_floor_mod_:6
msgid "The FloorMod to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_for_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_for_:1
msgid ""
"Visit For. Users can customize this function to overwrite "
"VisitStmt_(const ForNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_for_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_for_:5
msgid "The For to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_ge_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_ge_:1
msgid "Visit GE."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_ge_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_ge_:3
msgid ""
"Users can customize this function to overwrite VisitGE_(const GENode* op)"
" on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_ge_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_ge_:6
msgid "The GE to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_gt_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_gt_:1
msgid "Visit GT."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_gt_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_gt_:3
msgid ""
"Users can customize this function to overwrite VisitGT_(const GTNode* op)"
" on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_gt_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_gt_:6
msgid "The GT to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_if_then_else_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_if_then_else_:1
msgid ""
"Visit IfThenElse. Users can customize this function to overwrite "
"VisitStmt_(const IfThenElseNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_if_then_else_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_if_then_else_:5
msgid "The IfThenElse to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_int_imm_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_int_imm_:1
msgid "Visit IntImm."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_int_imm_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_int_imm_:3
msgid ""
"Users can customize this function to overwrite VisitIntImm_(const "
"IntImmNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_int_imm_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_int_imm_:6
msgid "The IntImm to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_le_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_le_:1
msgid "Visit LE."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_le_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_le_:3
msgid ""
"Users can customize this function to overwrite VisitLE_(const LENode* op)"
" on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_le_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_le_:6
msgid "The LE to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_let_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_let_:1
msgid "Visit Let."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_let_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_let_:3
msgid ""
"Users can customize this function to overwrite VisitLet_(const LetNode* "
"op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_let_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_let_:6
msgid "The Let to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_let_stmt_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_let_stmt_:1
msgid ""
"Visit LetStmt. Users can customize this function to overwrite "
"VisitStmt_(const LetStmtNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_let_stmt_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_let_stmt_:5
msgid "The LetStmt to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_lt_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_lt_:1
msgid "Visit LT."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_lt_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_lt_:3
msgid ""
"Users can customize this function to overwrite VisitLT_(const LTNode* op)"
" on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_lt_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_lt_:6
msgid "The LT to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_max_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_max_:1
msgid "Visit Max."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_max_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_max_:3
msgid ""
"Users can customize this function to overwrite VisitMax_(const MaxNode* "
"op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_max_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_max_:6
msgid "The Max to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_min_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_min_:1
msgid "Visit Min."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_min_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_min_:3
msgid ""
"Users can customize this function to overwrite VisitMin_(const MinNode* "
"op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_min_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_min_:6
msgid "The Min to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_mod_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_mod_:1
msgid "Visit Mod."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_mod_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_mod_:3
msgid ""
"Users can customize this function to overwrite VisitMod_(const ModNode* "
"op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_mod_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_mod_:6
msgid "The Mod to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_mul_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_mul_:1
msgid "Visit Mul."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_mul_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_mul_:3
msgid ""
"Users can customize this function to overwrite VisitMul_(const MulNode* "
"op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_mul_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_mul_:6
msgid "The Mul to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_ne_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_ne_:1
msgid "Visit NE."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_ne_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_ne_:3
msgid ""
"Users can customize this function to overwrite VisitNE_(const NENode* op)"
" on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_ne_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_ne_:6
msgid "The NE to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_not_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_not_:1
msgid "Visit Not."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_not_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_not_:3
msgid ""
"Users can customize this function to overwrite VisitNot_(const NotNode* "
"op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_not_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_not_:6
msgid "The Not to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_or_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_or_:1
msgid "Visit Or."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_or_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_or_:3
msgid ""
"Users can customize this function to overwrite VisitOr_(const OrNode* op)"
" on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_or_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_or_:6
msgid "The Or to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_producer_load_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_producer_load_:1
msgid "Visit ProducerLoad."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_producer_load_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_producer_load_:3
msgid ""
"Users can customize this function to overwrite VisitProducerLoad_(const "
"ProducerLoadNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_producer_load_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_producer_load_:6
msgid "The ProducerLoad to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_ramp_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_ramp_:1
msgid "Visit Ramp."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_ramp_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_ramp_:3
msgid ""
"Users can customize this function to overwrite VisitRamp_(const RampNode*"
" op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_ramp_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_ramp_:6
msgid "The Ramp to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_reduce_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_reduce_:1
msgid "Visit Reduce."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_reduce_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_reduce_:3
msgid ""
"Users can customize this function to overwrite VisitReduce_(const "
"ReduceNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_reduce_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_reduce_:6
msgid "The Reduce to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_select_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_select_:1
msgid "Visit Select."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_select_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_select_:3
msgid ""
"Users can customize this function to overwrite VisitSelect_(const "
"SelectNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_select_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_select_:6
msgid "The Select to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_seq_stmt_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_seq_stmt_:1
msgid ""
"Visit SeqStmt. Users can customize this function to overwrite "
"VisitStmt_(const SeqStmtNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_seq_stmt_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_seq_stmt_:5
msgid "The SeqStmt to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_shuffle_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_shuffle_:1
msgid "Visit Shuffle."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_shuffle_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_shuffle_:3
msgid ""
"Users can customize this function to overwrite VisitShuffle_(const "
"ShuffleNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_shuffle_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_shuffle_:6
msgid "The Shuffle to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_size_var_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_size_var_:1
msgid "Visit SizeVar."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_size_var_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_size_var_:3
msgid ""
"Users can customize this function to overwrite VisitSizeVar_(const "
"SizeVarNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_size_var_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_size_var_:6
msgid "The SizeVar to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_stmt:1
msgid ""
"Visit Stmt. Users can customize this function to overwrite "
"VisitStmt(const Stmt& stmt) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_stmt:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_stmt:3
msgid "The Stmt to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_string_imm_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_string_imm_:1
msgid "Visit StringImm."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_string_imm_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_string_imm_:3
msgid ""
"Users can customize this function to overwrite VisitStringImm_(const "
"StringImmNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_string_imm_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_string_imm_:6
msgid "The StringImm to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_sub_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_sub_:1
msgid "Visit Sub."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_sub_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_sub_:3
msgid ""
"Users can customize this function to overwrite VisitSub_(const SubNode* "
"op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_sub_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_sub_:6
msgid "The Sub to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_var_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_var_:1
msgid "Visit Var."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_var_:3
#: tvm.tir.functor.PyStmtExprVisitor.visit_var_:3
msgid ""
"Users can customize this function to overwrite VisitVar_(const VarNode* "
"op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_var_:6
#: tvm.tir.functor.PyStmtExprVisitor.visit_var_:6
msgid "The Var to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_while_:1
#: tvm.tir.functor.PyStmtExprVisitor.visit_while_:1
msgid ""
"Visit While. Users can customize this function to overwrite "
"VisitStmt_(const WhileNode* op) on the C++ side."
msgstr ""

#: of tvm.tir.functor.PyStmtExprMutator.visit_while_:5
#: tvm.tir.functor.PyStmtExprVisitor.visit_while_:5
msgid "The While to be visited."
msgstr ""

#: of tvm.tir.functor.PyStmtExprVisitor:1
msgid ""
"A Python StmtExprVisitor to define custom visitor for both Stmt and "
"PrimExpr."
msgstr ""

#: of tvm.tir.functor.PyStmtExprVisitor.visit_expr:1
msgid "Visit a PrimExpr."
msgstr ""

#: of tvm.tir.functor.PyStmtExprVisitor.visit_stmt:1
msgid "Visit a Stmt."
msgstr ""

#: of tvm.tir.expr.Ramp:1
msgid "Ramp node."
msgstr ""

#: of tvm.tir.expr.Ramp:3
msgid "The base expression."
msgstr ""

#: of tvm.tir.expr.Ramp:5
msgid "The stride of the ramp."
msgstr ""

#: of tvm.tir.expr.Reduce:1
msgid "Reduce node."
msgstr ""

#: of tvm.tir.expr.Reduce:3
msgid "The combiner."
msgstr ""

#: of tvm.tir.expr.Reduce:5 tvm.tir.op.comm_reducer.<locals>.reducer:3
msgid "The source expression."
msgstr ""

#: of tvm.tir.expr.Reduce:7
msgid "The iteration domain"
msgstr ""

#: of tvm.tir.expr.Reduce:9
msgid "The reduce condition."
msgstr ""

#: of tvm.tir.expr.Reduce:11
msgid "The value index."
msgstr ""

#: of tvm.tir.expr.Reduce:13
msgid "The initial value for output. This can be an int, float or ProducerLoad"
msgstr ""

#: of tvm.tir.expr.Select:1
msgid "Select node."
msgstr ""

#: of tvm.tir.expr.Select:5
msgid ""
"Select may compute both true_value and false_value. Use "
":py:class:`tvm.tir.if_then_else` instead if you want to get a conditional"
" expression that only evaluates the correct branch."
msgstr ""

#: of tvm.tir.expr.Select:10
msgid "The condition expression."
msgstr ""

#: of tvm.tir.expr.Select:12
msgid "The value to take when condition is true."
msgstr ""

#: of tvm.tir.expr.Select:14
msgid "The value to take when condition is false."
msgstr ""

#: of tvm.tir.stmt.SeqStmt:1
msgid "Sequence of statements."
msgstr ""

#: of tvm.tir.stmt.SeqStmt:3
msgid "The statements"
msgstr ""

#: of tvm.tir.expr.Shuffle:1
msgid "Shuffle node."
msgstr ""

#: of tvm.tir.expr.Shuffle:3
msgid "The vectors"
msgstr ""

#: of tvm.tir.expr.Shuffle:5
msgid "The indices"
msgstr ""

#: of tvm.tir.expr.SizeVar:1
msgid "Symbolic variable to represent a tensor index size"
msgstr ""

#: of tvm.tir.expr.SizeVar:2
msgid "which is greater or equal to zero."
msgstr ""

#: of tvm.tir.expr.SizeVar:4 tvm.tir.expr.Var:3
msgid "The name"
msgstr ""

#: of tvm.tir.stmt.Stmt:1
msgid "Base class of all the statements."
msgstr ""

#: of tvm.tir.expr.StringImm:1
msgid "String constant."
msgstr ""

#: of tvm.tir.expr.Sub:1
msgid "Sub node."
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:1
msgid "Backend function to allocate temporal workspace"
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:3
#: tvm.tir.op.TVMBackendFreeWorkspace:3
msgid "The device type which the space will be allocated."
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:5
#: tvm.tir.op.TVMBackendFreeWorkspace:5
msgid "The device id which the space will be allocated."
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:7
msgid "The size of the space requested."
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:9
msgid ""
"The type code of the array elements. Only used in certain backends such "
"as OpenGL."
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:11
msgid ""
"The type bits of the array elements. Only used in certain backends such "
"as OpenGL."
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:14
#: tvm.tir.op.TVMBackendFreeWorkspace:10 tvm.tir.op.address_of:8
#: tvm.tir.op.assume:6 tvm.tir.op.call_cpacked:11
#: tvm.tir.op.call_cpacked_lowered:10 tvm.tir.op.call_extern:12
#: tvm.tir.op.call_intrin:15 tvm.tir.op.call_llvm_intrin:12
#: tvm.tir.op.call_llvm_pure_intrin:12 tvm.tir.op.call_packed:15
#: tvm.tir.op.call_packed_lowered:13 tvm.tir.op.call_pure_extern:12
#: tvm.tir.op.call_tir:3 tvm.tir.op.create_barriers:6 tvm.tir.op.dp4a:10
#: tvm.tir.op.end_profile_intrinsic:5 tvm.tir.op.handle_add_byte_offset:8
#: tvm.tir.op.lookup_param:8 tvm.tir.op.make_filled_simdgroup_matrix:14
#: tvm.tir.op.mma_fill:12 tvm.tir.op.mma_store:18
#: tvm.tir.op.ptx_arrive_barrier:7 tvm.tir.op.ptx_arrive_barrier_expect_tx:11
#: tvm.tir.op.ptx_commit_group:4 tvm.tir.op.ptx_cp_async:17
#: tvm.tir.op.ptx_cp_async_barrier:7 tvm.tir.op.ptx_cp_async_bulk:19
#: tvm.tir.op.ptx_init_barrier_thread_count:9 tvm.tir.op.ptx_ldmatrix:21
#: tvm.tir.op.ptx_mma:35 tvm.tir.op.ptx_mma_sp:39 tvm.tir.op.ptx_wait_barrier:7
#: tvm.tir.op.ptx_wait_group:7 tvm.tir.op.simdgroup_load:18
#: tvm.tir.op.simdgroup_multiply_accumulate:21 tvm.tir.op.simdgroup_store:19
#: tvm.tir.op.start_profile_intrinsic:5 tvm.tir.op.trace:13
#: tvm.tir.op.tvm_access_ptr:14 tvm.tir.op.tvm_bmma_sync:20
#: tvm.tir.op.tvm_fill_fragment:16 tvm.tir.op.tvm_load_matrix_sync:20
#: tvm.tir.op.tvm_mma_sync:20 tvm.tir.op.tvm_stack_alloca:8
#: tvm.tir.op.tvm_stack_make_array:16 tvm.tir.op.tvm_stack_make_shape:6
#: tvm.tir.op.tvm_store_matrix_sync:20 tvm.tir.op.tvm_struct_get:12
#: tvm.tir.op.tvm_struct_set:12 tvm.tir.op.tvm_thread_allreduce:6
#: tvm.tir.op.tvm_tuple:6 tvm.tir.op.type_annotation:6 tvm.tir.op.undef:3
#: tvm.tir.op.vectorcombine:8 tvm.tir.op.vectorhigh:8 tvm.tir.op.vectorlow:8
msgid "**call** -- The call expression."
msgstr ""

#: of tvm.tir.op.TVMBackendFreeWorkspace:1
msgid "Backend function to free temporal workspace."
msgstr ""

#: of tvm.tir.op.TVMBackendFreeWorkspace:7
msgid "The result allocated space pointer."
msgstr ""

#: of tvm.tir.function.TensorIntrin:1
msgid "A tensor intrinsic."
msgstr ""

#: of tvm.tir.function.TensorIntrin:3 tvm.tir.function.TensorIntrin.register:5
msgid "The function to describe the computation."
msgstr ""

#: of tvm.tir.function.TensorIntrin:5 tvm.tir.function.TensorIntrin.register:7
msgid "The function of the implementation for the execution."
msgstr ""

#: of tvm.tir.function.TensorIntrin.get:1
msgid "Look up a tensor intrinsic by its name."
msgstr ""

#: of tvm.tir.function.TensorIntrin.get:3
msgid "The name of the TensorIntrin to look up."
msgstr ""

#: of tvm.tir.function.TensorIntrin.get:5
msgid ""
"Whether to allow missing tensor intrin. If False, raise an error if the "
"tensor intrin"
msgstr ""

#: of tvm.tir.function.TensorIntrin.get:9
msgid ""
"**result** -- The TensorIntrin with the specified name, or None if not "
"found."
msgstr ""

#: of tvm.tir.function.TensorIntrin.register:1
msgid "Register a tensor intrinsic with its name."
msgstr ""

#: of tvm.tir.function.TensorIntrin.register:3
msgid "The name of the TensorIntrin to register."
msgstr ""

#: of tvm.tir.function.TensorIntrin.register:9
msgid "Whether override existing intrinsic."
msgstr ""

#: of tvm.tir.expr.Var:1
msgid "Symbolic variable."
msgstr ""

#: of tvm.tir.stmt.While:1
msgid "While node."
msgstr ""

#: of tvm.tir.stmt.While:3
msgid "The termination condition."
msgstr ""

#: of tvm.tir.op.abs:1
msgid "Get absolute value of the input element-wise."
msgstr ""

#: of tvm.tir.op.abs:3 tvm.tir.op.acos:3 tvm.tir.op.acosh:3 tvm.tir.op.asin:3
#: tvm.tir.op.asinh:3 tvm.tir.op.atan:3 tvm.tir.op.atan2:3 tvm.tir.op.atan2:5
#: tvm.tir.op.atanh:3 tvm.tir.op.ceil:3 tvm.tir.op.copysign:3
#: tvm.tir.op.copysign:5 tvm.tir.op.cos:3 tvm.tir.op.cosh:3 tvm.tir.op.erf:3
#: tvm.tir.op.exp:3 tvm.tir.op.exp10:3 tvm.tir.op.exp2:3 tvm.tir.op.floor:3
#: tvm.tir.op.fmod:3 tvm.tir.op.fmod:5 tvm.tir.op.hypot:3 tvm.tir.op.hypot:5
#: tvm.tir.op.isfinite:3 tvm.tir.op.isinf:3 tvm.tir.op.isnan:3
#: tvm.tir.op.isnullptr:3 tvm.tir.op.ldexp:3 tvm.tir.op.ldexp:5
#: tvm.tir.op.likely:3 tvm.tir.op.log:3 tvm.tir.op.log10:3 tvm.tir.op.log1p:3
#: tvm.tir.op.log2:3 tvm.tir.op.nearbyint:10 tvm.tir.op.nextafter:3
#: tvm.tir.op.nextafter:5 tvm.tir.op.popcount:3 tvm.tir.op.pow:3
#: tvm.tir.op.power:3 tvm.tir.op.round:3 tvm.tir.op.rsqrt:3
#: tvm.tir.op.shift_left:3 tvm.tir.op.shift_left:5 tvm.tir.op.shift_right:3
#: tvm.tir.op.shift_right:5 tvm.tir.op.sigmoid:3 tvm.tir.op.sin:3
#: tvm.tir.op.sinh:3 tvm.tir.op.sqrt:3 tvm.tir.op.tan:3 tvm.tir.op.tanh:3
#: tvm.tir.op.trunc:6
msgid "Input argument."
msgstr ""

#: of tvm.tir.op.abs:5 tvm.tir.op.address_of:5 tvm.tir.op.all:6
#: tvm.tir.op.any:5 tvm.tir.op.bitwise_and:7 tvm.tir.op.bitwise_not:5
#: tvm.tir.op.bitwise_or:7 tvm.tir.op.bitwise_xor:7 tvm.tir.op.call_cpacked:8
#: tvm.tir.op.call_cpacked_lowered:7 tvm.tir.op.call_extern:9
#: tvm.tir.op.call_intrin:12 tvm.tir.op.call_llvm_intrin:9
#: tvm.tir.op.call_llvm_pure_intrin:9 tvm.tir.op.call_packed:12
#: tvm.tir.op.call_packed_lowered:10 tvm.tir.op.call_pure_extern:9
#: tvm.tir.op.ceil:5 tvm.tir.op.floor:5 tvm.tir.op.infinity:5
#: tvm.tir.op.isfinite:5 tvm.tir.op.isinf:5 tvm.tir.op.isnan:5
#: tvm.tir.op.isnullptr:5 tvm.tir.op.likely:5 tvm.tir.op.lookup_param:5
#: tvm.tir.op.max_value:5 tvm.tir.op.min_value:5 tvm.tir.op.nearbyint:12
#: tvm.tir.op.pow:7 tvm.tir.op.power:7 tvm.tir.op.reinterpret:7
#: tvm.tir.op.ret:5 tvm.tir.op.round:5 tvm.tir.op.trunc:8
msgid "The location of this operator in the source code."
msgstr ""

#: of tvm.tir.op.abs:8 tvm.tir.op.acos:6 tvm.tir.op.acosh:6 tvm.tir.op.asin:6
#: tvm.tir.op.asinh:6 tvm.tir.op.atan:6 tvm.tir.op.atan2:8 tvm.tir.op.atanh:6
#: tvm.tir.op.ceil:8 tvm.tir.op.clz:7 tvm.tir.op.copysign:8 tvm.tir.op.cos:6
#: tvm.tir.op.cosh:6 tvm.tir.op.erf:6 tvm.tir.op.exp:6 tvm.tir.op.exp10:6
#: tvm.tir.op.exp2:6 tvm.tir.op.floor:8 tvm.tir.op.hypot:8
#: tvm.tir.op.isfinite:8 tvm.tir.op.isinf:8 tvm.tir.op.isnan:8
#: tvm.tir.op.isnullptr:8 tvm.tir.op.ldexp:8 tvm.tir.op.log:6
#: tvm.tir.op.log10:6 tvm.tir.op.log1p:6 tvm.tir.op.log2:6
#: tvm.tir.op.nearbyint:15 tvm.tir.op.nextafter:8 tvm.tir.op.popcount:6
#: tvm.tir.op.q_multiply_shift:19 tvm.tir.op.round:8 tvm.tir.op.rsqrt:6
#: tvm.tir.op.sigmoid:6 tvm.tir.op.sin:6 tvm.tir.op.sinh:6 tvm.tir.op.sqrt:6
#: tvm.tir.op.tan:6 tvm.tir.op.tanh:6 tvm.tir.op.trunc:11
msgid "**y** -- The result."
msgstr ""

#: of tvm.tir.op.acos:1 tvm.tir.op.acosh:1
msgid "Take acos of input x."
msgstr ""

#: of tvm.tir.generic.add:1
msgid "Generic add operator."
msgstr ""

#: of tvm.tir.generic.add:3 tvm.tir.generic.multiply:3
#: tvm.tir.generic.subtract:3 tvm.tir.op.ceildiv:3
msgid "The left operand."
msgstr ""

#: of tvm.tir.generic.add:5 tvm.tir.generic.multiply:5
#: tvm.tir.generic.subtract:5 tvm.tir.op.ceildiv:5
msgid "The right operand."
msgstr ""

#: of tvm.tir.generic.add:7 tvm.tir.generic.multiply:7
#: tvm.tir.generic.subtract:7 tvm.tir.op.ceildiv:7 tvm.tir.op.div:7
#: tvm.tir.op.floordiv:7 tvm.tir.op.floormod:7 tvm.tir.op.if_then_else:9
#: tvm.tir.op.indexdiv:7 tvm.tir.op.indexmod:7 tvm.tir.op.logaddexp:7
#: tvm.tir.op.truncdiv:7 tvm.tir.op.truncmod:7
msgid "The location of this operator in the source."
msgstr ""

#: of tvm.tir.generic.add:10
msgid "**op** -- The result Expr of add operaton."
msgstr ""

#: of tvm.tir.op.address_of:1
msgid "Returns the address of an element in the buffer"
msgstr ""

#: of tvm.tir.op.address_of:3
msgid "The buffer or buffer load."
msgstr ""

#: of tvm.tir.op.all:1
msgid "Create a new expression of the intersection of all conditions in the"
msgstr ""

#: of tvm.tir.op.all:2
msgid "arguments"
msgstr ""

#: of tvm.tir.op.all:4 tvm.tir.op.any:3
msgid "List of symbolic boolean expressions"
msgstr ""

#: of tvm.tir.op.all:9 tvm.tir.op.any:8
msgid "**expr** -- Expression"
msgstr ""

#: of tvm.tir.op.any:1
msgid "Create a new experssion of the union of all conditions in the arguments"
msgstr ""

#: of tvm.tir.op.asin:1
msgid "Take asin of input x."
msgstr ""

#: of tvm.tir.op.asinh:1
msgid "Take asinh of input x."
msgstr ""

#: of tvm.tir.op.assume:1
msgid "Provide a true statement that can be used for simplifications"
msgstr ""

#: of tvm.tir.op.assume:3
msgid "The constraint condition."
msgstr ""

#: of tvm.tir.op.atan:1
msgid "Take atan of input x."
msgstr ""

#: of tvm.tir.op.atan2:1
msgid "Take arctan2(x1, x2)."
msgstr ""

#: of tvm.tir.op.atanh:1
msgid "Take atanh of input x."
msgstr ""

#: of tvm.tir.data_layout.bijective_layout:1
msgid "Create a bijective layout mapping."
msgstr ""

#: of tvm.tir.data_layout.bijective_layout:8
msgid "**bijective_layout** -- The created bijective layout"
msgstr ""

#: of tvm.tir.op.bitwise_and:1
msgid "Take bitwise and of two values"
msgstr ""

#: of tvm.tir.op.bitwise_and:3 tvm.tir.op.bitwise_or:3 tvm.tir.op.bitwise_xor:3
msgid "Left operand"
msgstr ""

#: of tvm.tir.op.bitwise_and:5 tvm.tir.op.bitwise_or:5 tvm.tir.op.bitwise_xor:5
msgid "Right operand"
msgstr ""

#: of tvm.tir.op.bitwise_and:10 tvm.tir.op.bitwise_not:8
#: tvm.tir.op.bitwise_or:10 tvm.tir.op.bitwise_xor:10
msgid "**res** -- The result."
msgstr ""

#: of tvm.tir.op.bitwise_not:1
msgid "Take bitwise not of input value"
msgstr ""

#: of tvm.tir.op.bitwise_not:3
msgid "Input operand"
msgstr ""

#: of tvm.tir.op.bitwise_or:1
msgid "Take bitwise or of two values"
msgstr ""

#: of tvm.tir.op.bitwise_xor:1
msgid "Take bitwise xor of two values"
msgstr ""

#: of tvm.tir.build.build:1
msgid ""
"Build a function with a signature, generating code for devices coupled "
"with target information."
msgstr ""

#: of tvm.tir.build.build:4
msgid "The input to be built."
msgstr ""

#: of tvm.tir.build.build:6
msgid "The target for compilation."
msgstr ""

#: of tvm.tir.build.build:8
msgid "The pipeline to use for compilation."
msgstr ""

#: of tvm.tir.build.build:11
msgid "A module combining both host and device code."
msgstr ""

#: of tvm.tir.op.call_cpacked:1 tvm.tir.op.call_packed:1
msgid "Build expression by call an external packed function."
msgstr ""

#: of tvm.tir.op.call_cpacked:3
msgid ""
"Same as call_packed, except that the first argument is the function name "
"(as in call_extern), and the last argument is the resource handle."
msgstr ""

#: of tvm.tir.op.call_cpacked:6 tvm.tir.op.call_cpacked_lowered:5
#: tvm.tir.op.call_extern:7 tvm.tir.op.call_intrin:10
#: tvm.tir.op.call_llvm_intrin:7 tvm.tir.op.call_llvm_pure_intrin:7
#: tvm.tir.op.call_packed:10 tvm.tir.op.call_packed_lowered:8
#: tvm.tir.op.call_pure_extern:7 tvm.tir.op.trace:8
msgid "Positional arguments."
msgstr ""

#: of tvm.tir.op.call_cpacked:16 tvm.tir.op.call_cpacked_lowered:15
#: tvm.tir.op.call_packed:20 tvm.tir.op.call_packed_lowered:18
msgid ":py:obj:`te.extern`"
msgstr ""

#: of tvm.tir.op.call_cpacked:17 tvm.tir.op.call_cpacked_lowered:16
#: tvm.tir.op.call_packed:21 tvm.tir.op.call_packed_lowered:19
msgid "Create tensor with extern function call."
msgstr ""

#: of tvm.tir.op.call_cpacked_lowered:1
msgid ""
"Lowered version of call c-packed. Same as call_packed, except that the "
"first argument is the function name (as in call_extern), and the last "
"argument is the resource handle."
msgstr ""

#: of tvm.tir.op.call_extern:1
msgid "Build expression by calling a extern function."
msgstr ""

#: of tvm.tir.op.call_extern:3 tvm.tir.op.call_intrin:6
#: tvm.tir.op.call_llvm_intrin:3 tvm.tir.op.call_llvm_pure_intrin:3
#: tvm.tir.op.call_pure_extern:3 tvm.tir.op.get_active_lane_mask:6
#: tvm.tir.op.mma_fill:3 tvm.tir.op.mma_store:3 tvm.tir.op.ptx_cp_async:4
#: tvm.tir.op.ptx_cp_async_bulk:4 tvm.tir.op.ptx_ldmatrix:4
#: tvm.tir.op.ptx_mma:4 tvm.tir.op.ptx_mma_sp:4 tvm.tir.op.vectorhigh:3
#: tvm.tir.op.vectorlow:3
msgid "The data type of the result."
msgstr ""

#: of tvm.tir.op.call_extern:5 tvm.tir.op.call_pure_extern:5
msgid "The extern function name."
msgstr ""

#: of tvm.tir.op.call_intrin:1
msgid "Build expression by calling an intrinsic function."
msgstr ""

#: of tvm.tir.op.call_intrin:3
msgid ""
"Intrinsics can be overloaded with multiple data types via the intrinsic "
"translation rule."
msgstr ""

#: of tvm.tir.op.call_intrin:8
msgid "The intrinsic function name."
msgstr ""

#: of tvm.tir.op.call_llvm_intrin:1
msgid "Build expression by calling a llvm intrinsic function"
msgstr ""

#: of tvm.tir.op.call_llvm_intrin:5 tvm.tir.op.call_llvm_pure_intrin:5
msgid "The name of the llvm intrinsic function."
msgstr ""

#: of tvm.tir.op.call_llvm_pure_intrin:1
msgid "Build expression by calling a pure llvm intrinsic function"
msgstr ""

#: of tvm.tir.op.call_packed:3
msgid ""
"The argument to packed function can be Expr or Buffer. The argument is "
"the corresponding POD type when Expr is presented."
msgstr ""

#: of tvm.tir.op.call_packed:6
msgid ""
"When the argument is Buffer, the corresponding PackedFunc will receive an"
" TVMArrayHandle whose content is valid during the callback period. If the"
" PackedFunc is a python callback, then the corresponding argument is "
"Tensor."
msgstr ""

#: of tvm.tir.op.call_packed_lowered:1
msgid ""
"Lowered version of call packed. The argument to packed function can be "
"Expr or Buffer. The argument is the corresponding POD type when Expr is "
"presented. When the argument is Buffer, the corresponding PackedFunc will"
" recieve an TVMArrayHandle whose content is valid during the callback "
"period. If the PackedFunc is a python callback, then the corresponding "
"argument is Tensor."
msgstr ""

#: of tvm.tir.op.call_pure_extern:1
msgid "Build expression by calling a pure extern function."
msgstr ""

#: of tvm.tir.op.call_tir:1
msgid "Performs a call into another PrimFunc in the same IRModule"
msgstr ""

#: of tvm.tir.op.ceil:1
msgid "Take ceil of float input x."
msgstr ""

#: of tvm.tir.op.ceildiv:1
msgid "Generic ceildiv operator."
msgstr ""

#: of tvm.tir.op.ceildiv:10
msgid "**op** -- The result Expr of ceildiv operaton."
msgstr ""

#: of tvm.tir.op.clz:1
msgid "Count leading zero bits of an integer x."
msgstr ""

#: of tvm.tir.op.clz:3
msgid "Input 32 or 64 bit integer. The result is undefined if the input is 0."
msgstr ""

#: of tvm.tir.op.comm_reducer:1
msgid "Create a commutative reducer for reduction."
msgstr ""

#: of tvm.tir.op.comm_reducer:3
msgid "A binary function which takes two Expr as input to return a Expr."
msgstr ""

#: of tvm.tir.op.comm_reducer:5
msgid "A function which takes a type string as input to return a const Expr."
msgstr ""

#: of tvm.tir.op.comm_reducer:8
msgid ""
"**reducer** -- A function which creates a reduce expression over axis. "
"There are two ways to use it:  1. accept (expr, axis, where) to produce "
"an Reduce Expr on    specified axis; 2. simply use it with multiple "
"Exprs."
msgstr ""

#: of tvm.tir.op.comm_reducer:8
msgid ""
"**reducer** -- A function which creates a reduce expression over axis. "
"There are two ways to use it:"
msgstr ""

#: of tvm.tir.op.comm_reducer:11
msgid "accept (expr, axis, where) to produce an Reduce Expr on specified axis;"
msgstr ""

#: of tvm.tir.op.comm_reducer:13
msgid "simply use it with multiple Exprs."
msgstr ""

#: of tvm.tir.op.copysign:1
msgid "Change the sign of x1 to that of x2, element-wise."
msgstr ""

#: of tvm.tir.op.cos:1
msgid "Take cos of input x."
msgstr ""

#: of tvm.tir.op.cosh:1
msgid "Take cosh of input x."
msgstr ""

#: of tvm.tir.op.create_barriers:1
msgid "TVM intrinsic to create N barriers"
msgstr ""

#: of tvm.tir.op.create_barriers:3
msgid "The number of barriers to create."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:1
msgid "Declare a new symbolic buffer."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:3
msgid ""
"Normally buffer is created automatically during lower and build. This is "
"only needed if user want to specify their own buffer layout."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:6
msgid "See the note below for detailed discussion on usage of buffer."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:8
msgid "The shape of the buffer."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:12
msgid "The name of the buffer."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:14
msgid "The data pointer in the buffer."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:16
msgid "The stride of the buffer."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:18
msgid ""
"The beginning offset of the array to data. In terms of number of elements"
" of dtype."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:21
msgid ""
"The storage scope of the buffer, if not global. If scope equals empty "
"string, it means it is global memory."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:24
msgid ""
"The alignment of data pointer in bytes. If -1 is passed, the alignment "
"will be set to TVM's internal default."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:27
msgid ""
"The factor of elem_offset field, when set, elem_offset is required to be "
"multiple of offset_factor. If 0 is pssed, the alignment will be set to 1."
" if non-zero is passed, we will created a Var for elem_offset if "
"elem_offset is not None."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:32
msgid ""
"auto_broadcast buffer allows one to implement broadcast computation "
"without considering whether dimension size equals to one. TVM maps "
"buffer[i][j][k] -> buffer[i][0][k] if dimension j's shape equals 1."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:36
msgid ""
"If passed, a list of separators between groups of axes, each of which is "
"flattened to an output axis.  For flat memory spaces, should either be "
"None, or an empty list."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:40
msgid "The location of the decl_buffer creation in the source."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:43
msgid "**buffer** -- The created buffer"
msgstr ""

#: of tvm.tir.buffer.decl_buffer:48
msgid ""
"Buffer data structure reflects the DLTensor structure in dlpack. While "
"DLTensor data structure is very general, it is usually helpful to create "
"function that only handles specific case of data structure and make "
"compiled function benefit from it."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:53
msgid ""
"If user pass strides and elem_offset is passed as None when constructing "
"the function, then the function will be specialized for the DLTensor that"
" is compact and aligned. If user pass a fully generic symbolic array to "
"the strides, then the resulting function becomes fully generic."
msgstr ""

#: of tvm.tir.op.div:1
msgid "Compute a / b as in C/C++ semantics."
msgstr ""

#: of tvm.tir.op.div:3 tvm.tir.op.indexdiv:3 tvm.tir.op.indexmod:3
msgid "The left hand operand, known to be non-negative."
msgstr ""

#: of tvm.tir.op.div:5 tvm.tir.op.indexdiv:5 tvm.tir.op.indexmod:5
msgid "The right hand operand, known to be non-negative."
msgstr ""

#: of tvm.tir.op.div:10 tvm.tir.op.floordiv:10 tvm.tir.op.floormod:10
#: tvm.tir.op.indexdiv:10 tvm.tir.op.indexmod:10 tvm.tir.op.logaddexp:10
#: tvm.tir.op.truncdiv:10 tvm.tir.op.truncmod:10
msgid "**res** -- The result expression."
msgstr ""

#: of tvm.tir.op.div:13
msgid "When operands are integers, returns truncdiv(a, b, span)."
msgstr ""

#: of tvm.tir.op.dp4a:1
msgid "Dot product of two int8x4 vectors and add an optional accumulator"
msgstr ""

#: of tvm.tir.op.dp4a:3 tvm.tir.op.dp4a:5 tvm.tir.op.vectorcombine:3
#: tvm.tir.op.vectorcombine:5 tvm.tir.op.vectorhigh:5 tvm.tir.op.vectorlow:5
msgid "The input vector."
msgstr ""

#: of tvm.tir.op.dp4a:7
msgid "The accumulator."
msgstr ""

#: of tvm.tir.op.end_profile_intrinsic:1
msgid "End profile intrinsic. :param id: The intrinsic id. :type id: int"
msgstr ""

#: of tvm.tir.op.erf:1
msgid "Take gauss error function of the input x."
msgstr ""

#: of tvm.tir.op.exp:1
msgid "Take exponential of input x."
msgstr ""

#: of tvm.tir.op.exp10:1
msgid "Calculate 10**x"
msgstr ""

#: of tvm.tir.op.exp2:1
msgid "Calculate 2**x"
msgstr ""

#: of tvm.tir.op.floor:1
msgid "Take floor of float input x."
msgstr ""

#: of tvm.tir.op.floordiv:1
msgid "Compute the floordiv of two expressions."
msgstr ""

#: of tvm.tir.op.floordiv:3 tvm.tir.op.floormod:3 tvm.tir.op.logaddexp:3
#: tvm.tir.op.truncdiv:3 tvm.tir.op.truncmod:3
msgid "The left hand operand"
msgstr ""

#: of tvm.tir.op.floordiv:5 tvm.tir.op.floormod:5 tvm.tir.op.logaddexp:5
#: tvm.tir.op.truncdiv:5 tvm.tir.op.truncmod:5
msgid "The right hand operand"
msgstr ""

#: of tvm.tir.op.floormod:1
msgid "Compute the floormod of two expressions."
msgstr ""

#: of tvm.tir.op.fmod:1
msgid "Return the remainder of x divided by y with the same sign as x."
msgstr ""

#: of tvm.tir.op.fmod:8 tvm.tir.op.pow:10 tvm.tir.op.power:10
#: tvm.tir.op.q_multiply_shift_per_axis:18 tvm.tir.op.shift_left:8
#: tvm.tir.op.shift_right:8
msgid "**z** -- The result."
msgstr ""

#: of tvm.tir.op.get_active_lane_mask:1
msgid ""
"Calculate a predicate mask given an upper bound (limit) and a current "
"value (base)."
msgstr ""

#: of tvm.tir.op.get_active_lane_mask:3
msgid ""
"It will be lowered to the llvm.get.active.lane.mask intrinsic. "
"(https://llvm.org/docs/LangRef.html#llvm-get-active-lane-mask-intrinsics)"
msgstr ""

#: of tvm.tir.op.get_active_lane_mask:8
msgid "An expression reprsenting the base."
msgstr ""

#: of tvm.tir.op.get_active_lane_mask:10
msgid "An expression representing the limit."
msgstr ""

#: of tvm.tir.pipeline.get_default_tir_pipeline:1
msgid "Get the default TIR pipeline for the given target."
msgstr ""

#: of tvm.tir.pipeline.get_tir_pipeline:1
msgid "Get pre-build pipeline by name"
msgstr ""

#: of tvm.tir.pipeline.get_tir_pipeline:3
msgid "Name of the pipeline"
msgstr ""

#: of tvm.tir.op.get_vscale_expr:1
msgid "Create a datatype dependent scalable expression."
msgstr ""

#: of tvm.tir.op.get_vscale_expr:3
msgid "Element data type."
msgstr ""

#: of tvm.tir.op.get_vscale_expr:5
msgid "The minimum size of the scalable vector in bits."
msgstr ""

#: of tvm.tir.op.handle_add_byte_offset:1
msgid "Add offset to handle"
msgstr ""

#: of tvm.tir.op.handle_add_byte_offset:3
msgid "The handle."
msgstr ""

#: of tvm.tir.op.handle_add_byte_offset:5
msgid "The offset."
msgstr ""

#: of tvm.tir.op.hypot:1
msgid "Equivalent to sqrt(x1**2 + x2**2), element-wise."
msgstr ""

#: of tvm.tir.op.if_then_else:1
msgid "Conditional selection expression."
msgstr ""

#: of tvm.tir.op.if_then_else:3
msgid "The condition"
msgstr ""

#: of tvm.tir.op.if_then_else:5
msgid "The result expression if cond is true."
msgstr ""

#: of tvm.tir.op.if_then_else:7
msgid "The result expression if cond is false."
msgstr ""

#: of tvm.tir.op.if_then_else:12
msgid "**result** -- The result of conditional expression."
msgstr ""

#: of tvm.tir.op.if_then_else:17
msgid ""
"Unlike Select, if_then_else will not execute the branch that does not "
"satisfy the condition. You can use it to guard against out of bound "
"access. Unlike Select, if_then_else cannot be vectorized if some lanes in"
" the vector have different conditions."
msgstr ""

#: of tvm.tir.op.ignore_loop_partition:1
msgid ""
"Annotate a predicate not be considered as target condition of loop "
"partition."
msgstr ""

#: of tvm.tir.op.ignore_loop_partition:3
msgid "The annotated predicate expression."
msgstr ""

#: of tvm.tir.op.indexdiv:1
msgid "Compute floor(a / b) where a and b are non-negative."
msgstr ""

#: of tvm.tir.op.indexdiv:15 tvm.tir.op.indexmod:15
msgid ""
"Use this function to split non-negative indices. This function may take "
"advantage of operands' non-negativeness."
msgstr ""

#: of tvm.tir.op.indexmod:1
msgid "Compute the remainder of indexdiv. a and b are non-negative."
msgstr ""

#: of tvm.tir.op.infinity:1 tvm.tir.op.reinterpret:1
msgid "infinity value of dtype"
msgstr ""

#: of tvm.tir.op.infinity:3 tvm.tir.op.max_value:3 tvm.tir.op.min_value:3
#: tvm.tir.op.reinterpret:3 tvm.tir.op.type_annotation:3
msgid "The data type."
msgstr ""

#: of tvm.tir.op.infinity:8
msgid "**value** -- The infinity value of dtype."
msgstr ""

#: of tvm.tir.op.isfinite:1
msgid "Check if input value is finite."
msgstr ""

#: of tvm.tir.op.isinf:1
msgid "Check if input value is infinite."
msgstr ""

#: of tvm.tir.op.isnan:1
msgid "Check if input value is Nan."
msgstr ""

#: of tvm.tir.op.isnullptr:1
msgid "Check if input value is nullptr."
msgstr ""

#: of tvm.tir.data_layout.layout:1
msgid "Create a layout node from a string."
msgstr ""

#: of tvm.tir.data_layout.layout:3
msgid ""
"A layout representation is composed of upper cases, lower cases and "
"numbers, where upper case indicates a primal axis and the corresponding "
"lower case with factor size indicates the subordinate axis. For example, "
"NCHW16c can describe a 5-D tensor of [batch_size, channel, height, width,"
" channel_block]. Here subordinate axis channel_block=16 is the factor "
"size of the primal axis C (channel)."
msgstr ""

#: of tvm.tir.data_layout.layout:11
msgid ""
"The dtype of generated axes vars in the returned layout. It is required "
"to be integer type."
msgstr ""

#: of tvm.tir.data_layout.layout:15
msgid "**layout** -- The created layout"
msgstr ""

#: of tvm.tir.op.ldexp:1
msgid "Returns x1 * (2 ** x2)."
msgstr ""

#: of tvm.tir.op.likely:1
msgid "Mark condition as likely."
msgstr ""

#: of tvm.tir.op.likely:8
msgid "**y** -- The marked expression."
msgstr ""

#: of tvm.tir.op.log:1
msgid "Take log of input x."
msgstr ""

#: of tvm.tir.op.log10:1
msgid "Take log10 of input x."
msgstr ""

#: of tvm.tir.op.log1p:1
msgid "Take log(x + 1) with respect to input x."
msgstr ""

#: of tvm.tir.op.log2:1
msgid "Take log2 of input x."
msgstr ""

#: of tvm.tir.op.logaddexp:1
msgid "Compute the logaddexp of two expressions."
msgstr ""

#: of tvm.tir.op.lookup_param:1
msgid "Returns the param by name"
msgstr ""

#: of tvm.tir.op.lookup_param:3
msgid "The name of param."
msgstr ""

#: of tvm.tir.op.make_filled_simdgroup_matrix:1
msgid "Create a filled SIMDGroup matrix"
msgstr ""

#: of tvm.tir.op.make_filled_simdgroup_matrix:3 tvm.tir.op.simdgroup_load:3
msgid "The simdgroup var"
msgstr ""

#: of tvm.tir.op.make_filled_simdgroup_matrix:5 tvm.tir.op.simdgroup_load:5
#: tvm.tir.op.simdgroup_store:5
msgid "The index of the matrix."
msgstr ""

#: of tvm.tir.op.make_filled_simdgroup_matrix:7
msgid "The value to fill."
msgstr ""

#: of tvm.tir.op.make_filled_simdgroup_matrix:9 tvm.tir.op.simdgroup_load:11
#: tvm.tir.op.simdgroup_store:11
msgid "The number of columns."
msgstr ""

#: of tvm.tir.op.make_filled_simdgroup_matrix:11 tvm.tir.op.simdgroup_load:13
#: tvm.tir.op.simdgroup_store:13
msgid "The number of rows."
msgstr ""

#: of tvm.tir.op.comm_reducer.<locals>.reducer:1
msgid "Create a max expression over axis."
msgstr ""

#: of tvm.tir.op.comm_reducer.<locals>.reducer:5
msgid "The reduction IterVar axis"
msgstr ""

#: of tvm.tir.op.comm_reducer.<locals>.reducer:7
msgid "Filtering predicate of the reduction."
msgstr ""

#: of tvm.tir.op.comm_reducer.<locals>.reducer:10
msgid "**value** -- The result value."
msgstr ""

#: of tvm.tir.op.max_value:1
msgid "maximum value of dtype"
msgstr ""

#: of tvm.tir.op.max_value:8
msgid "**value** -- The maximum value of dtype."
msgstr ""

#: of tvm.tir.op.comm_reducer.<locals>.reducer:1
msgid "Create a min expression over axis."
msgstr ""

#: of tvm.tir.op.min_value:1
msgid "minimum value of dtype"
msgstr ""

#: of tvm.tir.op.min_value:8
msgid "**value** -- The minimum value of dtype."
msgstr ""

#: of tvm.tir.op.mma_fill:1
msgid "TVM intrinsic for zero-initalizing an MMA accumulation registor"
msgstr ""

#: of tvm.tir.op.mma_fill:5
msgid "The number of elements."
msgstr ""

#: of tvm.tir.op.mma_fill:7 tvm.tir.op.mma_store:9
msgid "The destination pointer variable."
msgstr ""

#: of tvm.tir.op.mma_fill:9
msgid "The destination offset."
msgstr ""

#: of tvm.tir.op.mma_store:1
msgid "TVM intrinsic for storing the result of PTX MMA into a destination pointer"
msgstr ""

#: of tvm.tir.op.mma_store:5 tvm.tir.op.mma_store:7 tvm.tir.op.ptx_mma:6
#: tvm.tir.op.ptx_mma_sp:6
msgid "The shape of mma fragment."
msgstr ""

#: of tvm.tir.op.mma_store:11
msgid "The source pointer variable."
msgstr ""

#: of tvm.tir.op.mma_store:13
msgid "The source offset."
msgstr ""

#: of tvm.tir.op.mma_store:15
msgid "The destination stride."
msgstr ""

#: of tvm.tir.generic.multiply:1
msgid "Generic multiply operator."
msgstr ""

#: of tvm.tir.generic.multiply:10
msgid "**op** -- The result Expr of multiply operaton."
msgstr ""

#: of tvm.tir.op.nearbyint:1
msgid ""
"Round elements of the array to the nearest integer. This intrinsic uses "
"llvm.nearbyint instead of llvm.round which is faster but will results "
"different from te.round. Notably nearbyint rounds according to the "
"rounding mode, whereas te.round (llvm.round) ignores that. For "
"differences between the two see: "
"https://en.cppreference.com/w/cpp/numeric/math/round "
"https://en.cppreference.com/w/cpp/numeric/math/nearbyint"
msgstr ""

#: of tvm.tir.op.nextafter:1
msgid "Return the next floating-point value after x1 towards x2."
msgstr ""

#: of tvm.tir.op.popcount:1
msgid "Count the number of set bits in input x."
msgstr ""

#: of tvm.tir.op.pow:1 tvm.tir.op.power:1
msgid "x power y"
msgstr ""

#: of tvm.tir.op.pow:5 tvm.tir.op.power:5
msgid "The exponent"
msgstr ""

#: of tvm.tir.op.ptx_arrive_barrier:1
msgid ""
"TVM intrinsic for ptx barrier arrival using mbarrier.arrive "
"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html"
"#parallel-synchronization-and-communication-instructions-mbarrier-arrive"
msgstr ""

#: of tvm.tir.op.ptx_arrive_barrier:4 tvm.tir.op.ptx_arrive_barrier_expect_tx:5
#: tvm.tir.op.ptx_cp_async_barrier:4 tvm.tir.op.ptx_cp_async_bulk:16
#: tvm.tir.op.ptx_init_barrier_thread_count:4 tvm.tir.op.ptx_wait_barrier:4
msgid "The ID of the barrier shared memory pointer."
msgstr ""

#: of tvm.tir.op.ptx_arrive_barrier_expect_tx:1
msgid ""
"TVM intrinsic for ptx barrier arrival with expect tx using "
"mbarrier.arrive.expect_tx https://docs.nvidia.com/cuda/parallel-thread-"
"execution/index.html#parallel-synchronization-and-communication-"
"instructions-mbarrier-arrive https://docs.nvidia.com/cuda/parallel-"
"thread-execution/index.html#parallel-synchronization-and-communication-"
"instructions-mbarrier-expect-tx-operation"
msgstr ""

#: of tvm.tir.op.ptx_arrive_barrier_expect_tx:7
msgid ""
"Increases the tx count of the mbarrier object to track completion of "
"addtional async transactions."
msgstr ""

#: of tvm.tir.op.ptx_commit_group:1
msgid ""
"TVM intrinsic for ptx async copy commit https://docs.nvidia.com/cuda"
"/parallel-thread-execution/index.html#data-movement-and-conversion-"
"instructions-cp-async-commit-group"
msgstr ""

#: of tvm.tir.op.ptx_cp_async:1
msgid ""
"TVM intrinsic for ptx async copy from global to shared memory using "
"cp.async https://docs.nvidia.com/cuda/parallel-thread-"
"execution/index.html#data-movement-and-conversion-instructions-cp-async"
msgstr ""

#: of tvm.tir.op.ptx_cp_async:6 tvm.tir.op.ptx_cp_async_bulk:6
#: tvm.tir.op.ptx_ldmatrix:16
msgid "The shared memory pointer variable."
msgstr ""

#: of tvm.tir.op.ptx_cp_async:8 tvm.tir.op.ptx_cp_async_bulk:8
msgid "The offset of shared memory pointer."
msgstr ""

#: of tvm.tir.op.ptx_cp_async:10 tvm.tir.op.ptx_cp_async_bulk:10
msgid "The global memory pointer variable."
msgstr ""

#: of tvm.tir.op.ptx_cp_async:12 tvm.tir.op.ptx_cp_async_bulk:12
msgid "The offset of global memory pointer."
msgstr ""

#: of tvm.tir.op.ptx_cp_async:14 tvm.tir.op.ptx_cp_async_bulk:14
msgid "The data size to copy."
msgstr ""

#: of tvm.tir.op.ptx_cp_async_barrier:1
msgid ""
"TVM intrinsic for ptx async copy barrier using cp.async.mbarrier.arrive "
"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html"
"#parallel-synchronization-and-communication-instructions-cp-async-"
"mbarrier-arrive"
msgstr ""

#: of tvm.tir.op.ptx_cp_async_bulk:1
msgid ""
"TVM intrinsic for ptx async copy from global to shared memory using "
"cp.async.bulk https://docs.nvidia.com/cuda/parallel-thread-"
"execution/index.html#data-movement-and-conversion-instructions-cp-async-"
"bulk"
msgstr ""

#: of tvm.tir.op.ptx_init_barrier_thread_count:1
msgid ""
"TVM intrinsic for ptx barrier initialization of thread count using "
"mbarrier.init https://docs.nvidia.com/cuda/parallel-thread-"
"execution/index.html#parallel-synchronization-and-communication-"
"instructions-mbarrier-init"
msgstr ""

#: of tvm.tir.op.ptx_init_barrier_thread_count:6
msgid "Number of threads expected to arrive at the barrier."
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:1
msgid ""
"TVM intrinsic for ptx load matrix from shared memory "
"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-"
"level-matrix-instructions-ldmatrix"
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:6
msgid "The matrix is loaded in column-major format."
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:8
msgid "The number of matrices."
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:10
msgid "The data type of the matrices."
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:12
msgid "The local pointer variable."
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:14
msgid "The offset of local pointer."
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:18
msgid "The offset of shared memort pointer."
msgstr ""

#: of tvm.tir.op.ptx_mma:1
msgid ""
"TVM intrinsic for ptx tensor core mma instructions "
"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-"
"level-matrix-instructions-for-mma"
msgstr ""

#: of tvm.tir.op.ptx_mma:8 tvm.tir.op.ptx_mma_sp:8
msgid "The layout of multiplicand fragment A."
msgstr ""

#: of tvm.tir.op.ptx_mma:10 tvm.tir.op.ptx_mma_sp:10
msgid "The layout of multiplicand fragment B."
msgstr ""

#: of tvm.tir.op.ptx_mma:12 tvm.tir.op.ptx_mma_sp:12
msgid "The data type of multiplicand fragment A."
msgstr ""

#: of tvm.tir.op.ptx_mma:14 tvm.tir.op.ptx_mma_sp:14
msgid "The data type of multiplicand fragment B."
msgstr ""

#: of tvm.tir.op.ptx_mma:16
msgid "The data type of accumulator fragment C."
msgstr ""

#: of tvm.tir.op.ptx_mma:18 tvm.tir.op.ptx_mma_sp:18
msgid "The multiplicand fragment A variable."
msgstr ""

#: of tvm.tir.op.ptx_mma:20 tvm.tir.op.ptx_mma:24 tvm.tir.op.ptx_mma_sp:20
msgid "The index of multiplicand fragment A."
msgstr ""

#: of tvm.tir.op.ptx_mma:22 tvm.tir.op.ptx_mma_sp:22
msgid "The multiplicand fragment B variable."
msgstr ""

#: of tvm.tir.op.ptx_mma:26 tvm.tir.op.ptx_mma_sp:26
msgid "The accumulator fragment C variable."
msgstr ""

#: of tvm.tir.op.ptx_mma:28 tvm.tir.op.ptx_mma_sp:28
msgid "The index of accumulator fragment C."
msgstr ""

#: of tvm.tir.op.ptx_mma:30 tvm.tir.op.ptx_mma_sp:36
msgid "The optional saturation at the output."
msgstr ""

#: of tvm.tir.op.ptx_mma:32
msgid "The 1-bit operator."
msgstr ""

#: of tvm.tir.op.ptx_mma_sp:1
msgid ""
"TVM intrinsic for sparse tensor core ptx instructions "
"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-"
"level-matrix-instructions-for-sparse-mma"
msgstr ""

#: of tvm.tir.op.ptx_mma_sp:16
msgid "The data type of multiplicand fragment C."
msgstr ""

#: of tvm.tir.op.ptx_mma_sp:24
msgid "The index of multiplicand fragment B."
msgstr ""

#: of tvm.tir.op.ptx_mma_sp:30
msgid "The metadata of operand."
msgstr ""

#: of tvm.tir.op.ptx_mma_sp:32
msgid "The metadata index of operand."
msgstr ""

#: of tvm.tir.op.ptx_mma_sp:34
msgid "The sparse selector indicating the thread that stores the metadata."
msgstr ""

#: of tvm.tir.op.ptx_wait_barrier:1
msgid ""
"TVM intrinsic for ptx barrier wait using mbarrier.try_wait "
"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html"
"#parallel-synchronization-and-communication-instructions-mbarrier-test-"
"wait-mbarrier-try-wait"
msgstr ""

#: of tvm.tir.op.ptx_wait_group:1
msgid ""
"TVM intrinsic for ptx async copy wait https://docs.nvidia.com/cuda"
"/parallel-thread-execution/index.html#data-movement-and-conversion-"
"instructions-cp-async-wait-group"
msgstr ""

#: of tvm.tir.op.ptx_wait_group:4
msgid "The number of the most recent uncommitted pending cp.async groups to wait."
msgstr ""

#: of tvm.tir.op.q_multiply_shift:1
msgid ""
"Execute a multiplication between two Q-numbers x and y followed by a "
"right shift s. The mathematical expression is:"
msgstr ""

#: of tvm.tir.op.q_multiply_shift:4
msgid "out = round(x*y*2^-s)"
msgstr ""

#: of tvm.tir.op.q_multiply_shift:6
msgid ""
"More about Q-numbers here: "
"https://en.wikipedia.org/wiki/Q_(number_format) The rounding rule is to "
"the nearest value, rounding half up (i.e., round(x.1) = x and round (x.5)"
" = x+1)"
msgstr ""

#: of tvm.tir.op.q_multiply_shift:10
msgid "First Q-number"
msgstr ""

#: of tvm.tir.op.q_multiply_shift:12
msgid "Second Q-number"
msgstr ""

#: of tvm.tir.op.q_multiply_shift:14
msgid "Number of fractional bits in x and y. Needs to be > 0"
msgstr ""

#: of tvm.tir.op.q_multiply_shift:16
msgid "Integer shift"
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:1
msgid "Execute a multiplication between two Q-numbers x and y"
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:3
msgid "First Q-number."
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:5
msgid "Second Q-number."
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:7
msgid "Integer left shift."
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:9
msgid "Integer right shift."
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:11
msgid "Number of fractional bits in x and y. Needs to be > 0."
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:13
msgid "Whether we need to do left shift or not."
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:15
msgid "Whether we need to do right shift or not."
msgstr ""

#: of tvm.tir.op.reinterpret:5
msgid "The input value."
msgstr ""

#: of tvm.tir.op.reinterpret:10
msgid "**value** -- The reinterpret cast value of dtype."
msgstr ""

#: of tvm.tir.op.ret:1
msgid "Create a tir return expression"
msgstr ""

#: of tvm.tir.op.ret:3
msgid ""
"The returned tir expression, whose data type is int, float or void "
"pointer."
msgstr ""

#: of tvm.tir.op.ret:8 tvm.tir.op.tvm_throw_last_error:3
msgid "**ret** -- The return expression"
msgstr ""

#: of tvm.tir.op.round:1
msgid "Round elements of the array to the nearest integer."
msgstr ""

#: of tvm.tir.op.rsqrt:1
msgid "Take reciprocal of square root of input x."
msgstr ""

#: of tvm.tir.op.shift_left:1
msgid "Return the result of x left shifted by y bits."
msgstr ""

#: of tvm.tir.op.shift_right:1
msgid "Return the result of x right shifted by y bits."
msgstr ""

#: of tvm.tir.op.sigmoid:1
msgid "Quick function to get sigmoid"
msgstr ""

#: of tvm.tir.op.simdgroup_load:1
msgid "Load data from device memory or threadgroup memory to simdgroup"
msgstr ""

#: of tvm.tir.op.simdgroup_load:7 tvm.tir.op.simdgroup_store:7
msgid "The pointer."
msgstr ""

#: of tvm.tir.op.simdgroup_load:9 tvm.tir.op.simdgroup_store:9
msgid "The stride."
msgstr ""

#: of tvm.tir.op.simdgroup_load:15 tvm.tir.op.simdgroup_store:17
msgid "Whether to transpose the matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:1
msgid "Multiply and accumulate two matrices in simdgroup i.e. d = a * b + c"
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:4
msgid "The destination matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:6
msgid "The index of the destination matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:8
msgid "The first matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:10
msgid "The index of the first matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:12
msgid "The second matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:14
msgid "The index of the second matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:16
msgid "The third matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:18
msgid "The index of the third matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_store:1
msgid "Store data from simdgroup to device memory or threadgroup memory"
msgstr ""

#: of tvm.tir.op.simdgroup_store:3
msgid "The SIMDGroup."
msgstr ""

#: of tvm.tir.op.simdgroup_store:16
msgid "transpose_matrix"
msgstr ""

#: of tvm.tir.op.simdgroup_store:-1
msgid "bool"
msgstr ""

#: of tvm.tir.op.sin:1
msgid "Take sin of input x."
msgstr ""

#: of tvm.tir.op.sinh:1
msgid "Take sinh of input x."
msgstr ""

#: of tvm.tir.op.sqrt:1
msgid "Take square root of input x."
msgstr ""

#: of tvm.tir.op.start_profile_intrinsic:1
msgid "Start profile intrinsic. :param id: The intrinsic id. :type id: int"
msgstr ""

#: of tvm.tir.stmt.stmt_list:1
msgid "Make list of stmt from blocks."
msgstr ""

#: of tvm.tir.stmt.stmt_list:3
msgid "The input statement."
msgstr ""

#: of tvm.tir.stmt.stmt_list:6
msgid "**stmt_list** -- The unpacked list of statements"
msgstr ""

#: of tvm.tir.stmt.stmt_seq:1
msgid "Make sequence of statements"
msgstr ""

#: of tvm.tir.stmt.stmt_seq:3
msgid "List of statements to be combined as sequence."
msgstr ""

#: of tvm.tir.stmt.stmt_seq:6
msgid "**stmt** -- The combined statement."
msgstr ""

#: of tvm.tir.generic.subtract:1
msgid "Generic subtract operator."
msgstr ""

#: of tvm.tir.generic.subtract:10
msgid "**op** -- The result Expr of subtract operaton."
msgstr ""

#: of tvm.tir.op.comm_reducer.<locals>.reducer:1
msgid "Create a sum expression over axis."
msgstr ""

#: of tvm.tir.op.tan:1
msgid "Take tan of input x."
msgstr ""

#: of tvm.tir.op.tanh:1
msgid "Take hyperbolic tanh of input x."
msgstr ""

#: of tvm.tir.op.trace:1
msgid "Trace tensor data at the runtime."
msgstr ""

#: of tvm.tir.op.trace:3
msgid ""
"The trace function allows to trace specific tensor at the runtime. The "
"tracing value should come as last argument. The trace action should be "
"specified, by default tvm.default_trace_action is used."
msgstr ""

#: of tvm.tir.op.trace:10
msgid "The name of the trace action."
msgstr ""

#: of tvm.tir.op.trace:18
msgid ":py:obj:`tvm.tir.call_packed`"
msgstr ""

#: of tvm.tir.op.trace:19
msgid "Creates packed function."
msgstr ""

#: of tvm.tir.op.trunc:1
msgid "Get truncated value of the input."
msgstr ""

#: of tvm.tir.op.trunc:3
msgid ""
"The truncated value of the scalar x is the nearest integer i which is "
"closer to zero than x is."
msgstr ""

#: of tvm.tir.op.truncdiv:1
msgid "Compute the truncdiv of two expressions."
msgstr ""

#: of tvm.tir.op.truncdiv:13 tvm.tir.op.truncmod:13
msgid "This is the default integer division behavior in C."
msgstr ""

#: of tvm.tir.op.truncmod:1
msgid "Compute the truncmod of two expressions."
msgstr ""

#: of tvm.tir.op.tvm_access_ptr:1
msgid "Get head access address with memory access pattern info"
msgstr ""

#: of tvm.tir.op.tvm_access_ptr:3
msgid "The data type of pointer."
msgstr ""

#: of tvm.tir.op.tvm_access_ptr:5
msgid "The data of pointer."
msgstr ""

#: of tvm.tir.op.tvm_access_ptr:7
msgid "The offset of pointer."
msgstr ""

#: of tvm.tir.op.tvm_access_ptr:11
msgid "The read write mask."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:1
msgid "TVM intrinsic for tensor core bmma_sync operators"
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:3
msgid "The bwmma fragment_d."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:5 tvm.tir.op.tvm_mma_sync:5
msgid "The fragment_d index."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:7
msgid "The bwmma fragment_a."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:9 tvm.tir.op.tvm_mma_sync:9
msgid "The fragment_a index."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:11
msgid "The bwmma fragment_b."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:13 tvm.tir.op.tvm_mma_sync:13
msgid "The fragment_b index."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:15
msgid "The bwmma fragment_c."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:17 tvm.tir.op.tvm_mma_sync:17
msgid "The fragment_c index."
msgstr ""

#: of tvm.tir.op.tvm_fill_fragment:1
msgid "TVM intrinsic for tensor core fill_fragment operators"
msgstr ""

#: of tvm.tir.op.tvm_fill_fragment:3
msgid "The wmma fragment"
msgstr ""

#: of tvm.tir.op.tvm_fill_fragment:5 tvm.tir.op.tvm_fill_fragment:7
#: tvm.tir.op.tvm_fill_fragment:9 tvm.tir.op.tvm_load_matrix_sync:5
#: tvm.tir.op.tvm_load_matrix_sync:7 tvm.tir.op.tvm_load_matrix_sync:9
#: tvm.tir.op.tvm_store_matrix_sync:5 tvm.tir.op.tvm_store_matrix_sync:7
#: tvm.tir.op.tvm_store_matrix_sync:9
msgid "The shape of wmma fragment."
msgstr ""

#: of tvm.tir.op.tvm_fill_fragment:11 tvm.tir.op.tvm_load_matrix_sync:11
#: tvm.tir.op.tvm_store_matrix_sync:11
msgid "The fragment index."
msgstr ""

#: of tvm.tir.op.tvm_fill_fragment:13
msgid "The value to be filled in fragment."
msgstr ""

#: of tvm.tir.op.tvm_load_matrix_sync:1
msgid "TVM intrinsic for tensor core load operators"
msgstr ""

#: of tvm.tir.op.tvm_load_matrix_sync:3 tvm.tir.op.tvm_store_matrix_sync:3
msgid "The wmma fragment."
msgstr ""

#: of tvm.tir.op.tvm_load_matrix_sync:13 tvm.tir.op.tvm_store_matrix_sync:13
msgid "The fragment buffer pointer."
msgstr ""

#: of tvm.tir.op.tvm_load_matrix_sync:15 tvm.tir.op.tvm_store_matrix_sync:15
msgid "The fragment stride."
msgstr ""

#: of tvm.tir.op.tvm_load_matrix_sync:17 tvm.tir.op.tvm_store_matrix_sync:17
msgid "The fragment layout."
msgstr ""

#: of tvm.tir.op.tvm_mma_sync:1
msgid "TVM intrinsic for tensor core mma_sync operators"
msgstr ""

#: of tvm.tir.op.tvm_mma_sync:3
msgid "The wmma fragment_d."
msgstr ""

#: of tvm.tir.op.tvm_mma_sync:7
msgid "The wmma fragment_a."
msgstr ""

#: of tvm.tir.op.tvm_mma_sync:11
msgid "The wmma fragment_b."
msgstr ""

#: of tvm.tir.op.tvm_mma_sync:15
msgid "The wmma fragment_c."
msgstr ""

#: of tvm.tir.op.tvm_stack_alloca:1
msgid "Return new on stack dtype[num]"
msgstr ""

#: of tvm.tir.op.tvm_stack_alloca:3 tvm.tir.op.tvm_stack_make_array:11
msgid "The data type of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_alloca:5
msgid "The size of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_make_array:1
msgid "Allocate a Tensor(DLTensor) on stack, return the handle"
msgstr ""

#: of tvm.tir.op.tvm_stack_make_array:3
msgid "The data of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_make_array:5
msgid "The shape of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_make_array:7
msgid "The strides of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_make_array:9
msgid "The dimensions of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_make_array:13
msgid "The element offset of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_make_shape:1
msgid "Allocate a shape tuple on stack, return the handle"
msgstr ""

#: of tvm.tir.op.tvm_stack_make_shape:3
msgid "The tuple shape."
msgstr ""

#: of tvm.tir.op.tvm_store_matrix_sync:1
msgid "TVM intrinsic for tensor core store operators"
msgstr ""

#: of tvm.tir.op.tvm_struct_get:1
msgid "Get struct field value in array"
msgstr ""

#: of tvm.tir.op.tvm_struct_get:3
msgid "The date type of the result."
msgstr ""

#: of tvm.tir.op.tvm_struct_get:5 tvm.tir.op.tvm_struct_set:3
msgid "The array of struct."
msgstr ""

#: of tvm.tir.op.tvm_struct_get:7 tvm.tir.op.tvm_struct_set:5
msgid "The index of struct."
msgstr ""

#: of tvm.tir.op.tvm_struct_get:9 tvm.tir.op.tvm_struct_set:7
msgid "The field of struct."
msgstr ""

#: of tvm.tir.op.tvm_struct_set:1
msgid "Set value in struct field in array"
msgstr ""

#: of tvm.tir.op.tvm_struct_set:9
msgid "The value to be set in field."
msgstr ""

#: of tvm.tir.op.tvm_thread_allreduce:1
msgid "Perform allreduce inside threadblock."
msgstr ""

#: of tvm.tir.op.tvm_thread_allreduce:3
msgid "The args."
msgstr ""

#: of tvm.tir.op.tvm_throw_last_error:1
msgid "Throw TVMGetLastError()"
msgstr ""

#: of tvm.tir.op.tvm_tuple:1
msgid "Create a tuple structure in value field of AttrStmt"
msgstr ""

#: of tvm.tir.op.tvm_tuple:3
msgid "The value in tuple."
msgstr ""

#: of tvm.tir.op.type_annotation:1
msgid "Create a type annotation expression"
msgstr ""

#: of tvm.tir.op.undef:1
msgid "Returns an initialized but arbitrary value"
msgstr ""

#: of tvm.tir.op.vectorcombine:1
msgid "Concat two vectors"
msgstr ""

#: of tvm.tir.op.vectorhigh:1
msgid "Get the high level half of the vector"
msgstr ""

#: of tvm.tir.op.vectorlow:1
msgid "Get the low level half of the vector"
msgstr ""

#: of tvm.tir.op.vscale:1
msgid ""
"Get the target's vscale value. It will be lowered to llvm.vscale "
"intrinsic (https://llvm.org/docs/LangRef.html#llvm-vscale-intrinsic) "
":returns: **call** -- Call to the vscale intrinsic :rtype: PrimExpr"
msgstr ""

#~ msgid ""
#~ "Here's an example of how broadcast "
#~ "buffer can be used to define a "
#~ "symbolic broadcast operation,"
#~ msgstr ""

#~ msgid "Any node."
#~ msgstr ""

#~ msgid "span"
#~ msgstr ""

#~ msgid "Optional[Span]"
#~ msgstr ""

#~ msgid "Namespace for Tensor-level IR"
#~ msgstr ""

#~ msgid "Add node."
#~ msgstr ""

#~ msgid "参数"
#~ msgstr ""

#~ msgid "The left hand operand."
#~ msgstr ""

#~ msgid "The right hand operand."
#~ msgstr ""

#~ msgid "The location of this expression in the source code."
#~ msgstr ""

#~ msgid "Allocate node."
#~ msgstr ""

#~ msgid "The buffer variable."
#~ msgstr ""

#~ msgid "The data type of the buffer."
#~ msgstr ""

#~ msgid "The extents of the allocate"
#~ msgstr ""

#~ msgid "The condition."
#~ msgstr ""

#~ msgid "The body statement."
#~ msgstr ""

#~ msgid "Additional annotation hints"
#~ msgstr ""

#~ msgid "The location of the stmt in the source code."
#~ msgstr ""

#~ msgid "Allocate constant node."
#~ msgstr ""

#~ msgid ""
#~ "If an NDArray, this is the const"
#~ " data associated with the constant.  "
#~ "If an integer, this is the index"
#~ " into the \"constants\" attribute of "
#~ "the `IRModule` that contains the "
#~ "`AllocateConst`."
#~ msgstr ""

#~ msgid "Additional annotations about the allocation."
#~ msgstr ""

#~ msgid "And node."
#~ msgstr ""

#~ msgid "AssertStmt node."
#~ msgstr ""

#~ msgid "The assert condition."
#~ msgstr ""

#~ msgid "The error message."
#~ msgstr ""

#~ msgid "AttrStmt node."
#~ msgstr ""

#~ msgid "The node to annotate the attribute"
#~ msgstr ""

#~ msgid "Attribute type key."
#~ msgstr ""

#~ msgid "The value of the attribute"
#~ msgstr ""

#~ msgid ""
#~ "Bijective mapping for two layouts "
#~ "(src-layout and dst-layout). It "
#~ "provides shape and index conversion "
#~ "between each other."
#~ msgstr ""

#~ msgid ""
#~ "Do not construct directly, use "
#~ ":any:`bijective_layout` instead. See the "
#~ "documentation of :any:`bijective_layout` for "
#~ "more details."
#~ msgstr ""

#~ msgid "source layout."
#~ msgstr ""

#~ msgid "destination layout."
#~ msgstr ""

#~ msgid ":obj:`bijective_layout`"
#~ msgstr ""

#~ msgid "Declare a layout"
#~ msgstr ""

#~ msgid "Given the indices of the dst-layout, infer the src index."
#~ msgstr ""

#~ msgid "The indices in dst-layout."
#~ msgstr ""

#~ msgid "返回"
#~ msgstr ""

#~ msgid "**src_index** -- The inferred indices in src-layout."
#~ msgstr ""

#~ msgid "返回类型"
#~ msgstr ""

#~ msgid "Given the shape of the dst-layout, infer the src shape."
#~ msgstr ""

#~ msgid "The shape in dst-layout."
#~ msgstr ""

#~ msgid "**src_shape** -- The inferred shape in src-layout."
#~ msgstr ""

#~ msgid "Given the indices of the src-layout, infer the dst index."
#~ msgstr ""

#~ msgid "The indices in src-layout."
#~ msgstr ""

#~ msgid "**dst_index** -- The inferred indices in dst-layout."
#~ msgstr ""

#~ msgid "Given the shape of the src-layout, infer the dst shape."
#~ msgstr ""

#~ msgid "The shape in src-layout."
#~ msgstr ""

#~ msgid "**dst_shape** -- The inferred shape in dst-layout."
#~ msgstr ""

#~ msgid "Block node."
#~ msgstr ""

#~ msgid "The block Variable."
#~ msgstr ""

#~ msgid "The read buffer regions of the block."
#~ msgstr ""

#~ msgid "The write buffer regions of the block."
#~ msgstr ""

#~ msgid "the name_hint of the block."
#~ msgstr ""

#~ msgid "The body of the block."
#~ msgstr ""

#~ msgid "The init block of the reduction block"
#~ msgstr ""

#~ msgid "The buffer allocations"
#~ msgstr ""

#~ msgid "The subregion buffer match"
#~ msgstr ""

#~ msgid "Additional annotation hints."
#~ msgstr ""

#~ msgid "The location of this block in the source code."
#~ msgstr ""

#~ msgid ""
#~ "An object that helps build and "
#~ "query block level dependences using the"
#~ " 2 core objects BlockScope and "
#~ "StmtSRef"
#~ msgstr ""

#~ msgid ""
#~ "The data structures exposed are: 1) "
#~ "sref2scope: Mapping from the srefs to"
#~ " its corresponding BlockScope 2) stmt2ref:"
#~ " Mapping from blocks to corresponding "
#~ "StmtSRefs"
#~ msgstr ""

#~ msgid ""
#~ "Note that this object does not "
#~ "store SRefs to loops as the "
#~ "purpose is only to expose block "
#~ "level dependences. This provides the "
#~ "advantage that the scope block (parent"
#~ " block) for a given block sref "
#~ "can be directly accessed as sref->parent"
#~ msgstr ""

#~ msgid "Get the BlockScope correpsonding to the block sref"
#~ msgstr ""

#~ msgid "The block sref to be retrieved"
#~ msgstr ""

#~ msgid "**scope** -- The corresponding BlockScope"
#~ msgstr ""

#~ msgid "Return the corresponding sref that points to the block"
#~ msgstr ""

#~ msgid "The block for which the sref is to be retrived"
#~ msgstr ""

#~ msgid "**sref** -- The corresponding sref"
#~ msgstr ""

#~ msgid "BlockRealize node."
#~ msgstr ""

#~ msgid "The binding values of the block var."
#~ msgstr ""

#~ msgid "The predicate of the block."
#~ msgstr ""

#~ msgid "The block to realize"
#~ msgstr ""

#~ msgid "The location of this block_realize in the source code."
#~ msgstr ""

#~ msgid "Broadcast node."
#~ msgstr ""

#~ msgid "The value of the expression."
#~ msgstr ""

#~ msgid "The lanes of the expression."
#~ msgstr ""

#~ msgid "Symbolic data buffer in TVM."
#~ msgstr ""

#~ msgid ""
#~ "Buffer provide a way to represent "
#~ "data layout specialization of data "
#~ "structure in TVM."
#~ msgstr ""

#~ msgid ""
#~ "Do not construct directly, use "
#~ ":py:func:`~decl_buffer` instead. See the "
#~ "documentation of :py:func:`decl_buffer` for "
#~ "more details."
#~ msgstr ""

#~ msgid ":obj:`decl_buffer`"
#~ msgstr ""

#~ msgid "Declare a buffer"
#~ msgstr ""

#~ msgid "Get an access pointer to the head of buffer."
#~ msgstr ""

#~ msgid ""
#~ "This is the recommended method to "
#~ "get buffer data ptress when interacting"
#~ " with external functions."
#~ msgstr ""

#~ msgid ""
#~ "The access pattern MASK. Indicate "
#~ "whether the access will read or "
#~ "write to the data content."
#~ msgstr ""

#~ msgid ""
#~ "The data type of the result "
#~ "pointer. Do not specify unless we "
#~ "want to cast pointer to specific "
#~ "type."
#~ msgstr ""

#~ msgid ""
#~ "The number of lanes for the data"
#~ " type. This value is greater than "
#~ "one for vector types."
#~ msgstr ""

#~ msgid ""
#~ "The offset of pointer. We can use"
#~ " it to offset by the number of"
#~ " elements from the address of ptr."
#~ msgstr ""

#~ msgid "The extent of pointer."
#~ msgstr ""

#~ msgid "示例"
#~ msgstr ""

#~ msgid "Generate a Buffer that is a flattened version of this buffer."
#~ msgstr ""

#~ msgid "**flattened** -- The corresponding flat buffer."
#~ msgstr ""

#~ msgid "Determine the offset of the provided indices in the flattened buffer."
#~ msgstr ""

#~ msgid "The indices of the element in the original buffer."
#~ msgstr ""

#~ msgid ""
#~ "**flattened_indices** -- The offset indices"
#~ " of the element in the flattened "
#~ "buffer."
#~ msgstr ""

#~ msgid ""
#~ "Return the storage scope associated with"
#~ " this buffer. :returns: **scope** -- "
#~ "The storage scope associated with this"
#~ " buffer. :rtype: str"
#~ msgstr ""

#~ msgid "Generate an Expr that loads dtype from begin index."
#~ msgstr ""

#~ msgid "The beginning index in unit of Buffer.dtype"
#~ msgstr ""

#~ msgid ""
#~ "The data type to be loaded, can"
#~ " be vector type which have lanes "
#~ "that is multiple of Buffer.dtype"
#~ msgstr ""

#~ msgid ""
#~ "A vector mask of boolean values "
#~ "indicating which lanes of a vector "
#~ "are to be loaded. The number lanes"
#~ " of the mask must be equal to"
#~ " the number of lanes being loaded."
#~ msgstr ""

#~ msgid "**load** -- The corresponding load expression."
#~ msgstr ""

#~ msgid "Generate a Stmt that store value into begin index."
#~ msgstr ""

#~ msgid "The value to be stored."
#~ msgstr ""

#~ msgid ""
#~ "A vector mask of boolean values "
#~ "indicating which lanes of a vector "
#~ "are to be stored. The number lanes"
#~ " of the mask must be equal to"
#~ " the number of lanes in value."
#~ msgstr ""

#~ msgid "**store** -- The corresponding store stmt."
#~ msgstr ""

#~ msgid "Buffer load node."
#~ msgstr ""

#~ msgid "The buffer to be loaded."
#~ msgstr ""

#~ msgid "The buffer indices to load values from."
#~ msgstr ""

#~ msgid "Buffer realize node."
#~ msgstr ""

#~ msgid "The buffer."
#~ msgstr ""

#~ msgid "The value we to be stored."
#~ msgstr ""

#~ msgid "The realize condition."
#~ msgstr ""

#~ msgid "The body of the statement."
#~ msgstr ""

#~ msgid "BufferRegion node."
#~ msgstr ""

#~ msgid "The buffer of the buffer region"
#~ msgstr ""

#~ msgid "The region array of the buffer region"
#~ msgstr ""

#~ msgid "Buffer store node."
#~ msgstr ""

#~ msgid "The indices location to be stored."
#~ msgstr ""

#~ msgid "Call node."
#~ msgstr ""

#~ msgid "The return data type"
#~ msgstr ""

#~ msgid "The function to be called, or the name to the global tvm.Op"
#~ msgstr ""

#~ msgid "The input arguments to the call"
#~ msgstr ""

#~ msgid "Possible kinds of Call effects."
#~ msgstr ""

#~ msgid "Cast expression."
#~ msgstr ""

#~ msgid "The data type"
#~ msgstr ""

#~ msgid "The value of the function."
#~ msgstr ""

#~ msgid "Commutative reduce operator"
#~ msgstr ""

#~ msgid "The left arguments of the reducer."
#~ msgstr ""

#~ msgid "The right arguments of the reducer."
#~ msgstr ""

#~ msgid "The reduction results."
#~ msgstr ""

#~ msgid "The identity elements."
#~ msgstr ""

#~ msgid "DeclBuffer node."
#~ msgstr ""

#~ msgid "The buffer being declared."
#~ msgstr ""

#~ msgid "The body statement to be executed."
#~ msgstr ""

#~ msgid "The location of this DeclBuffer in the source code."
#~ msgstr ""

#~ msgid "Div node."
#~ msgstr ""

#~ msgid "EQ node."
#~ msgstr ""

#~ msgid "Evaluate node."
#~ msgstr ""

#~ msgid "The expression to be evaluated."
#~ msgstr ""

#~ msgid "Float constant."
#~ msgstr ""

#~ msgid "The constant value."
#~ msgstr ""

#~ msgid "FloorDiv node."
#~ msgstr ""

#~ msgid "FloorMod node."
#~ msgstr ""

#~ msgid "For node."
#~ msgstr ""

#~ msgid "The loop variable."
#~ msgstr ""

#~ msgid "The beginning value."
#~ msgstr ""

#~ msgid "The length of the loop."
#~ msgstr ""

#~ msgid "The type of the for."
#~ msgstr ""

#~ msgid "The thread this loop binds to. Only valid if kind is ThreadBinding"
#~ msgstr ""

#~ msgid "The kind of the for loop."
#~ msgstr ""

#~ msgid ""
#~ "ForKind can change the control flow "
#~ "semantics of the loop and need to"
#~ " be considered in all TIR passes."
#~ msgstr ""

#~ msgid "GE node."
#~ msgstr ""

#~ msgid "GT node."
#~ msgstr ""

#~ msgid "IfThenElse node."
#~ msgstr ""

#~ msgid "The expression"
#~ msgstr ""

#~ msgid "The statement to execute if condition is true."
#~ msgstr ""

#~ msgid "The statement to execute if condition is false."
#~ msgstr ""

#~ msgid ""
#~ "A mapping from multi-dimensional indices"
#~ " to another set of multi-dimensional"
#~ " indices"
#~ msgstr ""

#~ msgid "Variables representing the indices prior to remapping."
#~ msgstr ""

#~ msgid "Expressions defining the indices after remapping."
#~ msgstr ""

#~ msgid ""
#~ "The optional pre-defined inverse index"
#~ " map. When this is defined, "
#~ "IndexMap::Inverse will return the pre-"
#~ "defined inverse index map. Otherwise, "
#~ "the inverse index map will be "
#~ "computed on the fly. It is the "
#~ "user's responsibility to ensure the "
#~ "correctness of the pre-defined inverse"
#~ " index map."
#~ msgstr ""

#~ msgid "Create an index map from a function"
#~ msgstr ""

#~ msgid ""
#~ "The function to map from source "
#~ "indices to target indices. The function"
#~ " should accept `tir.Var` parameters and "
#~ "return a either a `tir.PrimExpr`, or "
#~ "a list of `tir.PrimExpr`. Returning a"
#~ " `tir.PrimExpr` is equivalent to returning"
#~ " a list of length 1 containing "
#~ "that `tir.PrimExpr`."
#~ msgstr ""

#~ msgid ""
#~ "The dimensionality of the buffer to "
#~ "which this transformation should be "
#~ "applied.  If mapping_function uses variadic"
#~ " argument `*args`, `ndim` must be "
#~ "specified.  If mapping_function does not "
#~ "use variadic arguments, ndim is "
#~ "optional."
#~ msgstr ""

#~ msgid ""
#~ "**index_map** -- Returns an IndexMap "
#~ "representing the `mapping_function`."
#~ msgstr ""

#~ msgid ""
#~ "The function to map from source "
#~ "indices to target indices. The function"
#~ " should accept tir.Var parameters and "
#~ "return either a `tir.PrimExpr` or a "
#~ "list.  Each element of the returned "
#~ "list should be either a `tir.PrimExpr`"
#~ " or the object `IndexMap.AXIS_SEPARATOR`.  "
#~ "Returning a `tir.PrimExpr` is equivalent "
#~ "to returning a list of length 1"
#~ " containing that `tir.PrimExpr`."
#~ msgstr ""

#~ msgid ""
#~ "The dimensionality of the buffer to "
#~ "which this transformation should be "
#~ "applied.  If mapping_function uses variadic"
#~ " argument `*args`, ndim must be "
#~ "specified.  If mapping_function does not "
#~ "use variadic arguments, ndim is "
#~ "optional."
#~ msgstr ""

#~ msgid "The default index dtype to use for input iters in the mapping function."
#~ msgstr ""

#~ msgid ""
#~ "**ret** -- Returns a tuple whose "
#~ "first element is an IndexMap "
#~ "representing the `mapping_function`, and whose"
#~ " second index is a list of "
#~ "indices at which `IndexMap.AXIS_SEPARATOR` "
#~ "occurred."
#~ msgstr ""

#~ msgid "Return the inverse of the map"
#~ msgstr ""

#~ msgid "Throws an error if the function is not bijective."
#~ msgstr ""

#~ msgid ""
#~ "The region over which the inverse "
#~ "should be determined. Used for "
#~ "validating that the mapping is bijective"
#~ " over this range."
#~ msgstr ""

#~ msgid "**inverse** -- The inverse"
#~ msgstr ""

#~ msgid "Return if the index maps are equivalent."
#~ msgstr ""

#~ msgid "The IndexMap to which the comparison should be made."
#~ msgstr ""

#~ msgid ""
#~ "**is_equivalent** -- True if the two "
#~ "mappings represent the same transformation,"
#~ " otherwise False"
#~ msgstr ""

#~ msgid "Apply the index map to a set of indices"
#~ msgstr ""

#~ msgid "The indices to be mapped"
#~ msgstr ""

#~ msgid "**result** -- The mapped indices"
#~ msgstr ""

#~ msgid "Apply thie index map to transform the layout of the input NDArray"
#~ msgstr ""

#~ msgid "The NDArray to be transformed"
#~ msgstr ""

#~ msgid "**arr_dst** -- The transformed NDArray"
#~ msgstr ""

#~ msgid "Apply the index map to a buffer shape"
#~ msgstr ""

#~ msgid "The buffer shape to be mapped"
#~ msgstr ""

#~ msgid "**result** -- The mapped shape"
#~ msgstr ""

#~ msgid "Can be applied to transformations that introduce padding."
#~ msgstr ""

#~ msgid ""
#~ "The region over which the inverse "
#~ "should be determined. Used for "
#~ "determining the predicate."
#~ msgstr ""

#~ msgid ""
#~ "**result** -- The inverse, and a "
#~ "predicate for which the inverse maps "
#~ "to a valid index in the input "
#~ "range."
#~ msgstr ""

#~ msgid "Int constant."
#~ msgstr ""

#~ msgid "Represent iteration variable."
#~ msgstr ""

#~ msgid "IterVar represents axis iterations in the computation."
#~ msgstr ""

#~ msgid "The domain of the iteration."
#~ msgstr ""

#~ msgid "The internal variable that is used for iteration."
#~ msgstr ""

#~ msgid "The iteration type."
#~ msgstr ""

#~ msgid "The thread type tag."
#~ msgstr ""

#~ msgid ":obj:`te.thread_axis`"
#~ msgstr ""

#~ msgid "Create thread axis IterVar."
#~ msgstr ""

#~ msgid ":obj:`te.reduce_axis`"
#~ msgstr ""

#~ msgid "Create reduce axis IterVar."
#~ msgstr ""

#~ msgid "LE node."
#~ msgstr ""

#~ msgid "LT node."
#~ msgstr ""

#~ msgid ""
#~ "Layout is composed of upper cases, "
#~ "lower cases and numbers, where upper "
#~ "case indicates a primal axis and "
#~ "the corresponding lower case with factor"
#~ " size indicates the subordinate axis. "
#~ "For example, NCHW16c can describe a "
#~ "5-D tensor of [batch_size, channel, "
#~ "height, width, channel_block]. Here "
#~ "subordinate axis channel_block=16 is the "
#~ "factor size of the primal axis C"
#~ " (channel)."
#~ msgstr ""

#~ msgid ":obj:`layout`"
#~ msgstr ""

#~ msgid "Get the factor size of the subordinate axis."
#~ msgstr ""

#~ msgid "The axis name, need to be [a-z,A-Z]"
#~ msgstr ""

#~ msgid ""
#~ "**factor** -- the size of the "
#~ "subordinate-axis of axis (if axis is"
#~ " a primal-axis), or the size of"
#~ " axis itself (if axis is a "
#~ "subordinate-axis). Return -1 if axis "
#~ "is not in the layout."
#~ msgstr ""

#~ msgid "Get the index of an axis"
#~ msgstr ""

#~ msgid "**index** -- The index of the axis, -1 if not found."
#~ msgstr ""

#~ msgid "Let node."
#~ msgstr ""

#~ msgid "The variable in the binding."
#~ msgstr ""

#~ msgid "The value in to be bound."
#~ msgstr ""

#~ msgid "The body expression."
#~ msgstr ""

#~ msgid "LetStmt node."
#~ msgstr ""

#~ msgid "MatchBufferRegion node."
#~ msgstr ""

#~ msgid "The target buffer"
#~ msgstr ""

#~ msgid "The region of source buffer"
#~ msgstr ""

#~ msgid "Max node."
#~ msgstr ""

#~ msgid "Min node."
#~ msgstr ""

#~ msgid "Mod node."
#~ msgstr ""

#~ msgid "Mul node."
#~ msgstr ""

#~ msgid "NE node."
#~ msgstr ""

#~ msgid "Not node."
#~ msgstr ""

#~ msgid "The input value"
#~ msgstr ""

#~ msgid "Or node."
#~ msgstr ""

#~ msgid "Prefetch node."
#~ msgstr ""

#~ msgid "The buffer to be prefetched."
#~ msgstr ""

#~ msgid "The bounds to be prefetched."
#~ msgstr ""

#~ msgid "A function declaration expression."
#~ msgstr ""

#~ msgid "List of input parameters to the function."
#~ msgstr ""

#~ msgid "The body of the function."
#~ msgstr ""

#~ msgid "The return type annotation of the function."
#~ msgstr ""

#~ msgid "The buffer binding map."
#~ msgstr ""

#~ msgid "Attributes of the function, can be None"
#~ msgstr ""

#~ msgid "The location of this itervar in the source code."
#~ msgstr ""

#~ msgid "Specialize parameters of PrimFunc"
#~ msgstr ""

#~ msgid "The mapping from function params to the instance"
#~ msgstr ""

#~ msgid "We can define a Meta TIR function with symbolic shape:"
#~ msgstr ""

#~ msgid "Then we can make it specialized with given shapes or buffers."
#~ msgstr ""

#~ msgid "The specialized function:"
#~ msgstr ""

#~ msgid "**func** -- The new function with parameter specialized"
#~ msgstr ""

#~ msgid "Create a new PrimFunc with the same set signatures but a new body."
#~ msgstr ""

#~ msgid "The new body."
#~ msgstr ""

#~ msgid "**new_func** -- The created new function."
#~ msgstr ""

#~ msgid "Producer load node."
#~ msgstr ""

#~ msgid "The buffer indices."
#~ msgstr ""

#~ msgid "ProducerRealize node."
#~ msgstr ""

#~ msgid "The data producer."
#~ msgstr ""

#~ msgid "The bound of realize"
#~ msgstr ""

#~ msgid "The realize body"
#~ msgstr ""

#~ msgid "The storage scope associated with this realization"
#~ msgstr ""

#~ msgid "ProducerStore node."
#~ msgstr ""

#~ msgid "The index arguments of the store."
#~ msgstr ""

#~ msgid "Ramp node."
#~ msgstr ""

#~ msgid "The base expression."
#~ msgstr ""

#~ msgid "The stride of the ramp."
#~ msgstr ""

#~ msgid "Reduce node."
#~ msgstr ""

#~ msgid "The combiner."
#~ msgstr ""

#~ msgid "The source expression."
#~ msgstr ""

#~ msgid "The iteration domain"
#~ msgstr ""

#~ msgid "The reduce condition."
#~ msgstr ""

#~ msgid "The value index."
#~ msgstr ""

#~ msgid "The initial value for output. This can be an int, float or ProducerLoad"
#~ msgstr ""

#~ msgid "Select node."
#~ msgstr ""

#~ msgid ""
#~ "Select may compute both true_value and"
#~ " false_value. Use :py:class:`tvm.tir.if_then_else` "
#~ "instead if you want to get a "
#~ "conditional expression that only evaluates "
#~ "the correct branch."
#~ msgstr ""

#~ msgid "The condition expression."
#~ msgstr ""

#~ msgid "The value to take when condition is true."
#~ msgstr ""

#~ msgid "The value to take when condition is false."
#~ msgstr ""

#~ msgid "Sequence of statements."
#~ msgstr ""

#~ msgid "The statements"
#~ msgstr ""

#~ msgid "Shuffle node."
#~ msgstr ""

#~ msgid "The vectors"
#~ msgstr ""

#~ msgid "The indices"
#~ msgstr ""

#~ msgid "Symbolic variable to represent a tensor index size"
#~ msgstr ""

#~ msgid "which is greater or equal to zero."
#~ msgstr ""

#~ msgid "The name"
#~ msgstr ""

#~ msgid "Base class of all the statements."
#~ msgstr ""

#~ msgid "String constant."
#~ msgstr ""

#~ msgid "Sub node."
#~ msgstr ""

#~ msgid "Backend function to allocate temporal workspace"
#~ msgstr ""

#~ msgid "The device type which the space will be allocated."
#~ msgstr ""

#~ msgid "The device id which the space will be allocated."
#~ msgstr ""

#~ msgid "The size of the space requested."
#~ msgstr ""

#~ msgid ""
#~ "The type code of the array "
#~ "elements. Only used in certain backends"
#~ " such as OpenGL."
#~ msgstr ""

#~ msgid ""
#~ "The type bits of the array "
#~ "elements. Only used in certain backends"
#~ " such as OpenGL."
#~ msgstr ""

#~ msgid "**call** -- The call expression."
#~ msgstr ""

#~ msgid "Backend function to free temporal workspace."
#~ msgstr ""

#~ msgid "The result allocated space pointer."
#~ msgstr ""

#~ msgid "A tensor intrinsic."
#~ msgstr ""

#~ msgid "The function to describe the computation."
#~ msgstr ""

#~ msgid "The function of the implementation for the execution."
#~ msgstr ""

#~ msgid "Look up a tensor intrinsic by its name."
#~ msgstr ""

#~ msgid "The name of the TensorIntrin to look up."
#~ msgstr ""

#~ msgid ""
#~ "Whether to allow missing tensor intrin."
#~ " If False, raise an error if "
#~ "the tensor intrin"
#~ msgstr ""

#~ msgid ""
#~ "**result** -- The TensorIntrin with the"
#~ " specified name, or None if not "
#~ "found."
#~ msgstr ""

#~ msgid "Register a tensor intrinsic with its name."
#~ msgstr ""

#~ msgid "The name of the TensorIntrin to register."
#~ msgstr ""

#~ msgid "Whether override existing intrinsic."
#~ msgstr ""

#~ msgid "Symbolic variable."
#~ msgstr ""

#~ msgid "While node."
#~ msgstr ""

#~ msgid "The termination condition."
#~ msgstr ""

#~ msgid "Get absolute value of the input element-wise."
#~ msgstr ""

#~ msgid "Input argument."
#~ msgstr ""

#~ msgid "The location of this operator in the source code."
#~ msgstr ""

#~ msgid "**y** -- The result."
#~ msgstr ""

#~ msgid "Take acos of input x."
#~ msgstr ""

#~ msgid "Generic add operator."
#~ msgstr ""

#~ msgid "The left operand."
#~ msgstr ""

#~ msgid "The right operand."
#~ msgstr ""

#~ msgid "The location of this operator in the source."
#~ msgstr ""

#~ msgid "**op** -- The result Expr of add operaton."
#~ msgstr ""

#~ msgid "Returns the address of an element in the buffer"
#~ msgstr ""

#~ msgid "The buffer load."
#~ msgstr ""

#~ msgid "Create a new expression of the intersection of all conditions in the"
#~ msgstr ""

#~ msgid "arguments"
#~ msgstr ""

#~ msgid "List of symbolic boolean expressions"
#~ msgstr ""

#~ msgid "**expr** -- Expression"
#~ msgstr ""

#~ msgid "Create a new experssion of the union of all conditions in the arguments"
#~ msgstr ""

#~ msgid "Take asin of input x."
#~ msgstr ""

#~ msgid "Take asinh of input x."
#~ msgstr ""

#~ msgid "Provide a true statement that can be used for simplifications"
#~ msgstr ""

#~ msgid "The constraint condition."
#~ msgstr ""

#~ msgid "Take atan of input x."
#~ msgstr ""

#~ msgid "Take arctan2(x1, x2)."
#~ msgstr ""

#~ msgid "Take atanh of input x."
#~ msgstr ""

#~ msgid "Create a bijective layout mapping."
#~ msgstr ""

#~ msgid "**bijective_layout** -- The created bijective layout"
#~ msgstr ""

#~ msgid "Take bitwise and of two values"
#~ msgstr ""

#~ msgid "Left operand"
#~ msgstr ""

#~ msgid "Right operand"
#~ msgstr ""

#~ msgid "**res** -- The result."
#~ msgstr ""

#~ msgid "Take bitwise not of input value"
#~ msgstr ""

#~ msgid "Input operand"
#~ msgstr ""

#~ msgid "Take bitwise or of two values"
#~ msgstr ""

#~ msgid "Take bitwise xor of two values"
#~ msgstr ""

#~ msgid ""
#~ "Build a function with a signature, "
#~ "generating code for devices coupled with"
#~ " target information."
#~ msgstr ""

#~ msgid "The input to be built."
#~ msgstr ""

#~ msgid "The target for compilation."
#~ msgstr ""

#~ msgid "The pipeline to use for compilation."
#~ msgstr ""

#~ msgid "A module combining both host and device code."
#~ msgstr ""

#~ msgid "Build expression by call an external packed function."
#~ msgstr ""

#~ msgid ""
#~ "Same as call_packed, except that the "
#~ "first argument is the function name "
#~ "(as in call_extern), and the last "
#~ "argument is the resource handle."
#~ msgstr ""

#~ msgid "Positional arguments."
#~ msgstr ""

#~ msgid ":obj:`te.extern`"
#~ msgstr ""

#~ msgid "Create tensor with extern function call."
#~ msgstr ""

#~ msgid ""
#~ "Lowered version of call c-packed. Same"
#~ " as call_packed, except that the "
#~ "first argument is the function name "
#~ "(as in call_extern), and the last "
#~ "argument is the resource handle."
#~ msgstr ""

#~ msgid "Build expression by calling a extern function."
#~ msgstr ""

#~ msgid "The data type of the result."
#~ msgstr ""

#~ msgid "The extern function name."
#~ msgstr ""

#~ msgid "Build expression by calling an intrinsic function."
#~ msgstr ""

#~ msgid ""
#~ "Intrinsics can be overloaded with "
#~ "multiple data types via the intrinsic"
#~ " translation rule."
#~ msgstr ""

#~ msgid "The intrinsic function name."
#~ msgstr ""

#~ msgid "Build expression by calling a llvm intrinsic function"
#~ msgstr ""

#~ msgid "The name of the llvm intrinsic function."
#~ msgstr ""

#~ msgid "Build expression by calling a pure llvm intrinsic function"
#~ msgstr ""

#~ msgid ""
#~ "The argument to packed function can "
#~ "be Expr or Buffer. The argument is"
#~ " the corresponding POD type when Expr"
#~ " is presented."
#~ msgstr ""

#~ msgid ""
#~ "When the argument is Buffer, the "
#~ "corresponding PackedFunc will receive an "
#~ "TVMArrayHandle whose content is valid "
#~ "during the callback period. If the "
#~ "PackedFunc is a python callback, then"
#~ " the corresponding argument is NDArray."
#~ msgstr ""

#~ msgid ""
#~ "Lowered version of call packed. The "
#~ "argument to packed function can be "
#~ "Expr or Buffer. The argument is "
#~ "the corresponding POD type when Expr "
#~ "is presented. When the argument is "
#~ "Buffer, the corresponding PackedFunc will "
#~ "recieve an TVMArrayHandle whose content "
#~ "is valid during the callback period. "
#~ "If the PackedFunc is a python "
#~ "callback, then the corresponding argument "
#~ "is NDArray."
#~ msgstr ""

#~ msgid "Build expression by calling a pure extern function."
#~ msgstr ""

#~ msgid "Performs a call into another PrimFunc in the same IRModule"
#~ msgstr ""

#~ msgid "Take ceil of float input x."
#~ msgstr ""

#~ msgid "Generic ceildiv operator."
#~ msgstr ""

#~ msgid "**op** -- The result Expr of ceildiv operaton."
#~ msgstr ""

#~ msgid "Count leading zero bits of an integer x."
#~ msgstr ""

#~ msgid "Input 32 or 64 bit integer. The result is undefined if the input is 0."
#~ msgstr ""

#~ msgid "Create a commutative reducer for reduction."
#~ msgstr ""

#~ msgid "A binary function which takes two Expr as input to return a Expr."
#~ msgstr ""

#~ msgid "A function which takes a type string as input to return a const Expr."
#~ msgstr ""

#~ msgid ""
#~ "**reducer** -- A function which creates"
#~ " a reduce expression over axis. There"
#~ " are two ways to use it:  1."
#~ " accept (expr, axis, where) to "
#~ "produce an Reduce Expr on    specified"
#~ " axis; 2. simply use it with "
#~ "multiple Exprs."
#~ msgstr ""

#~ msgid ""
#~ "**reducer** -- A function which creates"
#~ " a reduce expression over axis. There"
#~ " are two ways to use it:"
#~ msgstr ""

#~ msgid "accept (expr, axis, where) to produce an Reduce Expr on specified axis;"
#~ msgstr ""

#~ msgid "simply use it with multiple Exprs."
#~ msgstr ""

#~ msgid "Change the sign of x1 to that of x2, element-wise."
#~ msgstr ""

#~ msgid "Take cos of input x."
#~ msgstr ""

#~ msgid "Take cosh of input x."
#~ msgstr ""

#~ msgid "TVM intrinsic to create N barriers"
#~ msgstr ""

#~ msgid "The number of barriers to create."
#~ msgstr ""

#~ msgid "Declare a new symbolic buffer."
#~ msgstr ""

#~ msgid ""
#~ "Normally buffer is created automatically "
#~ "during lower and build. This is "
#~ "only needed if user want to "
#~ "specify their own buffer layout."
#~ msgstr ""

#~ msgid "See the note below for detailed discussion on usage of buffer."
#~ msgstr ""

#~ msgid "The shape of the buffer."
#~ msgstr ""

#~ msgid "The name of the buffer."
#~ msgstr ""

#~ msgid "The data pointer in the buffer."
#~ msgstr ""

#~ msgid "The stride of the buffer."
#~ msgstr ""

#~ msgid ""
#~ "The beginning offset of the array "
#~ "to data. In terms of number of "
#~ "elements of dtype."
#~ msgstr ""

#~ msgid ""
#~ "The storage scope of the buffer, "
#~ "if not global. If scope equals "
#~ "empty string, it means it is "
#~ "global memory."
#~ msgstr ""

#~ msgid ""
#~ "The alignment of data pointer in "
#~ "bytes. If -1 is passed, the "
#~ "alignment will be set to TVM's "
#~ "internal default."
#~ msgstr ""

#~ msgid ""
#~ "The factor of elem_offset field, when"
#~ " set, elem_offset is required to be"
#~ " multiple of offset_factor. If 0 is"
#~ " pssed, the alignment will be set "
#~ "to 1. if non-zero is passed, "
#~ "we will created a Var for "
#~ "elem_offset if elem_offset is not None."
#~ msgstr ""

#~ msgid ""
#~ "auto_broadcast buffer allows one to "
#~ "implement broadcast computation without "
#~ "considering whether dimension size equals "
#~ "to one. TVM maps buffer[i][j][k] -> "
#~ "buffer[i][0][k] if dimension j's shape "
#~ "equals 1."
#~ msgstr ""

#~ msgid ""
#~ "If passed, a list of separators "
#~ "between groups of axes, each of "
#~ "which is flattened to an output "
#~ "axis.  For flat memory spaces, should"
#~ " either be None, or an empty "
#~ "list."
#~ msgstr ""

#~ msgid "The location of the decl_buffer creation in the source."
#~ msgstr ""

#~ msgid "**buffer** -- The created buffer"
#~ msgstr ""

#~ msgid ""
#~ "Buffer data structure reflects the "
#~ "DLTensor structure in dlpack. While "
#~ "DLTensor data structure is very general,"
#~ " it is usually helpful to create "
#~ "function that only handles specific case"
#~ " of data structure and make compiled"
#~ " function benefit from it."
#~ msgstr ""

#~ msgid ""
#~ "If user pass strides and elem_offset "
#~ "is passed as None when constructing "
#~ "the function, then the function will "
#~ "be specialized for the DLTensor that "
#~ "is compact and aligned. If user "
#~ "pass a fully generic symbolic array "
#~ "to the strides, then the resulting "
#~ "function becomes fully generic."
#~ msgstr ""

#~ msgid "Compute a / b as in C/C++ semantics."
#~ msgstr ""

#~ msgid "The left hand operand, known to be non-negative."
#~ msgstr ""

#~ msgid "The right hand operand, known to be non-negative."
#~ msgstr ""

#~ msgid "**res** -- The result expression."
#~ msgstr ""

#~ msgid "When operands are integers, returns truncdiv(a, b, span)."
#~ msgstr ""

#~ msgid "Dot product of two int8x4 vectors and add an optional accumulator"
#~ msgstr ""

#~ msgid "The input vector."
#~ msgstr ""

#~ msgid "The accumulator."
#~ msgstr ""

#~ msgid "End profile intrinsic. :param id: The intrinsic id. :type id: int"
#~ msgstr ""

#~ msgid "Take gauss error function of the input x."
#~ msgstr ""

#~ msgid "Take exponential of input x."
#~ msgstr ""

#~ msgid "Calculate 10**x"
#~ msgstr ""

#~ msgid "Calculate 2**x"
#~ msgstr ""

#~ msgid "Take floor of float input x."
#~ msgstr ""

#~ msgid "Compute the floordiv of two expressions."
#~ msgstr ""

#~ msgid "The left hand operand"
#~ msgstr ""

#~ msgid "The right hand operand"
#~ msgstr ""

#~ msgid "Compute the floormod of two expressions."
#~ msgstr ""

#~ msgid "Return the remainder of x divided by y with the same sign as x."
#~ msgstr ""

#~ msgid "**z** -- The result."
#~ msgstr ""

#~ msgid ""
#~ "Calculate a predicate mask given an "
#~ "upper bound (limit) and a current "
#~ "value (base)."
#~ msgstr ""

#~ msgid ""
#~ "It will be lowered to the "
#~ "llvm.get.active.lane.mask intrinsic. "
#~ "(https://llvm.org/docs/LangRef.html#llvm-get-active-"
#~ "lane-mask-intrinsics)"
#~ msgstr ""

#~ msgid "An expression reprsenting the base."
#~ msgstr ""

#~ msgid "An expression representing the limit."
#~ msgstr ""

#~ msgid "Get the default TIR pipeline for the given target."
#~ msgstr ""

#~ msgid "Get pre-build pipeline by name"
#~ msgstr ""

#~ msgid "Name of the pipeline"
#~ msgstr ""

#~ msgid "Create a datatype dependent scalable expression."
#~ msgstr ""

#~ msgid "Element data type."
#~ msgstr ""

#~ msgid "The minimum size of the scalable vector in bits."
#~ msgstr ""

#~ msgid "Equivalent to sqrt(x1**2 + x2**2), element-wise."
#~ msgstr ""

#~ msgid "Conditional selection expression."
#~ msgstr ""

#~ msgid "The condition"
#~ msgstr ""

#~ msgid "The result expression if cond is true."
#~ msgstr ""

#~ msgid "The result expression if cond is false."
#~ msgstr ""

#~ msgid "**result** -- The result of conditional expression."
#~ msgstr ""

#~ msgid ""
#~ "Unlike Select, if_then_else will not "
#~ "execute the branch that does not "
#~ "satisfy the condition. You can use "
#~ "it to guard against out of bound"
#~ " access. Unlike Select, if_then_else cannot"
#~ " be vectorized if some lanes in "
#~ "the vector have different conditions."
#~ msgstr ""

#~ msgid ""
#~ "Annotate a predicate not be considered"
#~ " as target condition of loop "
#~ "partition."
#~ msgstr ""

#~ msgid "The annotated predicate expression."
#~ msgstr ""

#~ msgid "Compute floor(a / b) where a and b are non-negative."
#~ msgstr ""

#~ msgid ""
#~ "Use this function to split non-"
#~ "negative indices. This function may take"
#~ " advantage of operands' non-negativeness."
#~ msgstr ""

#~ msgid "Compute the remainder of indexdiv. a and b are non-negative."
#~ msgstr ""

#~ msgid "infinity value of dtype"
#~ msgstr ""

#~ msgid "The data type."
#~ msgstr ""

#~ msgid "**value** -- The infinity value of dtype."
#~ msgstr ""

#~ msgid "Check if input value is finite."
#~ msgstr ""

#~ msgid "Check if input value is infinite."
#~ msgstr ""

#~ msgid "Check if input value is Nan."
#~ msgstr ""

#~ msgid "Check if input value is nullptr."
#~ msgstr ""

#~ msgid "Create a layout node from a string."
#~ msgstr ""

#~ msgid ""
#~ "A layout representation is composed of"
#~ " upper cases, lower cases and "
#~ "numbers, where upper case indicates a"
#~ " primal axis and the corresponding "
#~ "lower case with factor size indicates"
#~ " the subordinate axis. For example, "
#~ "NCHW16c can describe a 5-D tensor "
#~ "of [batch_size, channel, height, width, "
#~ "channel_block]. Here subordinate axis "
#~ "channel_block=16 is the factor size of"
#~ " the primal axis C (channel)."
#~ msgstr ""

#~ msgid ""
#~ "The dtype of generated axes vars "
#~ "in the returned layout. It is "
#~ "required to be integer type."
#~ msgstr ""

#~ msgid "**layout** -- The created layout"
#~ msgstr ""

#~ msgid "Returns x1 * (2 ** x2)."
#~ msgstr ""

#~ msgid "Mark condition as likely."
#~ msgstr ""

#~ msgid "**y** -- The marked expression."
#~ msgstr ""

#~ msgid "Take log of input x."
#~ msgstr ""

#~ msgid "Take log10 of input x."
#~ msgstr ""

#~ msgid "Take log(x + 1) with respect to input x."
#~ msgstr ""

#~ msgid "Take log2 of input x."
#~ msgstr ""

#~ msgid "Returns the param by name"
#~ msgstr ""

#~ msgid "The name of param."
#~ msgstr ""

#~ msgid "Create a filled SIMDGroup matrix"
#~ msgstr ""

#~ msgid "The simdgroup var"
#~ msgstr ""

#~ msgid "The index of the matrix."
#~ msgstr ""

#~ msgid "The value to fill."
#~ msgstr ""

#~ msgid "The number of columns."
#~ msgstr ""

#~ msgid "The number of rows."
#~ msgstr ""

#~ msgid "Create a max expression over axis."
#~ msgstr ""

#~ msgid "The reduction IterVar axis"
#~ msgstr ""

#~ msgid "Filtering predicate of the reduction."
#~ msgstr ""

#~ msgid "**value** -- The result value."
#~ msgstr ""

#~ msgid "maximum value of dtype"
#~ msgstr ""

#~ msgid "**value** -- The maximum value of dtype."
#~ msgstr ""

#~ msgid "Create a min expression over axis."
#~ msgstr ""

#~ msgid "minimum value of dtype"
#~ msgstr ""

#~ msgid "**value** -- The minimum value of dtype."
#~ msgstr ""

#~ msgid "TVM intrinsic for zero-initalizing an MMA accumulation registor"
#~ msgstr ""

#~ msgid "The number of elements."
#~ msgstr ""

#~ msgid "The destination pointer variable."
#~ msgstr ""

#~ msgid "The destination offset."
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for storing the result "
#~ "of PTX MMA into a destination "
#~ "pointer"
#~ msgstr ""

#~ msgid "The shape of mma fragment."
#~ msgstr ""

#~ msgid "The source pointer variable."
#~ msgstr ""

#~ msgid "The source offset."
#~ msgstr ""

#~ msgid "The destination stride."
#~ msgstr ""

#~ msgid "Generic multiply operator."
#~ msgstr ""

#~ msgid "**op** -- The result Expr of multiply operaton."
#~ msgstr ""

#~ msgid ""
#~ "Round elements of the array to the"
#~ " nearest integer. This intrinsic uses "
#~ "llvm.nearbyint instead of llvm.round which "
#~ "is faster but will results different "
#~ "from te.round. Notably nearbyint rounds "
#~ "according to the rounding mode, whereas"
#~ " te.round (llvm.round) ignores that. For"
#~ " differences between the two see: "
#~ "https://en.cppreference.com/w/cpp/numeric/math/round "
#~ "https://en.cppreference.com/w/cpp/numeric/math/nearbyint"
#~ msgstr ""

#~ msgid "Return the next floating-point value after x1 towards x2."
#~ msgstr ""

#~ msgid "Count the number of set bits in input x."
#~ msgstr ""

#~ msgid "x power y"
#~ msgstr ""

#~ msgid "The exponent"
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for ptx barrier arrival"
#~ " using mbarrier.arrive https://docs.nvidia.com/cuda"
#~ "/parallel-thread-execution/index.html#parallel-"
#~ "synchronization-and-communication-instructions-"
#~ "mbarrier-arrive"
#~ msgstr ""

#~ msgid "The ID of the barrier shared memory pointer."
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for ptx barrier arrival"
#~ " with expect tx using "
#~ "mbarrier.arrive.expect_tx https://docs.nvidia.com/cuda"
#~ "/parallel-thread-execution/index.html#parallel-"
#~ "synchronization-and-communication-instructions-"
#~ "mbarrier-arrive https://docs.nvidia.com/cuda/parallel-"
#~ "thread-execution/index.html#parallel-synchronization-"
#~ "and-communication-instructions-mbarrier-"
#~ "expect-tx-operation"
#~ msgstr ""

#~ msgid ""
#~ "Increases the tx count of the "
#~ "mbarrier object to track completion of"
#~ " addtional async transactions."
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for ptx async copy "
#~ "commit https://docs.nvidia.com/cuda/parallel-thread-"
#~ "execution/index.html#data-movement-and-"
#~ "conversion-instructions-cp-async-commit-"
#~ "group"
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for ptx async copy "
#~ "from global to shared memory using "
#~ "cp.async https://docs.nvidia.com/cuda/parallel-thread-"
#~ "execution/index.html#data-movement-and-"
#~ "conversion-instructions-cp-async"
#~ msgstr ""

#~ msgid "The shared memory pointer variable."
#~ msgstr ""

#~ msgid "The offset of shared memory pointer."
#~ msgstr ""

#~ msgid "The global memory pointer variable."
#~ msgstr ""

#~ msgid "The offset of global memory pointer."
#~ msgstr ""

#~ msgid "The data size to copy."
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for ptx async copy "
#~ "barrier using cp.async.mbarrier.arrive "
#~ "https://docs.nvidia.com/cuda/parallel-thread-"
#~ "execution/index.html#parallel-synchronization-and-"
#~ "communication-instructions-cp-async-mbarrier-"
#~ "arrive"
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for ptx async copy "
#~ "from global to shared memory using "
#~ "cp.async.bulk https://docs.nvidia.com/cuda/parallel-"
#~ "thread-execution/index.html#data-movement-and-"
#~ "conversion-instructions-cp-async-bulk"
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for ptx barrier "
#~ "initialization of thread count using "
#~ "mbarrier.init https://docs.nvidia.com/cuda/parallel-"
#~ "thread-execution/index.html#parallel-synchronization-"
#~ "and-communication-instructions-mbarrier-init"
#~ msgstr ""

#~ msgid "Number of threads expected to arrive at the barrier."
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for ptx load matrix "
#~ "from shared memory https://docs.nvidia.com/cuda"
#~ "/parallel-thread-execution/index.html#warp-level-"
#~ "matrix-instructions-ldmatrix"
#~ msgstr ""

#~ msgid "The matrix is loaded in column-major format."
#~ msgstr ""

#~ msgid "The number of matrices."
#~ msgstr ""

#~ msgid "The data type of the matrices."
#~ msgstr ""

#~ msgid "The local pointer variable."
#~ msgstr ""

#~ msgid "The offset of local pointer."
#~ msgstr ""

#~ msgid "The offset of shared memort pointer."
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for ptx tensor core "
#~ "mma instructions https://docs.nvidia.com/cuda/parallel-"
#~ "thread-execution/index.html#warp-level-matrix-"
#~ "instructions-for-mma"
#~ msgstr ""

#~ msgid "The layout of multiplicand fragment A."
#~ msgstr ""

#~ msgid "The layout of multiplicand fragment B."
#~ msgstr ""

#~ msgid "The data type of multiplicand fragment A."
#~ msgstr ""

#~ msgid "The data type of multiplicand fragment B."
#~ msgstr ""

#~ msgid "The data type of accumulator fragment C."
#~ msgstr ""

#~ msgid "The multiplicand fragment A variable."
#~ msgstr ""

#~ msgid "The index of multiplicand fragment A."
#~ msgstr ""

#~ msgid "The multiplicand fragment B variable."
#~ msgstr ""

#~ msgid "The accumulator fragment C variable."
#~ msgstr ""

#~ msgid "The index of accumulator fragment C."
#~ msgstr ""

#~ msgid "The optional saturation at the output."
#~ msgstr ""

#~ msgid "The 1-bit operator."
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for sparse tensor core "
#~ "ptx instructions https://docs.nvidia.com/cuda/parallel-"
#~ "thread-execution/index.html#warp-level-matrix-"
#~ "instructions-for-sparse-mma"
#~ msgstr ""

#~ msgid "The data type of multiplicand fragment C."
#~ msgstr ""

#~ msgid "The index of multiplicand fragment B."
#~ msgstr ""

#~ msgid "The metadata of operand."
#~ msgstr ""

#~ msgid "The metadata index of operand."
#~ msgstr ""

#~ msgid "The sparse selector indicating the thread that stores the metadata."
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for ptx barrier wait "
#~ "using mbarrier.try_wait https://docs.nvidia.com/cuda"
#~ "/parallel-thread-execution/index.html#parallel-"
#~ "synchronization-and-communication-instructions-"
#~ "mbarrier-test-wait-mbarrier-try-wait"
#~ msgstr ""

#~ msgid ""
#~ "TVM intrinsic for ptx async copy "
#~ "wait https://docs.nvidia.com/cuda/parallel-thread-"
#~ "execution/index.html#data-movement-and-"
#~ "conversion-instructions-cp-async-wait-group"
#~ msgstr ""

#~ msgid ""
#~ "The number of the most recent "
#~ "uncommitted pending cp.async groups to "
#~ "wait."
#~ msgstr ""

#~ msgid ""
#~ "Execute a multiplication between two "
#~ "Q-numbers x and y followed by a"
#~ " right shift s. The mathematical "
#~ "expression is:"
#~ msgstr ""

#~ msgid "out = round(x*y*2^-s)"
#~ msgstr ""

#~ msgid ""
#~ "More about Q-numbers here: "
#~ "https://en.wikipedia.org/wiki/Q_(number_format) The "
#~ "rounding rule is to the nearest "
#~ "value, rounding half up (i.e., "
#~ "round(x.1) = x and round (x.5) ="
#~ " x+1)"
#~ msgstr ""

#~ msgid "First Q-number"
#~ msgstr ""

#~ msgid "Second Q-number"
#~ msgstr ""

#~ msgid "Number of fractional bits in x and y. Needs to be > 0"
#~ msgstr ""

#~ msgid "Integer shift"
#~ msgstr ""

#~ msgid "Execute a multiplication between two Q-numbers x and y"
#~ msgstr ""

#~ msgid "First Q-number."
#~ msgstr ""

#~ msgid "Second Q-number."
#~ msgstr ""

#~ msgid "Integer left shift."
#~ msgstr ""

#~ msgid "Integer right shift."
#~ msgstr ""

#~ msgid "Number of fractional bits in x and y. Needs to be > 0."
#~ msgstr ""

#~ msgid "Whether we need to do left shift or not."
#~ msgstr ""

#~ msgid "Whether we need to do right shift or not."
#~ msgstr ""

#~ msgid "The input value."
#~ msgstr ""

#~ msgid "**value** -- The reinterpret cast value of dtype."
#~ msgstr ""

#~ msgid "Create a tir return expression"
#~ msgstr ""

#~ msgid ""
#~ "The returned tir expression, whose data"
#~ " type is int, float or void "
#~ "pointer."
#~ msgstr ""

#~ msgid "**ret** -- The return expression"
#~ msgstr ""

#~ msgid "Round elements of the array to the nearest integer."
#~ msgstr ""

#~ msgid "Take reciprocal of square root of input x."
#~ msgstr ""

#~ msgid "Return the result of x left shifted by y bits."
#~ msgstr ""

#~ msgid "Return the result of x right shifted by y bits."
#~ msgstr ""

#~ msgid "Quick function to get sigmoid"
#~ msgstr ""

#~ msgid "Load data from device memory or threadgroup memory to simdgroup"
#~ msgstr ""

#~ msgid "The pointer."
#~ msgstr ""

#~ msgid "The stride."
#~ msgstr ""

#~ msgid "Whether to transpose the matrix."
#~ msgstr ""

#~ msgid "Multiply and accumulate two matrices in simdgroup i.e. d = a * b + c"
#~ msgstr ""

#~ msgid "The destination matrix."
#~ msgstr ""

#~ msgid "The index of the destination matrix."
#~ msgstr ""

#~ msgid "The first matrix."
#~ msgstr ""

#~ msgid "The index of the first matrix."
#~ msgstr ""

#~ msgid "The second matrix."
#~ msgstr ""

#~ msgid "The index of the second matrix."
#~ msgstr ""

#~ msgid "The third matrix."
#~ msgstr ""

#~ msgid "The index of the third matrix."
#~ msgstr ""

#~ msgid "Store data from simdgroup to device memory or threadgroup memory"
#~ msgstr ""

#~ msgid "The SIMDGroup."
#~ msgstr ""

#~ msgid "transpose_matrix"
#~ msgstr ""

#~ msgid "bool"
#~ msgstr ""

#~ msgid "Take sin of input x."
#~ msgstr ""

#~ msgid "Take sinh of input x."
#~ msgstr ""

#~ msgid "Take square root of input x."
#~ msgstr ""

#~ msgid "Start profile intrinsic. :param id: The intrinsic id. :type id: int"
#~ msgstr ""

#~ msgid "Make list of stmt from blocks."
#~ msgstr ""

#~ msgid "The input statement."
#~ msgstr ""

#~ msgid "**stmt_list** -- The unpacked list of statements"
#~ msgstr ""

#~ msgid "Make sequence of statements"
#~ msgstr ""

#~ msgid "List of statements to be combined as sequence."
#~ msgstr ""

#~ msgid "**stmt** -- The combined statement."
#~ msgstr ""

#~ msgid "Generic subtract operator."
#~ msgstr ""

#~ msgid "**op** -- The result Expr of subtract operaton."
#~ msgstr ""

#~ msgid "Create a sum expression over axis."
#~ msgstr ""

#~ msgid "Take tan of input x."
#~ msgstr ""

#~ msgid "Take hyperbolic tanh of input x."
#~ msgstr ""

#~ msgid "Trace tensor data at the runtime."
#~ msgstr ""

#~ msgid ""
#~ "The trace function allows to trace "
#~ "specific tensor at the runtime. The "
#~ "tracing value should come as last "
#~ "argument. The trace action should be "
#~ "specified, by default tvm.default_trace_action "
#~ "is used."
#~ msgstr ""

#~ msgid "The name of the trace action."
#~ msgstr ""

#~ msgid ":obj:`tvm.tir.call_packed`"
#~ msgstr ""

#~ msgid "Creates packed function."
#~ msgstr ""

#~ msgid "Get truncated value of the input."
#~ msgstr ""

#~ msgid ""
#~ "The truncated value of the scalar "
#~ "x is the nearest integer i which"
#~ " is closer to zero than x is."
#~ msgstr ""

#~ msgid "Compute the truncdiv of two expressions."
#~ msgstr ""

#~ msgid "This is the default integer division behavior in C."
#~ msgstr ""

#~ msgid "Compute the truncmod of two expressions."
#~ msgstr ""

#~ msgid "Get head access address with memory access pattern info"
#~ msgstr ""

#~ msgid "The data type of pointer."
#~ msgstr ""

#~ msgid "The data of pointer."
#~ msgstr ""

#~ msgid "The offset of pointer."
#~ msgstr ""

#~ msgid "The read write mask."
#~ msgstr ""

#~ msgid "TVM intrinsic for tensor core bmma_sync operators"
#~ msgstr ""

#~ msgid "The bwmma fragment_d."
#~ msgstr ""

#~ msgid "The fragment_d index."
#~ msgstr ""

#~ msgid "The bwmma fragment_a."
#~ msgstr ""

#~ msgid "The fragment_a index."
#~ msgstr ""

#~ msgid "The bwmma fragment_b."
#~ msgstr ""

#~ msgid "The fragment_b index."
#~ msgstr ""

#~ msgid "The bwmma fragment_c."
#~ msgstr ""

#~ msgid "The fragment_c index."
#~ msgstr ""

#~ msgid ""
#~ "Return new on stack dtype[num] :param"
#~ " expected: The expected return code. "
#~ ":type expected: int :param return_unexpected:"
#~ " The unexpected return code. :type "
#~ "return_unexpected: int :param nested_call: The"
#~ " call expression to check return. "
#~ ":type nested_call: PrimExpr"
#~ msgstr ""

#~ msgid "TVM intrinsic for tensor core fill_fragment operators"
#~ msgstr ""

#~ msgid "The wmma fragment"
#~ msgstr ""

#~ msgid "The shape of wmma fragment."
#~ msgstr ""

#~ msgid "The fragment index."
#~ msgstr ""

#~ msgid "The value to be filled in fragment."
#~ msgstr ""

#~ msgid "TVM intrinsic for tensor core load operators"
#~ msgstr ""

#~ msgid "The wmma fragment."
#~ msgstr ""

#~ msgid "The fragment buffer pointer."
#~ msgstr ""

#~ msgid "The fragment stride."
#~ msgstr ""

#~ msgid "The fragment layout."
#~ msgstr ""

#~ msgid "TVM intrinsic for tensor core mma_sync operators"
#~ msgstr ""

#~ msgid "The wmma fragment_d."
#~ msgstr ""

#~ msgid "The wmma fragment_a."
#~ msgstr ""

#~ msgid "The wmma fragment_b."
#~ msgstr ""

#~ msgid "The wmma fragment_c."
#~ msgstr ""

#~ msgid "Return new on stack dtype[num]"
#~ msgstr ""

#~ msgid "The data type of array."
#~ msgstr ""

#~ msgid "The size of array."
#~ msgstr ""

#~ msgid "Allocate a NDArray(DLTensor) on stack, return the handle"
#~ msgstr ""

#~ msgid "The data of array."
#~ msgstr ""

#~ msgid "The shape of array."
#~ msgstr ""

#~ msgid "The strides of array."
#~ msgstr ""

#~ msgid "The dimensions of array."
#~ msgstr ""

#~ msgid "The element offset of array."
#~ msgstr ""

#~ msgid "Allocate a shape tuple on stack, return the handle"
#~ msgstr ""

#~ msgid "The tuple shape."
#~ msgstr ""

#~ msgid "TVM intrinsic for tensor core store operators"
#~ msgstr ""

#~ msgid "Get struct field value in array"
#~ msgstr ""

#~ msgid "The date type of the result."
#~ msgstr ""

#~ msgid "The array of struct."
#~ msgstr ""

#~ msgid "The index of struct."
#~ msgstr ""

#~ msgid "The field of struct."
#~ msgstr ""

#~ msgid "Set value in struct field in array"
#~ msgstr ""

#~ msgid "The value to be set in field."
#~ msgstr ""

#~ msgid "Perform allreduce inside threadblock."
#~ msgstr ""

#~ msgid "The args."
#~ msgstr ""

#~ msgid "Throw TVMGetLastError()"
#~ msgstr ""

#~ msgid "Create a tuple structure in value field of AttrStmt"
#~ msgstr ""

#~ msgid "The value in tuple."
#~ msgstr ""

#~ msgid "Create a type annotation expression"
#~ msgstr ""

#~ msgid "Returns an initialized but arbitrary value"
#~ msgstr ""

#~ msgid "Concat two vectors"
#~ msgstr ""

#~ msgid "Get the high level half of the vector"
#~ msgstr ""

#~ msgid "Get the low level half of the vector"
#~ msgstr ""

#~ msgid ""
#~ "Get the target's vscale value. It "
#~ "will be lowered to llvm.vscale intrinsic"
#~ " (https://llvm.org/docs/LangRef.html#llvm-vscale-"
#~ "intrinsic) :returns: **call** -- Call to"
#~ " the vscale intrinsic :rtype: PrimExpr"
#~ msgstr ""


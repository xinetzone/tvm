# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-02-05 13:19+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.16.0\n"

#: ../../doc/docs/reference/api/python/tir/tir.rst:19
msgid "tvm.tir"
msgstr ""

#: of tvm.tir:1
msgid "Namespace for Tensor-level IR"
msgstr ""

#: of tvm.tir.expr.Add:1
msgid "Add node."
msgstr ""

#: ../../doc/docs/reference/api/python/tir/tir.rst
msgid "参数"
msgstr ""

#: of tvm.tir.expr.Add:3 tvm.tir.expr.And:3 tvm.tir.expr.Div:3
#: tvm.tir.expr.EQ:3 tvm.tir.expr.FloorDiv:3 tvm.tir.expr.FloorMod:3
#: tvm.tir.expr.GE:3 tvm.tir.expr.GT:3 tvm.tir.expr.LE:3 tvm.tir.expr.LT:3
#: tvm.tir.expr.Max:3 tvm.tir.expr.Min:3 tvm.tir.expr.Mod:3 tvm.tir.expr.Mul:3
#: tvm.tir.expr.NE:3 tvm.tir.expr.Or:3 tvm.tir.expr.Sub:3
msgid "The left hand operand."
msgstr ""

#: of tvm.tir.expr.Add:5 tvm.tir.expr.And:5 tvm.tir.expr.Div:5
#: tvm.tir.expr.EQ:5 tvm.tir.expr.FloorDiv:5 tvm.tir.expr.FloorMod:5
#: tvm.tir.expr.GE:5 tvm.tir.expr.GT:5 tvm.tir.expr.LE:5 tvm.tir.expr.LT:5
#: tvm.tir.expr.Max:5 tvm.tir.expr.Min:5 tvm.tir.expr.Mod:5 tvm.tir.expr.Mul:5
#: tvm.tir.expr.NE:5 tvm.tir.expr.Or:5 tvm.tir.expr.Sub:5
msgid "The right hand operand."
msgstr ""

#: of tvm.tir.expr.Add:7 tvm.tir.expr.And:7 tvm.tir.expr.Any:4
#: tvm.tir.expr.Broadcast:7 tvm.tir.expr.BufferLoad:7 tvm.tir.expr.Call:10
#: tvm.tir.expr.Cast:7 tvm.tir.expr.CommReducer:11 tvm.tir.expr.Div:7
#: tvm.tir.expr.EQ:7 tvm.tir.expr.FloatImm:7 tvm.tir.expr.FloorDiv:7
#: tvm.tir.expr.FloorMod:7 tvm.tir.expr.GE:7 tvm.tir.expr.GT:7
#: tvm.tir.expr.IntImm:7 tvm.tir.expr.IterVar:13 tvm.tir.expr.LE:7
#: tvm.tir.expr.LT:7 tvm.tir.expr.Let:9 tvm.tir.expr.Max:7 tvm.tir.expr.Min:7
#: tvm.tir.expr.Mod:7 tvm.tir.expr.Mul:7 tvm.tir.expr.NE:7 tvm.tir.expr.Not:5
#: tvm.tir.expr.Or:7 tvm.tir.expr.ProducerLoad:7 tvm.tir.expr.Ramp:9
#: tvm.tir.expr.Reduce:15 tvm.tir.expr.Select:16 tvm.tir.expr.Shuffle:7
#: tvm.tir.expr.SizeVar:8 tvm.tir.expr.StringImm:5 tvm.tir.expr.Sub:7
#: tvm.tir.expr.Var:7
msgid "The location of this expression in the source code."
msgstr ""

#: of tvm.tir.stmt.Allocate:1
msgid "Allocate node."
msgstr ""

#: of tvm.tir.stmt.Allocate:3 tvm.tir.stmt.AllocateConst:3
msgid "The buffer variable."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:10 tvm.tir.stmt.Allocate:5
#: tvm.tir.stmt.AllocateConst:5
msgid "The data type of the buffer."
msgstr ""

#: of tvm.tir.stmt.Allocate:7 tvm.tir.stmt.AllocateConst:7
msgid "The extents of the allocate"
msgstr ""

#: of tvm.tir.stmt.Allocate:9
msgid "The condition."
msgstr ""

#: of tvm.tir.stmt.Allocate:11 tvm.tir.stmt.AllocateConst:14
#: tvm.tir.stmt.AssertStmt:7 tvm.tir.stmt.AttrStmt:9 tvm.tir.stmt.For:11
#: tvm.tir.stmt.LetStmt:7 tvm.tir.stmt.While:5
msgid "The body statement."
msgstr ""

#: of tvm.tir.stmt.Allocate:13
msgid "Additional annotation hints"
msgstr ""

#: of tvm.tir.stmt.Allocate:15 tvm.tir.stmt.AllocateConst:18
#: tvm.tir.stmt.AssertStmt:9 tvm.tir.stmt.AttrStmt:11
#: tvm.tir.stmt.BufferRealize:11 tvm.tir.stmt.BufferStore:13
#: tvm.tir.stmt.Evaluate:5 tvm.tir.stmt.For:18 tvm.tir.stmt.IfThenElse:9
#: tvm.tir.stmt.LetStmt:9 tvm.tir.stmt.Prefetch:7
#: tvm.tir.stmt.ProducerRealize:13 tvm.tir.stmt.ProducerStore:9
#: tvm.tir.stmt.SeqStmt:5 tvm.tir.stmt.While:7
msgid "The location of the stmt in the source code."
msgstr ""

#: of tvm.tir.stmt.AllocateConst:1
msgid "Allocate constant node."
msgstr ""

#: of tvm.tir.stmt.AllocateConst:9
msgid ""
"If an NDArray, this is the const data associated with the constant.  If "
"an integer, this is the index into the \"constants\" attribute of the "
"`IRModule` that contains the `AllocateConst`."
msgstr ""

#: of tvm.tir.stmt.AllocateConst:16
msgid "Additional annotations about the allocation."
msgstr ""

#: of tvm.tir.expr.And:1
msgid "And node."
msgstr ""

#: of tvm.tir.expr.Any:1
msgid "Any node."
msgstr ""

#: of tvm.tir.expr.Any:3
msgid "span"
msgstr ""

#: of tvm.tir.expr.Any:-1
msgid "Optional[Span]"
msgstr ""

#: of tvm.tir.stmt.AssertStmt:1
msgid "AssertStmt node."
msgstr ""

#: of tvm.tir.stmt.AssertStmt:3
msgid "The assert condition."
msgstr ""

#: of tvm.tir.stmt.AssertStmt:5
msgid "The error message."
msgstr ""

#: of tvm.tir.stmt.AttrStmt:1
msgid "AttrStmt node."
msgstr ""

#: of tvm.tir.stmt.AttrStmt:3
msgid "The node to annotate the attribute"
msgstr ""

#: of tvm.tir.stmt.AttrStmt:5
msgid "Attribute type key."
msgstr ""

#: of tvm.tir.stmt.AttrStmt:7
msgid "The value of the attribute"
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout:1
msgid ""
"Bijective mapping for two layouts (src-layout and dst-layout). It "
"provides shape and index conversion between each other."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout:4
msgid ""
"Do not construct directly, use :any:`bijective_layout` instead. See the "
"documentation of :any:`bijective_layout` for more details."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout:7
#: tvm.tir.data_layout.bijective_layout:3
msgid "source layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout:9
#: tvm.tir.data_layout.bijective_layout:5
msgid "destination layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout:14
msgid ":obj:`bijective_layout`"
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout:15 tvm.tir.data_layout.Layout:11
msgid "Declare a layout"
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.backward_index:1
msgid "Given the indices of the dst-layout, infer the src index."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.backward_index:3
msgid "The indices in dst-layout."
msgstr ""

#: ../../doc/docs/reference/api/python/tir/tir.rst
msgid "返回"
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.backward_index:6
msgid "**src_index** -- The inferred indices in src-layout."
msgstr ""

#: ../../doc/docs/reference/api/python/tir/tir.rst
msgid "返回类型"
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.backward_shape:1
msgid "Given the shape of the dst-layout, infer the src shape."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.backward_shape:3
msgid "The shape in dst-layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.backward_shape:6
msgid "**src_shape** -- The inferred shape in src-layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.forward_index:1
msgid "Given the indices of the src-layout, infer the dst index."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.forward_index:3
msgid "The indices in src-layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.forward_index:6
msgid "**dst_index** -- The inferred indices in dst-layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.forward_shape:1
msgid "Given the shape of the src-layout, infer the dst shape."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.forward_shape:3
msgid "The shape in src-layout."
msgstr ""

#: of tvm.tir.data_layout.BijectiveLayout.forward_shape:6
msgid "**dst_shape** -- The inferred shape in dst-layout."
msgstr ""

#: of tvm.tir.stmt.Block:1
msgid "Block node."
msgstr ""

#: of tvm.tir.stmt.Block:3
msgid "The block Variable."
msgstr ""

#: of tvm.tir.stmt.Block:5
msgid "The read buffer regions of the block."
msgstr ""

#: of tvm.tir.stmt.Block:7
msgid "The write buffer regions of the block."
msgstr ""

#: of tvm.tir.stmt.Block:9
msgid "the name_hint of the block."
msgstr ""

#: of tvm.tir.stmt.Block:11
msgid "The body of the block."
msgstr ""

#: of tvm.tir.stmt.Block:13
msgid "The init block of the reduction block"
msgstr ""

#: of tvm.tir.stmt.Block:15
msgid "The buffer allocations"
msgstr ""

#: of tvm.tir.stmt.Block:17
msgid "The subregion buffer match"
msgstr ""

#: of tvm.tir.stmt.Block:19 tvm.tir.stmt.For:16
msgid "Additional annotation hints."
msgstr ""

#: of tvm.tir.stmt.Block:21
msgid "The location of this block in the source code."
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo:1
msgid ""
"An object that helps build and query block level dependences using the 2 "
"core objects BlockScope and StmtSRef"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo:4
msgid ""
"The data structures exposed are: 1) sref2scope: Mapping from the srefs to"
" its corresponding BlockScope 2) stmt2ref: Mapping from blocks to "
"corresponding StmtSRefs"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo:8
msgid ""
"Note that this object does not store SRefs to loops as the purpose is "
"only to expose block level dependences. This provides the advantage that "
"the scope block (parent block) for a given block sref can be directly "
"accessed as sref->parent"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo.get_block_scope:1
msgid "Get the BlockScope correpsonding to the block sref"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo.get_block_scope:3
msgid "The block sref to be retrieved"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo.get_block_scope:6
msgid "**scope** -- The corresponding BlockScope"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo.get_sref:1
msgid "Return the corresponding sref that points to the block"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo.get_sref:3
msgid "The block for which the sref is to be retrived"
msgstr ""

#: of tvm.tir.block_dependence_info.BlockDependenceInfo.get_sref:6
msgid "**sref** -- The corresponding sref"
msgstr ""

#: of tvm.tir.stmt.BlockRealize:1
msgid "BlockRealize node."
msgstr ""

#: of tvm.tir.stmt.BlockRealize:3
msgid "The binding values of the block var."
msgstr ""

#: of tvm.tir.stmt.BlockRealize:5
msgid "The predicate of the block."
msgstr ""

#: of tvm.tir.stmt.BlockRealize:7
msgid "The block to realize"
msgstr ""

#: of tvm.tir.stmt.BlockRealize:9
msgid "The location of this block_realize in the source code."
msgstr ""

#: of tvm.tir.expr.Broadcast:1
msgid "Broadcast node."
msgstr ""

#: of tvm.tir.expr.Broadcast:3
msgid "The value of the expression."
msgstr ""

#: of tvm.tir.expr.Broadcast:5 tvm.tir.expr.Ramp:7
msgid "The lanes of the expression."
msgstr ""

#: of tvm.tir.buffer.Buffer:1
msgid "Symbolic data buffer in TVM."
msgstr ""

#: of tvm.tir.buffer.Buffer:3
msgid ""
"Buffer provide a way to represent data layout specialization of data "
"structure in TVM."
msgstr ""

#: of tvm.tir.buffer.Buffer:6
msgid ""
"Do not construct directly, use :py:func:`~decl_buffer` instead. See the "
"documentation of :py:func:`decl_buffer` for more details."
msgstr ""

#: of tvm.tir.buffer.Buffer:11
msgid ":obj:`decl_buffer`"
msgstr ""

#: of tvm.tir.buffer.Buffer:12
msgid "Declare a buffer"
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:1
msgid "Get an access pointer to the head of buffer."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:3
msgid ""
"This is the recommended method to get buffer data ptress when interacting"
" with external functions."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:6
msgid ""
"The access pattern MASK. Indicate whether the access will read or write "
"to the data content."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:9
msgid ""
"The data type of the result pointer. Do not specify unless we want to "
"cast pointer to specific type."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:12
msgid ""
"The number of lanes for the data type. This value is greater than one for"
" vector types."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:15
msgid ""
"The offset of pointer. We can use it to offset by the number of elements "
"from the address of ptr."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:18 tvm.tir.op.tvm_access_ptr:9
msgid "The extent of pointer."
msgstr ""

#: of tvm.tir.buffer.Buffer.access_ptr:22 tvm.tir.buffer.decl_buffer:47
#: tvm.tir.function.IndexMap.non_surjective_inverse:14
#: tvm.tir.function.PrimFunc.specialize:7 tvm.tir.op.comm_reducer:17
#: tvm.tir.op.comm_reducer.<locals>.reducer:14
msgid "示例"
msgstr ""

#: of tvm.tir.buffer.Buffer.get_flattened_buffer:1
msgid "Generate a Buffer that is a flattened version of this buffer."
msgstr ""

#: of tvm.tir.buffer.Buffer.get_flattened_buffer:3
msgid "**flattened** -- The corresponding flat buffer."
msgstr ""

#: of tvm.tir.buffer.Buffer.offset_of:1
msgid "Determine the offset of the provided indices in the flattened buffer."
msgstr ""

#: of tvm.tir.buffer.Buffer.offset_of:3
msgid "The indices of the element in the original buffer."
msgstr ""

#: of tvm.tir.buffer.Buffer.offset_of:6
msgid ""
"**flattened_indices** -- The offset indices of the element in the "
"flattened buffer."
msgstr ""

#: of tvm.tir.buffer.Buffer.scope:1
msgid ""
"Return the storage scope associated with this buffer. :returns: **scope**"
" -- The storage scope associated with this buffer. :rtype: str"
msgstr ""

#: of tvm.tir.buffer.Buffer.vload:1
msgid "Generate an Expr that loads dtype from begin index."
msgstr ""

#: of tvm.tir.buffer.Buffer.vload:3 tvm.tir.buffer.Buffer.vstore:3
msgid "The beginning index in unit of Buffer.dtype"
msgstr ""

#: of tvm.tir.buffer.Buffer.vload:5
msgid ""
"The data type to be loaded, can be vector type which have lanes that is "
"multiple of Buffer.dtype"
msgstr ""

#: of tvm.tir.buffer.Buffer.vload:8 tvm.tir.expr.BufferLoad:9
msgid ""
"A vector mask of boolean values indicating which lanes of a vector are to"
" be loaded. The number lanes of the mask must be equal to the number of "
"lanes being loaded."
msgstr ""

#: of tvm.tir.buffer.Buffer.vload:12
msgid "**load** -- The corresponding load expression."
msgstr ""

#: of tvm.tir.buffer.Buffer.vstore:1
msgid "Generate a Stmt that store value into begin index."
msgstr ""

#: of tvm.tir.buffer.Buffer.vstore:5 tvm.tir.stmt.ProducerStore:5
msgid "The value to be stored."
msgstr ""

#: of tvm.tir.buffer.Buffer.vstore:7 tvm.tir.stmt.BufferStore:9
msgid ""
"A vector mask of boolean values indicating which lanes of a vector are to"
" be stored. The number lanes of the mask must be equal to the number of "
"lanes in value."
msgstr ""

#: of tvm.tir.buffer.Buffer.vstore:12
msgid "**store** -- The corresponding store stmt."
msgstr ""

#: of tvm.tir.expr.BufferLoad:1
msgid "Buffer load node."
msgstr ""

#: of tvm.tir.expr.BufferLoad:3 tvm.tir.expr.ProducerLoad:3
msgid "The buffer to be loaded."
msgstr ""

#: of tvm.tir.expr.BufferLoad:5
msgid "The buffer indices to load values from."
msgstr ""

#: of tvm.tir.stmt.BufferRealize:1
msgid "Buffer realize node."
msgstr ""

#: of tvm.tir.stmt.BufferRealize:3 tvm.tir.stmt.BufferStore:3
msgid "The buffer."
msgstr ""

#: of tvm.tir.stmt.BufferRealize:5 tvm.tir.stmt.BufferStore:5
msgid "The value we to be stored."
msgstr ""

#: of tvm.tir.stmt.BufferRealize:7 tvm.tir.stmt.ProducerRealize:7
msgid "The realize condition."
msgstr ""

#: of tvm.tir.stmt.BufferRealize:9
msgid "The body of the statement."
msgstr ""

#: of tvm.tir.stmt.BufferRegion:1
msgid "BufferRegion node."
msgstr ""

#: of tvm.tir.stmt.BufferRegion:3
msgid "The buffer of the buffer region"
msgstr ""

#: of tvm.tir.stmt.BufferRegion:5
msgid "The region array of the buffer region"
msgstr ""

#: of tvm.tir.stmt.BufferStore:1
msgid "Buffer store node."
msgstr ""

#: of tvm.tir.stmt.BufferStore:7
msgid "The indices location to be stored."
msgstr ""

#: of tvm.tir.expr.Call:1
msgid "Call node."
msgstr ""

#: of tvm.tir.expr.Call:3
msgid "The return data type"
msgstr ""

#: of tvm.tir.expr.Call:5
msgid "The function to be called, or the name to the global tvm.Op"
msgstr ""

#: of tvm.tir.expr.Call:8
msgid "The input arguments to the call"
msgstr ""

#: of tvm.tir.expr.CallEffectKind:1
msgid "Possible kinds of Call effects."
msgstr ""

#: of tvm.tir.expr.Cast:1
msgid "Cast expression."
msgstr ""

#: of tvm.tir.expr.Cast:3 tvm.tir.expr.FloatImm:3 tvm.tir.expr.IntImm:3
#: tvm.tir.expr.SizeVar:6 tvm.tir.expr.Var:5
msgid "The data type"
msgstr ""

#: of tvm.tir.expr.Cast:5 tvm.tir.expr.StringImm:3
msgid "The value of the function."
msgstr ""

#: of tvm.tir.expr.CommReducer:1
msgid "Commutative reduce operator"
msgstr ""

#: of tvm.tir.expr.CommReducer:3
msgid "The left arguments of the reducer."
msgstr ""

#: of tvm.tir.expr.CommReducer:5
msgid "The right arguments of the reducer."
msgstr ""

#: of tvm.tir.expr.CommReducer:7
msgid "The reduction results."
msgstr ""

#: of tvm.tir.expr.CommReducer:9
msgid "The identity elements."
msgstr ""

#: of tvm.tir.stmt.DeclBuffer:1
msgid "DeclBuffer node."
msgstr ""

#: of tvm.tir.stmt.DeclBuffer:3
msgid "The buffer being declared."
msgstr ""

#: of tvm.tir.stmt.DeclBuffer:5
msgid "The body statement to be executed."
msgstr ""

#: of tvm.tir.stmt.DeclBuffer:7
msgid "The location of this DeclBuffer in the source code."
msgstr ""

#: of tvm.tir.expr.Div:1
msgid "Div node."
msgstr ""

#: of tvm.tir.expr.EQ:1
msgid "EQ node."
msgstr ""

#: of tvm.tir.stmt.Evaluate:1
msgid "Evaluate node."
msgstr ""

#: of tvm.tir.stmt.Evaluate:3
msgid "The expression to be evaluated."
msgstr ""

#: of tvm.tir.expr.FloatImm:1
msgid "Float constant."
msgstr ""

#: of tvm.tir.expr.FloatImm:5 tvm.tir.expr.IntImm:5
msgid "The constant value."
msgstr ""

#: of tvm.tir.expr.FloorDiv:1
msgid "FloorDiv node."
msgstr ""

#: of tvm.tir.expr.FloorMod:1
msgid "FloorMod node."
msgstr ""

#: of tvm.tir.stmt.For:1
msgid "For node."
msgstr ""

#: of tvm.tir.stmt.For:3
msgid "The loop variable."
msgstr ""

#: of tvm.tir.stmt.For:5
msgid "The beginning value."
msgstr ""

#: of tvm.tir.stmt.For:7
msgid "The length of the loop."
msgstr ""

#: of tvm.tir.stmt.For:9
msgid "The type of the for."
msgstr ""

#: of tvm.tir.stmt.For:13
msgid "The thread this loop binds to. Only valid if kind is ThreadBinding"
msgstr ""

#: of tvm.tir.stmt.ForKind:1
msgid "The kind of the for loop."
msgstr ""

#: of tvm.tir.stmt.ForKind:5
msgid ""
"ForKind can change the control flow semantics of the loop and need to be "
"considered in all TIR passes."
msgstr ""

#: of tvm.tir.expr.GE:1
msgid "GE node."
msgstr ""

#: of tvm.tir.expr.GT:1
msgid "GT node."
msgstr ""

#: of tvm.tir.stmt.IfThenElse:1
msgid "IfThenElse node."
msgstr ""

#: of tvm.tir.stmt.IfThenElse:3
msgid "The expression"
msgstr ""

#: of tvm.tir.stmt.IfThenElse:5
msgid "The statement to execute if condition is true."
msgstr ""

#: of tvm.tir.stmt.IfThenElse:7
msgid "The statement to execute if condition is false."
msgstr ""

#: of tvm.tir.function.IndexMap:1
msgid ""
"A mapping from multi-dimensional indices to another set of multi-"
"dimensional indices"
msgstr ""

#: of tvm.tir.function.IndexMap:3
msgid "Variables representing the indices prior to remapping."
msgstr ""

#: of tvm.tir.function.IndexMap:5
msgid "Expressions defining the indices after remapping."
msgstr ""

#: of tvm.tir.function.IndexMap:7 tvm.tir.function.IndexMap.from_func:15
#: tvm.tir.function.IndexMap.from_func_with_separators:17
msgid ""
"The optional pre-defined inverse index map. When this is defined, "
"IndexMap::Inverse will return the pre-defined inverse index map. "
"Otherwise, the inverse index map will be computed on the fly. It is the "
"user's responsibility to ensure the correctness of the pre-defined "
"inverse index map."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func:1
#: tvm.tir.function.IndexMap.from_func_with_separators:1
msgid "Create an index map from a function"
msgstr ""

#: of tvm.tir.function.IndexMap.from_func:3
msgid ""
"The function to map from source indices to target indices. The function "
"should accept `tir.Var` parameters and return a either a `tir.PrimExpr`, "
"or a list of `tir.PrimExpr`. Returning a `tir.PrimExpr` is equivalent to "
"returning a list of length 1 containing that `tir.PrimExpr`."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func:9
msgid ""
"The dimensionality of the buffer to which this transformation should be "
"applied.  If mapping_function uses variadic argument `*args`, `ndim` must"
" be specified.  If mapping_function does not use variadic arguments, ndim"
" is optional."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func:22
msgid "**index_map** -- Returns an IndexMap representing the `mapping_function`."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func_with_separators:3
msgid ""
"The function to map from source indices to target indices. The function "
"should accept tir.Var parameters and return either a `tir.PrimExpr` or a "
"list.  Each element of the returned list should be either a "
"`tir.PrimExpr` or the object `IndexMap.AXIS_SEPARATOR`.  Returning a "
"`tir.PrimExpr` is equivalent to returning a list of length 1 containing "
"that `tir.PrimExpr`."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func_with_separators:11
msgid ""
"The dimensionality of the buffer to which this transformation should be "
"applied.  If mapping_function uses variadic argument `*args`, ndim must "
"be specified.  If mapping_function does not use variadic arguments, ndim "
"is optional."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func_with_separators:23
msgid "The default index dtype to use for input iters in the mapping function."
msgstr ""

#: of tvm.tir.function.IndexMap.from_func_with_separators:26
msgid ""
"**ret** -- Returns a tuple whose first element is an IndexMap "
"representing the `mapping_function`, and whose second index is a list of "
"indices at which `IndexMap.AXIS_SEPARATOR` occurred."
msgstr ""

#: of tvm.tir.function.IndexMap.inverse:1
#: tvm.tir.function.IndexMap.non_surjective_inverse:1
msgid "Return the inverse of the map"
msgstr ""

#: of tvm.tir.function.IndexMap.inverse:3
msgid "Throws an error if the function is not bijective."
msgstr ""

#: of tvm.tir.function.IndexMap.inverse:5
msgid ""
"The region over which the inverse should be determined. Used for "
"validating that the mapping is bijective over this range."
msgstr ""

#: of tvm.tir.function.IndexMap.inverse:10
msgid "**inverse** -- The inverse"
msgstr ""

#: of tvm.tir.function.IndexMap.is_equivalent_to:1
msgid "Return if the index maps are equivalent."
msgstr ""

#: of tvm.tir.function.IndexMap.is_equivalent_to:3
msgid "The IndexMap to which the comparison should be made."
msgstr ""

#: of tvm.tir.function.IndexMap.is_equivalent_to:6
msgid ""
"**is_equivalent** -- True if the two mappings represent the same "
"transformation, otherwise False"
msgstr ""

#: of tvm.tir.function.IndexMap.map_indices:1
msgid "Apply the index map to a set of indices"
msgstr ""

#: of tvm.tir.function.IndexMap.map_indices:3
msgid "The indices to be mapped"
msgstr ""

#: of tvm.tir.function.IndexMap.map_indices:6
msgid "**result** -- The mapped indices"
msgstr ""

#: of tvm.tir.function.IndexMap.map_ndarray:1
msgid "Apply thie index map to transform the layout of the input NDArray"
msgstr ""

#: of tvm.tir.function.IndexMap.map_ndarray:3
msgid "The NDArray to be transformed"
msgstr ""

#: of tvm.tir.function.IndexMap.map_ndarray:6
msgid "**arr_dst** -- The transformed NDArray"
msgstr ""

#: of tvm.tir.function.IndexMap.map_shape:1
msgid "Apply the index map to a buffer shape"
msgstr ""

#: of tvm.tir.function.IndexMap.map_shape:3
msgid "The buffer shape to be mapped"
msgstr ""

#: of tvm.tir.function.IndexMap.map_shape:6
msgid "**result** -- The mapped shape"
msgstr ""

#: of tvm.tir.function.IndexMap.non_surjective_inverse:3
msgid "Can be applied to transformations that introduce padding."
msgstr ""

#: of tvm.tir.function.IndexMap.non_surjective_inverse:5
msgid ""
"The region over which the inverse should be determined. Used for "
"determining the predicate."
msgstr ""

#: of tvm.tir.function.IndexMap.non_surjective_inverse:9
msgid ""
"**result** -- The inverse, and a predicate for which the inverse maps to "
"a valid index in the input range."
msgstr ""

#: of tvm.tir.expr.IntImm:1
msgid "Int constant."
msgstr ""

#: of tvm.tir.expr.IterVar:1
msgid "Represent iteration variable."
msgstr ""

#: of tvm.tir.expr.IterVar:3
msgid "IterVar represents axis iterations in the computation."
msgstr ""

#: of tvm.tir.expr.IterVar:5
msgid "The domain of the iteration."
msgstr ""

#: of tvm.tir.expr.IterVar:7
msgid "The internal variable that is used for iteration."
msgstr ""

#: of tvm.tir.expr.IterVar:9
msgid "The iteration type."
msgstr ""

#: of tvm.tir.expr.IterVar:11
msgid "The thread type tag."
msgstr ""

#: of tvm.tir.expr.IterVar:18
msgid ":obj:`te.thread_axis`"
msgstr ""

#: of tvm.tir.expr.IterVar:19
msgid "Create thread axis IterVar."
msgstr ""

#: of tvm.tir.expr.IterVar:21
msgid ":obj:`te.reduce_axis`"
msgstr ""

#: of tvm.tir.expr.IterVar:22
msgid "Create reduce axis IterVar."
msgstr ""

#: of tvm.tir.expr.LE:1
msgid "LE node."
msgstr ""

#: of tvm.tir.expr.LT:1
msgid "LT node."
msgstr ""

#: of tvm.tir.data_layout.Layout:1
msgid ""
"Layout is composed of upper cases, lower cases and numbers, where upper "
"case indicates a primal axis and the corresponding lower case with factor"
" size indicates the subordinate axis. For example, NCHW16c can describe a"
" 5-D tensor of [batch_size, channel, height, width, channel_block]. Here "
"subordinate axis channel_block=16 is the factor size of the primal axis C"
" (channel)."
msgstr ""

#: of tvm.tir.data_layout.Layout:10
msgid ":obj:`layout`"
msgstr ""

#: of tvm.tir.data_layout.Layout.factor_of:1
msgid "Get the factor size of the subordinate axis."
msgstr ""

#: of tvm.tir.data_layout.Layout.factor_of:3
#: tvm.tir.data_layout.Layout.index_of:3
msgid "The axis name, need to be [a-z,A-Z]"
msgstr ""

#: of tvm.tir.data_layout.Layout.factor_of:6
msgid ""
"**factor** -- the size of the subordinate-axis of axis (if axis is a "
"primal-axis), or the size of axis itself (if axis is a subordinate-axis)."
" Return -1 if axis is not in the layout."
msgstr ""

#: of tvm.tir.data_layout.Layout.index_of:1
msgid "Get the index of an axis"
msgstr ""

#: of tvm.tir.data_layout.Layout.index_of:6
msgid "**index** -- The index of the axis, -1 if not found."
msgstr ""

#: of tvm.tir.expr.Let:1
msgid "Let node."
msgstr ""

#: of tvm.tir.expr.Let:3 tvm.tir.stmt.LetStmt:3
msgid "The variable in the binding."
msgstr ""

#: of tvm.tir.expr.Let:5 tvm.tir.stmt.LetStmt:5
msgid "The value in to be bound."
msgstr ""

#: of tvm.tir.expr.Let:7
msgid "The body expression."
msgstr ""

#: of tvm.tir.stmt.LetStmt:1
msgid "LetStmt node."
msgstr ""

#: of tvm.tir.stmt.MatchBufferRegion:1
msgid "MatchBufferRegion node."
msgstr ""

#: of tvm.tir.stmt.MatchBufferRegion:3
msgid "The target buffer"
msgstr ""

#: of tvm.tir.stmt.MatchBufferRegion:5
msgid "The region of source buffer"
msgstr ""

#: of tvm.tir.expr.Max:1
msgid "Max node."
msgstr ""

#: of tvm.tir.expr.Min:1
msgid "Min node."
msgstr ""

#: of tvm.tir.expr.Mod:1
msgid "Mod node."
msgstr ""

#: of tvm.tir.expr.Mul:1
msgid "Mul node."
msgstr ""

#: of tvm.tir.expr.NE:1
msgid "NE node."
msgstr ""

#: of tvm.tir.expr.Not:1
msgid "Not node."
msgstr ""

#: of tvm.tir.expr.Not:3
msgid "The input value"
msgstr ""

#: of tvm.tir.expr.Or:1
msgid "Or node."
msgstr ""

#: of tvm.tir.stmt.Prefetch:1
msgid "Prefetch node."
msgstr ""

#: of tvm.tir.stmt.Prefetch:3
msgid "The buffer to be prefetched."
msgstr ""

#: of tvm.tir.stmt.Prefetch:5
msgid "The bounds to be prefetched."
msgstr ""

#: of tvm.tir.function.PrimFunc:1
msgid "A function declaration expression."
msgstr ""

#: of tvm.tir.function.PrimFunc:3
msgid "List of input parameters to the function."
msgstr ""

#: of tvm.tir.function.PrimFunc:5
msgid "The body of the function."
msgstr ""

#: of tvm.tir.function.PrimFunc:7
msgid "The return type annotation of the function."
msgstr ""

#: of tvm.tir.function.PrimFunc:9
msgid "The buffer binding map."
msgstr ""

#: of tvm.tir.function.PrimFunc:11
msgid "Attributes of the function, can be None"
msgstr ""

#: of tvm.tir.function.PrimFunc:13 tvm.tir.function.PrimFunc.with_body:5
msgid "The location of this itervar in the source code."
msgstr ""

#: of tvm.tir.function.PrimFunc.specialize:1
msgid "Specialize parameters of PrimFunc"
msgstr ""

#: of tvm.tir.function.PrimFunc.specialize:3
msgid "The mapping from function params to the instance"
msgstr ""

#: of tvm.tir.function.PrimFunc.specialize:8
msgid "We can define a Meta TIR function with symbolic shape:"
msgstr ""

#: of tvm.tir.function.PrimFunc.specialize:22
msgid "Then we can make it specialized with given shapes or buffers."
msgstr ""

#: of tvm.tir.function.PrimFunc.specialize:31
msgid "The specialized function:"
msgstr ""

#: of tvm.tir.function.PrimFunc.specialize:45
msgid "**func** -- The new function with parameter specialized"
msgstr ""

#: of tvm.tir.function.PrimFunc.with_body:1
msgid "Create a new PrimFunc with the same set signatures but a new body."
msgstr ""

#: of tvm.tir.function.PrimFunc.with_body:3
msgid "The new body."
msgstr ""

#: of tvm.tir.function.PrimFunc.with_body:8
msgid "**new_func** -- The created new function."
msgstr ""

#: of tvm.tir.expr.ProducerLoad:1
msgid "Producer load node."
msgstr ""

#: of tvm.tir.expr.ProducerLoad:5
msgid "The buffer indices."
msgstr ""

#: of tvm.tir.stmt.ProducerRealize:1
msgid "ProducerRealize node."
msgstr ""

#: of tvm.tir.stmt.ProducerRealize:3 tvm.tir.stmt.ProducerStore:3
msgid "The data producer."
msgstr ""

#: of tvm.tir.stmt.ProducerRealize:5
msgid "The bound of realize"
msgstr ""

#: of tvm.tir.stmt.ProducerRealize:9
msgid "The realize body"
msgstr ""

#: of tvm.tir.stmt.ProducerRealize:11
msgid "The storage scope associated with this realization"
msgstr ""

#: of tvm.tir.stmt.ProducerStore:1
msgid "ProducerStore node."
msgstr ""

#: of tvm.tir.stmt.ProducerStore:7
msgid "The index arguments of the store."
msgstr ""

#: of tvm.tir.expr.Ramp:1
msgid "Ramp node."
msgstr ""

#: of tvm.tir.expr.Ramp:3
msgid "The base expression."
msgstr ""

#: of tvm.tir.expr.Ramp:5
msgid "The stride of the ramp."
msgstr ""

#: of tvm.tir.expr.Reduce:1
msgid "Reduce node."
msgstr ""

#: of tvm.tir.expr.Reduce:3
msgid "The combiner."
msgstr ""

#: of tvm.tir.expr.Reduce:5 tvm.tir.op.comm_reducer.<locals>.reducer:3
msgid "The source expression."
msgstr ""

#: of tvm.tir.expr.Reduce:7
msgid "The iteration domain"
msgstr ""

#: of tvm.tir.expr.Reduce:9
msgid "The reduce condition."
msgstr ""

#: of tvm.tir.expr.Reduce:11
msgid "The value index."
msgstr ""

#: of tvm.tir.expr.Reduce:13
msgid "The initial value for output. This can be an int, float or ProducerLoad"
msgstr ""

#: of tvm.tir.expr.Select:1
msgid "Select node."
msgstr ""

#: of tvm.tir.expr.Select:5
msgid ""
"Select may compute both true_value and false_value. Use "
":py:class:`tvm.tir.if_then_else` instead if you want to get a conditional"
" expression that only evaluates the correct branch."
msgstr ""

#: of tvm.tir.expr.Select:10
msgid "The condition expression."
msgstr ""

#: of tvm.tir.expr.Select:12
msgid "The value to take when condition is true."
msgstr ""

#: of tvm.tir.expr.Select:14
msgid "The value to take when condition is false."
msgstr ""

#: of tvm.tir.stmt.SeqStmt:1
msgid "Sequence of statements."
msgstr ""

#: of tvm.tir.stmt.SeqStmt:3
msgid "The statements"
msgstr ""

#: of tvm.tir.expr.Shuffle:1
msgid "Shuffle node."
msgstr ""

#: of tvm.tir.expr.Shuffle:3
msgid "The vectors"
msgstr ""

#: of tvm.tir.expr.Shuffle:5
msgid "The indices"
msgstr ""

#: of tvm.tir.expr.SizeVar:1
msgid "Symbolic variable to represent a tensor index size"
msgstr ""

#: of tvm.tir.expr.SizeVar:2
msgid "which is greater or equal to zero."
msgstr ""

#: of tvm.tir.expr.SizeVar:4 tvm.tir.expr.Var:3
msgid "The name"
msgstr ""

#: of tvm.tir.stmt.Stmt:1
msgid "Base class of all the statements."
msgstr ""

#: of tvm.tir.expr.StringImm:1
msgid "String constant."
msgstr ""

#: of tvm.tir.expr.Sub:1
msgid "Sub node."
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:1
msgid "Backend function to allocate temporal workspace"
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:3
#: tvm.tir.op.TVMBackendFreeWorkspace:3
msgid "The device type which the space will be allocated."
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:5
#: tvm.tir.op.TVMBackendFreeWorkspace:5
msgid "The device id which the space will be allocated."
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:7
msgid "The size of the space requested."
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:9
msgid ""
"The type code of the array elements. Only used in certain backends such "
"as OpenGL."
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:11
msgid ""
"The type bits of the array elements. Only used in certain backends such "
"as OpenGL."
msgstr ""

#: of tvm.tir.op.TVMBackendAllocWorkspace:14
#: tvm.tir.op.TVMBackendFreeWorkspace:10 tvm.tir.op.address_of:8
#: tvm.tir.op.assume:6 tvm.tir.op.call_cpacked:11
#: tvm.tir.op.call_cpacked_lowered:10 tvm.tir.op.call_extern:12
#: tvm.tir.op.call_intrin:15 tvm.tir.op.call_llvm_intrin:12
#: tvm.tir.op.call_llvm_pure_intrin:12 tvm.tir.op.call_packed:15
#: tvm.tir.op.call_packed_lowered:13 tvm.tir.op.call_pure_extern:12
#: tvm.tir.op.call_tir:3 tvm.tir.op.create_barriers:6 tvm.tir.op.dp4a:10
#: tvm.tir.op.end_profile_intrinsic:5 tvm.tir.op.lookup_param:8
#: tvm.tir.op.make_filled_simdgroup_matrix:14 tvm.tir.op.mma_fill:12
#: tvm.tir.op.mma_store:18 tvm.tir.op.ptx_arrive_barrier:7
#: tvm.tir.op.ptx_arrive_barrier_expect_tx:11 tvm.tir.op.ptx_commit_group:4
#: tvm.tir.op.ptx_cp_async:17 tvm.tir.op.ptx_cp_async_barrier:7
#: tvm.tir.op.ptx_cp_async_bulk:19 tvm.tir.op.ptx_init_barrier_thread_count:9
#: tvm.tir.op.ptx_ldmatrix:21 tvm.tir.op.ptx_mma:35 tvm.tir.op.ptx_mma_sp:39
#: tvm.tir.op.ptx_wait_barrier:7 tvm.tir.op.ptx_wait_group:7
#: tvm.tir.op.simdgroup_load:18 tvm.tir.op.simdgroup_multiply_accumulate:21
#: tvm.tir.op.simdgroup_store:19 tvm.tir.op.start_profile_intrinsic:5
#: tvm.tir.op.trace:13 tvm.tir.op.tvm_access_ptr:14 tvm.tir.op.tvm_bmma_sync:20
#: tvm.tir.op.tvm_check_return:9 tvm.tir.op.tvm_fill_fragment:16
#: tvm.tir.op.tvm_load_matrix_sync:20 tvm.tir.op.tvm_mma_sync:20
#: tvm.tir.op.tvm_stack_alloca:8 tvm.tir.op.tvm_stack_make_array:16
#: tvm.tir.op.tvm_stack_make_shape:6 tvm.tir.op.tvm_store_matrix_sync:20
#: tvm.tir.op.tvm_struct_get:12 tvm.tir.op.tvm_struct_set:12
#: tvm.tir.op.tvm_thread_allreduce:6 tvm.tir.op.tvm_tuple:6
#: tvm.tir.op.type_annotation:6 tvm.tir.op.undef:3 tvm.tir.op.vectorcombine:8
#: tvm.tir.op.vectorhigh:8 tvm.tir.op.vectorlow:8
msgid "**call** -- The call expression."
msgstr ""

#: of tvm.tir.op.TVMBackendFreeWorkspace:1
msgid "Backend function to free temporal workspace."
msgstr ""

#: of tvm.tir.op.TVMBackendFreeWorkspace:7
msgid "The result allocated space pointer."
msgstr ""

#: of tvm.tir.function.TensorIntrin:1
msgid "A tensor intrinsic."
msgstr ""

#: of tvm.tir.function.TensorIntrin:3 tvm.tir.function.TensorIntrin.register:5
msgid "The function to describe the computation."
msgstr ""

#: of tvm.tir.function.TensorIntrin:5 tvm.tir.function.TensorIntrin.register:7
msgid "The function of the implementation for the execution."
msgstr ""

#: of tvm.tir.function.TensorIntrin.get:1
msgid "Look up a tensor intrinsic by its name."
msgstr ""

#: of tvm.tir.function.TensorIntrin.get:3
msgid "The name of the TensorIntrin to look up."
msgstr ""

#: of tvm.tir.function.TensorIntrin.get:5
msgid ""
"Whether to allow missing tensor intrin. If False, raise an error if the "
"tensor intrin"
msgstr ""

#: of tvm.tir.function.TensorIntrin.get:9
msgid ""
"**result** -- The TensorIntrin with the specified name, or None if not "
"found."
msgstr ""

#: of tvm.tir.function.TensorIntrin.register:1
msgid "Register a tensor intrinsic with its name."
msgstr ""

#: of tvm.tir.function.TensorIntrin.register:3
msgid "The name of the TensorIntrin to register."
msgstr ""

#: of tvm.tir.function.TensorIntrin.register:9
msgid "Whether override existing intrinsic."
msgstr ""

#: of tvm.tir.expr.Var:1
msgid "Symbolic variable."
msgstr ""

#: of tvm.tir.stmt.While:1
msgid "While node."
msgstr ""

#: of tvm.tir.stmt.While:3
msgid "The termination condition."
msgstr ""

#: of tvm.tir.op.abs:1
msgid "Get absolute value of the input element-wise."
msgstr ""

#: of tvm.tir.op.abs:3 tvm.tir.op.acos:3 tvm.tir.op.acosh:3 tvm.tir.op.asin:3
#: tvm.tir.op.asinh:3 tvm.tir.op.atan:3 tvm.tir.op.atan2:3 tvm.tir.op.atan2:5
#: tvm.tir.op.atanh:3 tvm.tir.op.ceil:3 tvm.tir.op.copysign:3
#: tvm.tir.op.copysign:5 tvm.tir.op.cos:3 tvm.tir.op.cosh:3 tvm.tir.op.erf:3
#: tvm.tir.op.exp:3 tvm.tir.op.exp10:3 tvm.tir.op.exp2:3 tvm.tir.op.floor:3
#: tvm.tir.op.fmod:3 tvm.tir.op.fmod:5 tvm.tir.op.hypot:3 tvm.tir.op.hypot:5
#: tvm.tir.op.isfinite:3 tvm.tir.op.isinf:3 tvm.tir.op.isnan:3
#: tvm.tir.op.isnullptr:3 tvm.tir.op.ldexp:3 tvm.tir.op.ldexp:5
#: tvm.tir.op.likely:3 tvm.tir.op.log:3 tvm.tir.op.log10:3 tvm.tir.op.log1p:3
#: tvm.tir.op.log2:3 tvm.tir.op.nearbyint:10 tvm.tir.op.nextafter:3
#: tvm.tir.op.nextafter:5 tvm.tir.op.popcount:3 tvm.tir.op.pow:3
#: tvm.tir.op.power:3 tvm.tir.op.round:3 tvm.tir.op.rsqrt:3
#: tvm.tir.op.shift_left:3 tvm.tir.op.shift_left:5 tvm.tir.op.shift_right:3
#: tvm.tir.op.shift_right:5 tvm.tir.op.sigmoid:3 tvm.tir.op.sin:3
#: tvm.tir.op.sinh:3 tvm.tir.op.sqrt:3 tvm.tir.op.tan:3 tvm.tir.op.tanh:3
#: tvm.tir.op.trunc:6
msgid "Input argument."
msgstr ""

#: of tvm.tir.op.abs:5 tvm.tir.op.address_of:5 tvm.tir.op.all:6
#: tvm.tir.op.any:5 tvm.tir.op.bitwise_and:7 tvm.tir.op.bitwise_not:5
#: tvm.tir.op.bitwise_or:7 tvm.tir.op.bitwise_xor:7 tvm.tir.op.call_cpacked:8
#: tvm.tir.op.call_cpacked_lowered:7 tvm.tir.op.call_extern:9
#: tvm.tir.op.call_intrin:12 tvm.tir.op.call_llvm_intrin:9
#: tvm.tir.op.call_llvm_pure_intrin:9 tvm.tir.op.call_packed:12
#: tvm.tir.op.call_packed_lowered:10 tvm.tir.op.call_pure_extern:9
#: tvm.tir.op.ceil:5 tvm.tir.op.floor:5 tvm.tir.op.infinity:5
#: tvm.tir.op.isfinite:5 tvm.tir.op.isinf:5 tvm.tir.op.isnan:5
#: tvm.tir.op.isnullptr:5 tvm.tir.op.likely:5 tvm.tir.op.lookup_param:5
#: tvm.tir.op.max_value:5 tvm.tir.op.min_value:5 tvm.tir.op.nearbyint:12
#: tvm.tir.op.pow:7 tvm.tir.op.power:7 tvm.tir.op.reinterpret:7
#: tvm.tir.op.ret:5 tvm.tir.op.round:5 tvm.tir.op.trunc:8
msgid "The location of this operator in the source code."
msgstr ""

#: of tvm.tir.op.abs:8 tvm.tir.op.acos:6 tvm.tir.op.acosh:6 tvm.tir.op.asin:6
#: tvm.tir.op.asinh:6 tvm.tir.op.atan:6 tvm.tir.op.atan2:8 tvm.tir.op.atanh:6
#: tvm.tir.op.ceil:8 tvm.tir.op.clz:7 tvm.tir.op.copysign:8 tvm.tir.op.cos:6
#: tvm.tir.op.cosh:6 tvm.tir.op.erf:6 tvm.tir.op.exp:6 tvm.tir.op.exp10:6
#: tvm.tir.op.exp2:6 tvm.tir.op.floor:8 tvm.tir.op.hypot:8
#: tvm.tir.op.isfinite:8 tvm.tir.op.isinf:8 tvm.tir.op.isnan:8
#: tvm.tir.op.isnullptr:8 tvm.tir.op.ldexp:8 tvm.tir.op.log:6
#: tvm.tir.op.log10:6 tvm.tir.op.log1p:6 tvm.tir.op.log2:6
#: tvm.tir.op.nearbyint:15 tvm.tir.op.nextafter:8 tvm.tir.op.popcount:6
#: tvm.tir.op.q_multiply_shift:19 tvm.tir.op.round:8 tvm.tir.op.rsqrt:6
#: tvm.tir.op.sigmoid:6 tvm.tir.op.sin:6 tvm.tir.op.sinh:6 tvm.tir.op.sqrt:6
#: tvm.tir.op.tan:6 tvm.tir.op.tanh:6 tvm.tir.op.trunc:11
msgid "**y** -- The result."
msgstr ""

#: of tvm.tir.op.acos:1 tvm.tir.op.acosh:1
msgid "Take acos of input x."
msgstr ""

#: of tvm.tir.generic.add:1
msgid "Generic add operator."
msgstr ""

#: of tvm.tir.generic.add:3 tvm.tir.generic.multiply:3
#: tvm.tir.generic.subtract:3 tvm.tir.op.ceildiv:3
msgid "The left operand."
msgstr ""

#: of tvm.tir.generic.add:5 tvm.tir.generic.multiply:5
#: tvm.tir.generic.subtract:5 tvm.tir.op.ceildiv:5
msgid "The right operand."
msgstr ""

#: of tvm.tir.generic.add:7 tvm.tir.generic.multiply:7
#: tvm.tir.generic.subtract:7 tvm.tir.op.ceildiv:7 tvm.tir.op.div:7
#: tvm.tir.op.floordiv:7 tvm.tir.op.floormod:7 tvm.tir.op.if_then_else:9
#: tvm.tir.op.indexdiv:7 tvm.tir.op.indexmod:7 tvm.tir.op.truncdiv:7
#: tvm.tir.op.truncmod:7
msgid "The location of this operator in the source."
msgstr ""

#: of tvm.tir.generic.add:10
msgid "**op** -- The result Expr of add operaton."
msgstr ""

#: of tvm.tir.op.address_of:1
msgid "Returns the address of an element in the buffer"
msgstr ""

#: of tvm.tir.op.address_of:3
msgid "The buffer load."
msgstr ""

#: of tvm.tir.op.all:1
msgid "Create a new expression of the intersection of all conditions in the"
msgstr ""

#: of tvm.tir.op.all:2
msgid "arguments"
msgstr ""

#: of tvm.tir.op.all:4 tvm.tir.op.any:3
msgid "List of symbolic boolean expressions"
msgstr ""

#: of tvm.tir.op.all:9 tvm.tir.op.any:8
msgid "**expr** -- Expression"
msgstr ""

#: of tvm.tir.op.any:1
msgid "Create a new experssion of the union of all conditions in the arguments"
msgstr ""

#: of tvm.tir.op.asin:1
msgid "Take asin of input x."
msgstr ""

#: of tvm.tir.op.asinh:1
msgid "Take asinh of input x."
msgstr ""

#: of tvm.tir.op.assume:1
msgid "Provide a true statement that can be used for simplifications"
msgstr ""

#: of tvm.tir.op.assume:3
msgid "The constraint condition."
msgstr ""

#: of tvm.tir.op.atan:1
msgid "Take atan of input x."
msgstr ""

#: of tvm.tir.op.atan2:1
msgid "Take arctan2(x1, x2)."
msgstr ""

#: of tvm.tir.op.atanh:1
msgid "Take atanh of input x."
msgstr ""

#: of tvm.tir.data_layout.bijective_layout:1
msgid "Create a bijective layout mapping."
msgstr ""

#: of tvm.tir.data_layout.bijective_layout:8
msgid "**bijective_layout** -- The created bijective layout"
msgstr ""

#: of tvm.tir.op.bitwise_and:1
msgid "Take bitwise and of two values"
msgstr ""

#: of tvm.tir.op.bitwise_and:3 tvm.tir.op.bitwise_or:3 tvm.tir.op.bitwise_xor:3
msgid "Left operand"
msgstr ""

#: of tvm.tir.op.bitwise_and:5 tvm.tir.op.bitwise_or:5 tvm.tir.op.bitwise_xor:5
msgid "Right operand"
msgstr ""

#: of tvm.tir.op.bitwise_and:10 tvm.tir.op.bitwise_not:8
#: tvm.tir.op.bitwise_or:10 tvm.tir.op.bitwise_xor:10
msgid "**res** -- The result."
msgstr ""

#: of tvm.tir.op.bitwise_not:1
msgid "Take bitwise not of input value"
msgstr ""

#: of tvm.tir.op.bitwise_not:3
msgid "Input operand"
msgstr ""

#: of tvm.tir.op.bitwise_or:1
msgid "Take bitwise or of two values"
msgstr ""

#: of tvm.tir.op.bitwise_xor:1
msgid "Take bitwise xor of two values"
msgstr ""

#: of tvm.tir.op.call_cpacked:1 tvm.tir.op.call_packed:1
msgid "Build expression by call an external packed function."
msgstr ""

#: of tvm.tir.op.call_cpacked:3
msgid ""
"Same as call_packed, except that the first argument is the function name "
"(as in call_extern), and the last argument is the resource handle."
msgstr ""

#: of tvm.tir.op.call_cpacked:6 tvm.tir.op.call_cpacked_lowered:5
#: tvm.tir.op.call_extern:7 tvm.tir.op.call_intrin:10
#: tvm.tir.op.call_llvm_intrin:7 tvm.tir.op.call_llvm_pure_intrin:7
#: tvm.tir.op.call_packed:10 tvm.tir.op.call_packed_lowered:8
#: tvm.tir.op.call_pure_extern:7 tvm.tir.op.trace:8
msgid "Positional arguments."
msgstr ""

#: of tvm.tir.op.call_cpacked:16 tvm.tir.op.call_cpacked_lowered:15
#: tvm.tir.op.call_packed:20 tvm.tir.op.call_packed_lowered:18
msgid ":obj:`te.extern`"
msgstr ""

#: of tvm.tir.op.call_cpacked:17 tvm.tir.op.call_cpacked_lowered:16
#: tvm.tir.op.call_packed:21 tvm.tir.op.call_packed_lowered:19
msgid "Create tensor with extern function call."
msgstr ""

#: of tvm.tir.op.call_cpacked_lowered:1
msgid ""
"Lowered version of call c-packed. Same as call_packed, except that the "
"first argument is the function name (as in call_extern), and the last "
"argument is the resource handle."
msgstr ""

#: of tvm.tir.op.call_extern:1
msgid "Build expression by calling a extern function."
msgstr ""

#: of tvm.tir.op.call_extern:3 tvm.tir.op.call_intrin:6
#: tvm.tir.op.call_llvm_intrin:3 tvm.tir.op.call_llvm_pure_intrin:3
#: tvm.tir.op.call_pure_extern:3 tvm.tir.op.get_active_lane_mask:6
#: tvm.tir.op.mma_fill:3 tvm.tir.op.mma_store:3 tvm.tir.op.ptx_cp_async:4
#: tvm.tir.op.ptx_cp_async_bulk:4 tvm.tir.op.ptx_ldmatrix:4
#: tvm.tir.op.ptx_mma:4 tvm.tir.op.ptx_mma_sp:4 tvm.tir.op.vectorhigh:3
#: tvm.tir.op.vectorlow:3
msgid "The data type of the result."
msgstr ""

#: of tvm.tir.op.call_extern:5 tvm.tir.op.call_pure_extern:5
msgid "The extern function name."
msgstr ""

#: of tvm.tir.op.call_intrin:1
msgid "Build expression by calling an intrinsic function."
msgstr ""

#: of tvm.tir.op.call_intrin:3
msgid ""
"Intrinsics can be overloaded with multiple data types via the intrinsic "
"translation rule."
msgstr ""

#: of tvm.tir.op.call_intrin:8
msgid "The intrinsic function name."
msgstr ""

#: of tvm.tir.op.call_llvm_intrin:1
msgid "Build expression by calling a llvm intrinsic function"
msgstr ""

#: of tvm.tir.op.call_llvm_intrin:5 tvm.tir.op.call_llvm_pure_intrin:5
msgid "The name of the llvm intrinsic function."
msgstr ""

#: of tvm.tir.op.call_llvm_pure_intrin:1
msgid "Build expression by calling a pure llvm intrinsic function"
msgstr ""

#: of tvm.tir.op.call_packed:3
msgid ""
"The argument to packed function can be Expr or Buffer. The argument is "
"the corresponding POD type when Expr is presented."
msgstr ""

#: of tvm.tir.op.call_packed:6
msgid ""
"When the argument is Buffer, the corresponding PackedFunc will receive an"
" TVMArrayHandle whose content is valid during the callback period. If the"
" PackedFunc is a python callback, then the corresponding argument is "
"NDArray."
msgstr ""

#: of tvm.tir.op.call_packed_lowered:1
msgid ""
"Lowered version of call packed. The argument to packed function can be "
"Expr or Buffer. The argument is the corresponding POD type when Expr is "
"presented. When the argument is Buffer, the corresponding PackedFunc will"
" recieve an TVMArrayHandle whose content is valid during the callback "
"period. If the PackedFunc is a python callback, then the corresponding "
"argument is NDArray."
msgstr ""

#: of tvm.tir.op.call_pure_extern:1
msgid "Build expression by calling a pure extern function."
msgstr ""

#: of tvm.tir.op.call_tir:1
msgid "Performs a call into another PrimFunc in the same IRModule"
msgstr ""

#: of tvm.tir.op.ceil:1
msgid "Take ceil of float input x."
msgstr ""

#: of tvm.tir.op.ceildiv:1
msgid "Generic ceildiv operator."
msgstr ""

#: of tvm.tir.op.ceildiv:10
msgid "**op** -- The result Expr of ceildiv operaton."
msgstr ""

#: of tvm.tir.op.clz:1
msgid "Count leading zero bits of an integer x."
msgstr ""

#: of tvm.tir.op.clz:3
msgid "Input 32 or 64 bit integer. The result is undefined if the input is 0."
msgstr ""

#: of tvm.tir.op.comm_reducer:1
msgid "Create a commutative reducer for reduction."
msgstr ""

#: of tvm.tir.op.comm_reducer:3
msgid "A binary function which takes two Expr as input to return a Expr."
msgstr ""

#: of tvm.tir.op.comm_reducer:5
msgid "A function which takes a type string as input to return a const Expr."
msgstr ""

#: of tvm.tir.op.comm_reducer:8
msgid ""
"**reducer** -- A function which creates a reduce expression over axis. "
"There are two ways to use it:  1. accept (expr, axis, where) to produce "
"an Reduce Expr on    specified axis; 2. simply use it with multiple "
"Exprs."
msgstr ""

#: of tvm.tir.op.comm_reducer:8
msgid ""
"**reducer** -- A function which creates a reduce expression over axis. "
"There are two ways to use it:"
msgstr ""

#: of tvm.tir.op.comm_reducer:11
msgid "accept (expr, axis, where) to produce an Reduce Expr on specified axis;"
msgstr ""

#: of tvm.tir.op.comm_reducer:13
msgid "simply use it with multiple Exprs."
msgstr ""

#: of tvm.tir.op.copysign:1
msgid "Change the sign of x1 to that of x2, element-wise."
msgstr ""

#: of tvm.tir.op.cos:1
msgid "Take cos of input x."
msgstr ""

#: of tvm.tir.op.cosh:1
msgid "Take cosh of input x."
msgstr ""

#: of tvm.tir.op.create_barriers:1
msgid "TVM intrinsic to create N barriers"
msgstr ""

#: of tvm.tir.op.create_barriers:3
msgid "The number of barriers to create."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:1
msgid "Declare a new symbolic buffer."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:3
msgid ""
"Normally buffer is created automatically during lower and build. This is "
"only needed if user want to specify their own buffer layout."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:6
msgid "See the note below for detailed discussion on usage of buffer."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:8
msgid "The shape of the buffer."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:12
msgid "The name of the buffer."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:14
msgid "The data pointer in the buffer."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:16
msgid "The stride of the buffer."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:18
msgid ""
"The beginning offset of the array to data. In terms of number of elements"
" of dtype."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:21
msgid ""
"The storage scope of the buffer, if not global. If scope equals empty "
"string, it means it is global memory."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:24
msgid ""
"The alignment of data pointer in bytes. If -1 is passed, the alignment "
"will be set to TVM's internal default."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:27
msgid ""
"The factor of elem_offset field, when set, elem_offset is required to be "
"multiple of offset_factor. If 0 is pssed, the alignment will be set to 1."
" if non-zero is passed, we will created a Var for elem_offset if "
"elem_offset is not None."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:32
msgid ""
"auto_broadcast buffer allows one to implement broadcast computation "
"without considering whether dimension size equals to one. TVM maps "
"buffer[i][j][k] -> buffer[i][0][k] if dimension j's shape equals 1."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:36
msgid ""
"If passed, a list of separators between groups of axes, each of which is "
"flattened to an output axis.  For flat memory spaces, should either be "
"None, or an empty list."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:40
msgid "The location of the decl_buffer creation in the source."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:43
msgid "**buffer** -- The created buffer"
msgstr ""

#: of tvm.tir.buffer.decl_buffer:48
msgid ""
"Here's an example of how broadcast buffer can be used to define a "
"symbolic broadcast operation,"
msgstr ""

#: of tvm.tir.buffer.decl_buffer:71
msgid ""
"Buffer data structure reflects the DLTensor structure in dlpack. While "
"DLTensor data structure is very general, it is usually helpful to create "
"function that only handles specific case of data structure and make "
"compiled function benefit from it."
msgstr ""

#: of tvm.tir.buffer.decl_buffer:76
msgid ""
"If user pass strides and elem_offset is passed as None when constructing "
"the function, then the function will be specialized for the DLTensor that"
" is compact and aligned. If user pass a fully generic symbolic array to "
"the strides, then the resulting function becomes fully generic."
msgstr ""

#: of tvm.tir.op.div:1
msgid "Compute a / b as in C/C++ semantics."
msgstr ""

#: of tvm.tir.op.div:3 tvm.tir.op.indexdiv:3 tvm.tir.op.indexmod:3
msgid "The left hand operand, known to be non-negative."
msgstr ""

#: of tvm.tir.op.div:5 tvm.tir.op.indexdiv:5 tvm.tir.op.indexmod:5
msgid "The right hand operand, known to be non-negative."
msgstr ""

#: of tvm.tir.op.div:10 tvm.tir.op.floordiv:10 tvm.tir.op.floormod:10
#: tvm.tir.op.indexdiv:10 tvm.tir.op.indexmod:10 tvm.tir.op.truncdiv:10
#: tvm.tir.op.truncmod:10
msgid "**res** -- The result expression."
msgstr ""

#: of tvm.tir.op.div:13
msgid "When operands are integers, returns truncdiv(a, b, span)."
msgstr ""

#: of tvm.tir.op.dp4a:1
msgid "Dot product of two int8x4 vectors and add an optional accumulator"
msgstr ""

#: of tvm.tir.op.dp4a:3 tvm.tir.op.dp4a:5 tvm.tir.op.vectorcombine:3
#: tvm.tir.op.vectorcombine:5 tvm.tir.op.vectorhigh:5 tvm.tir.op.vectorlow:5
msgid "The input vector."
msgstr ""

#: of tvm.tir.op.dp4a:7
msgid "The accumulator."
msgstr ""

#: of tvm.tir.op.end_profile_intrinsic:1
msgid "End profile intrinsic. :param id: The intrinsic id. :type id: int"
msgstr ""

#: of tvm.tir.op.erf:1
msgid "Take gauss error function of the input x."
msgstr ""

#: of tvm.tir.op.exp:1
msgid "Take exponential of input x."
msgstr ""

#: of tvm.tir.op.exp10:1
msgid "Calculate 10**x"
msgstr ""

#: of tvm.tir.op.exp2:1
msgid "Calculate 2**x"
msgstr ""

#: of tvm.tir.op.floor:1
msgid "Take floor of float input x."
msgstr ""

#: of tvm.tir.op.floordiv:1
msgid "Compute the floordiv of two expressions."
msgstr ""

#: of tvm.tir.op.floordiv:3 tvm.tir.op.floormod:3 tvm.tir.op.truncdiv:3
#: tvm.tir.op.truncmod:3
msgid "The left hand operand"
msgstr ""

#: of tvm.tir.op.floordiv:5 tvm.tir.op.floormod:5 tvm.tir.op.truncdiv:5
#: tvm.tir.op.truncmod:5
msgid "The right hand operand"
msgstr ""

#: of tvm.tir.op.floormod:1
msgid "Compute the floormod of two expressions."
msgstr ""

#: of tvm.tir.op.fmod:1
msgid "Return the remainder of x divided by y with the same sign as x."
msgstr ""

#: of tvm.tir.op.fmod:8 tvm.tir.op.pow:10 tvm.tir.op.power:10
#: tvm.tir.op.q_multiply_shift_per_axis:18 tvm.tir.op.shift_left:8
#: tvm.tir.op.shift_right:8
msgid "**z** -- The result."
msgstr ""

#: of tvm.tir.op.get_active_lane_mask:1
msgid ""
"Calculate a predicate mask given an upper bound (limit) and a current "
"value (base)."
msgstr ""

#: of tvm.tir.op.get_active_lane_mask:3
msgid ""
"It will be lowered to the llvm.get.active.lane.mask intrinsic. "
"(https://llvm.org/docs/LangRef.html#llvm-get-active-lane-mask-intrinsics)"
msgstr ""

#: of tvm.tir.op.get_active_lane_mask:8
msgid "An expression reprsenting the base."
msgstr ""

#: of tvm.tir.op.get_active_lane_mask:10
msgid "An expression representing the limit."
msgstr ""

#: of tvm.tir.op.get_vscale_expr:1
msgid "Create a datatype dependent scalable expression."
msgstr ""

#: of tvm.tir.op.get_vscale_expr:3
msgid "Element data type."
msgstr ""

#: of tvm.tir.op.get_vscale_expr:5
msgid "The minimum size of the scalable vector in bits."
msgstr ""

#: of tvm.tir.op.hypot:1
msgid "Equivalent to sqrt(x1**2 + x2**2), element-wise."
msgstr ""

#: of tvm.tir.op.if_then_else:1
msgid "Conditional selection expression."
msgstr ""

#: of tvm.tir.op.if_then_else:3
msgid "The condition"
msgstr ""

#: of tvm.tir.op.if_then_else:5
msgid "The result expression if cond is true."
msgstr ""

#: of tvm.tir.op.if_then_else:7
msgid "The result expression if cond is false."
msgstr ""

#: of tvm.tir.op.if_then_else:12
msgid "**result** -- The result of conditional expression."
msgstr ""

#: of tvm.tir.op.if_then_else:17
msgid ""
"Unlike Select, if_then_else will not execute the branch that does not "
"satisfy the condition. You can use it to guard against out of bound "
"access. Unlike Select, if_then_else cannot be vectorized if some lanes in"
" the vector have different conditions."
msgstr ""

#: of tvm.tir.op.ignore_loop_partition:1
msgid ""
"Annotate a predicate not be considered as target condition of loop "
"partition."
msgstr ""

#: of tvm.tir.op.ignore_loop_partition:3
msgid "The annotated predicate expression."
msgstr ""

#: of tvm.tir.op.indexdiv:1
msgid "Compute floor(a / b) where a and b are non-negative."
msgstr ""

#: of tvm.tir.op.indexdiv:15 tvm.tir.op.indexmod:15
msgid ""
"Use this function to split non-negative indices. This function may take "
"advantage of operands' non-negativeness."
msgstr ""

#: of tvm.tir.op.indexmod:1
msgid "Compute the remainder of indexdiv. a and b are non-negative."
msgstr ""

#: of tvm.tir.op.infinity:1 tvm.tir.op.reinterpret:1
msgid "infinity value of dtype"
msgstr ""

#: of tvm.tir.op.infinity:3 tvm.tir.op.max_value:3 tvm.tir.op.min_value:3
#: tvm.tir.op.reinterpret:3 tvm.tir.op.type_annotation:3
msgid "The data type."
msgstr ""

#: of tvm.tir.op.infinity:8
msgid "**value** -- The infinity value of dtype."
msgstr ""

#: of tvm.tir.op.isfinite:1
msgid "Check if input value is finite."
msgstr ""

#: of tvm.tir.op.isinf:1
msgid "Check if input value is infinite."
msgstr ""

#: of tvm.tir.op.isnan:1
msgid "Check if input value is Nan."
msgstr ""

#: of tvm.tir.op.isnullptr:1
msgid "Check if input value is nullptr."
msgstr ""

#: of tvm.tir.data_layout.layout:1
msgid "Create a layout node from a string."
msgstr ""

#: of tvm.tir.data_layout.layout:3
msgid ""
"A layout representation is composed of upper cases, lower cases and "
"numbers, where upper case indicates a primal axis and the corresponding "
"lower case with factor size indicates the subordinate axis. For example, "
"NCHW16c can describe a 5-D tensor of [batch_size, channel, height, width,"
" channel_block]. Here subordinate axis channel_block=16 is the factor "
"size of the primal axis C (channel)."
msgstr ""

#: of tvm.tir.data_layout.layout:11
msgid ""
"The dtype of generated axes vars in the returned layout. It is required "
"to be integer type."
msgstr ""

#: of tvm.tir.data_layout.layout:15
msgid "**layout** -- The created layout"
msgstr ""

#: of tvm.tir.op.ldexp:1
msgid "Returns x1 * (2 ** x2)."
msgstr ""

#: of tvm.tir.op.likely:1
msgid "Mark condition as likely."
msgstr ""

#: of tvm.tir.op.likely:8
msgid "**y** -- The marked expression."
msgstr ""

#: of tvm.tir.op.log:1
msgid "Take log of input x."
msgstr ""

#: of tvm.tir.op.log10:1
msgid "Take log10 of input x."
msgstr ""

#: of tvm.tir.op.log1p:1
msgid "Take log(x + 1) with respect to input x."
msgstr ""

#: of tvm.tir.op.log2:1
msgid "Take log2 of input x."
msgstr ""

#: of tvm.tir.op.lookup_param:1
msgid "Returns the param by name"
msgstr ""

#: of tvm.tir.op.lookup_param:3
msgid "The name of param."
msgstr ""

#: of tvm.tir.op.make_filled_simdgroup_matrix:1
msgid "Create a filled SIMDGroup matrix"
msgstr ""

#: of tvm.tir.op.make_filled_simdgroup_matrix:3 tvm.tir.op.simdgroup_load:3
msgid "The simdgroup var"
msgstr ""

#: of tvm.tir.op.make_filled_simdgroup_matrix:5 tvm.tir.op.simdgroup_load:5
#: tvm.tir.op.simdgroup_store:5
msgid "The index of the matrix."
msgstr ""

#: of tvm.tir.op.make_filled_simdgroup_matrix:7
msgid "The value to fill."
msgstr ""

#: of tvm.tir.op.make_filled_simdgroup_matrix:9 tvm.tir.op.simdgroup_load:11
#: tvm.tir.op.simdgroup_store:11
msgid "The number of columns."
msgstr ""

#: of tvm.tir.op.make_filled_simdgroup_matrix:11 tvm.tir.op.simdgroup_load:13
#: tvm.tir.op.simdgroup_store:13
msgid "The number of rows."
msgstr ""

#: of tvm.tir.op.comm_reducer.<locals>.reducer:1
msgid "Create a max expression over axis."
msgstr ""

#: of tvm.tir.op.comm_reducer.<locals>.reducer:5
msgid "The reduction IterVar axis"
msgstr ""

#: of tvm.tir.op.comm_reducer.<locals>.reducer:7
msgid "Filtering predicate of the reduction."
msgstr ""

#: of tvm.tir.op.comm_reducer.<locals>.reducer:10
msgid "**value** -- The result value."
msgstr ""

#: of tvm.tir.op.max_value:1
msgid "maximum value of dtype"
msgstr ""

#: of tvm.tir.op.max_value:8
msgid "**value** -- The maximum value of dtype."
msgstr ""

#: of tvm.tir.op.comm_reducer.<locals>.reducer:1
msgid "Create a min expression over axis."
msgstr ""

#: of tvm.tir.op.min_value:1
msgid "minimum value of dtype"
msgstr ""

#: of tvm.tir.op.min_value:8
msgid "**value** -- The minimum value of dtype."
msgstr ""

#: of tvm.tir.op.mma_fill:1
msgid "TVM intrinsic for zero-initalizing an MMA accumulation registor"
msgstr ""

#: of tvm.tir.op.mma_fill:5
msgid "The number of elements."
msgstr ""

#: of tvm.tir.op.mma_fill:7 tvm.tir.op.mma_store:9
msgid "The destination pointer variable."
msgstr ""

#: of tvm.tir.op.mma_fill:9
msgid "The destination offset."
msgstr ""

#: of tvm.tir.op.mma_store:1
msgid "TVM intrinsic for storing the result of PTX MMA into a destination pointer"
msgstr ""

#: of tvm.tir.op.mma_store:5 tvm.tir.op.mma_store:7 tvm.tir.op.ptx_mma:6
#: tvm.tir.op.ptx_mma_sp:6
msgid "The shape of mma fragment."
msgstr ""

#: of tvm.tir.op.mma_store:11
msgid "The source pointer variable."
msgstr ""

#: of tvm.tir.op.mma_store:13
msgid "The source offset."
msgstr ""

#: of tvm.tir.op.mma_store:15
msgid "The destination stride."
msgstr ""

#: of tvm.tir.generic.multiply:1
msgid "Generic multiply operator."
msgstr ""

#: of tvm.tir.generic.multiply:10
msgid "**op** -- The result Expr of multiply operaton."
msgstr ""

#: of tvm.tir.op.nearbyint:1
msgid ""
"Round elements of the array to the nearest integer. This intrinsic uses "
"llvm.nearbyint instead of llvm.round which is faster but will results "
"different from te.round. Notably nearbyint rounds according to the "
"rounding mode, whereas te.round (llvm.round) ignores that. For "
"differences between the two see: "
"https://en.cppreference.com/w/cpp/numeric/math/round "
"https://en.cppreference.com/w/cpp/numeric/math/nearbyint"
msgstr ""

#: of tvm.tir.op.nextafter:1
msgid "Return the next floating-point value after x1 towards x2."
msgstr ""

#: of tvm.tir.op.popcount:1
msgid "Count the number of set bits in input x."
msgstr ""

#: of tvm.tir.op.pow:1 tvm.tir.op.power:1
msgid "x power y"
msgstr ""

#: of tvm.tir.op.pow:5 tvm.tir.op.power:5
msgid "The exponent"
msgstr ""

#: of tvm.tir.op.ptx_arrive_barrier:1
msgid ""
"TVM intrinsic for ptx barrier arrival using mbarrier.arrive "
"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html"
"#parallel-synchronization-and-communication-instructions-mbarrier-arrive"
msgstr ""

#: of tvm.tir.op.ptx_arrive_barrier:4 tvm.tir.op.ptx_arrive_barrier_expect_tx:5
#: tvm.tir.op.ptx_cp_async_barrier:4 tvm.tir.op.ptx_cp_async_bulk:16
#: tvm.tir.op.ptx_init_barrier_thread_count:4 tvm.tir.op.ptx_wait_barrier:4
msgid "The ID of the barrier shared memory pointer."
msgstr ""

#: of tvm.tir.op.ptx_arrive_barrier_expect_tx:1
msgid ""
"TVM intrinsic for ptx barrier arrival with expect tx using "
"mbarrier.arrive.expect_tx https://docs.nvidia.com/cuda/parallel-thread-"
"execution/index.html#parallel-synchronization-and-communication-"
"instructions-mbarrier-arrive https://docs.nvidia.com/cuda/parallel-"
"thread-execution/index.html#parallel-synchronization-and-communication-"
"instructions-mbarrier-expect-tx-operation"
msgstr ""

#: of tvm.tir.op.ptx_arrive_barrier_expect_tx:7
msgid ""
"Increases the tx count of the mbarrier object to track completion of "
"addtional async transactions."
msgstr ""

#: of tvm.tir.op.ptx_commit_group:1
msgid ""
"TVM intrinsic for ptx async copy commit https://docs.nvidia.com/cuda"
"/parallel-thread-execution/index.html#data-movement-and-conversion-"
"instructions-cp-async-commit-group"
msgstr ""

#: of tvm.tir.op.ptx_cp_async:1
msgid ""
"TVM intrinsic for ptx async copy from global to shared memory using "
"cp.async https://docs.nvidia.com/cuda/parallel-thread-"
"execution/index.html#data-movement-and-conversion-instructions-cp-async"
msgstr ""

#: of tvm.tir.op.ptx_cp_async:6 tvm.tir.op.ptx_cp_async_bulk:6
#: tvm.tir.op.ptx_ldmatrix:16
msgid "The shared memory pointer variable."
msgstr ""

#: of tvm.tir.op.ptx_cp_async:8 tvm.tir.op.ptx_cp_async_bulk:8
msgid "The offset of shared memory pointer."
msgstr ""

#: of tvm.tir.op.ptx_cp_async:10 tvm.tir.op.ptx_cp_async_bulk:10
msgid "The global memory pointer variable."
msgstr ""

#: of tvm.tir.op.ptx_cp_async:12 tvm.tir.op.ptx_cp_async_bulk:12
msgid "The offset of global memory pointer."
msgstr ""

#: of tvm.tir.op.ptx_cp_async:14 tvm.tir.op.ptx_cp_async_bulk:14
msgid "The data size to copy."
msgstr ""

#: of tvm.tir.op.ptx_cp_async_barrier:1
msgid ""
"TVM intrinsic for ptx async copy barrier using cp.async.mbarrier.arrive "
"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html"
"#parallel-synchronization-and-communication-instructions-cp-async-"
"mbarrier-arrive"
msgstr ""

#: of tvm.tir.op.ptx_cp_async_bulk:1
msgid ""
"TVM intrinsic for ptx async copy from global to shared memory using "
"cp.async.bulk https://docs.nvidia.com/cuda/parallel-thread-"
"execution/index.html#data-movement-and-conversion-instructions-cp-async-"
"bulk"
msgstr ""

#: of tvm.tir.op.ptx_init_barrier_thread_count:1
msgid ""
"TVM intrinsic for ptx barrier initialization of thread count using "
"mbarrier.init https://docs.nvidia.com/cuda/parallel-thread-"
"execution/index.html#parallel-synchronization-and-communication-"
"instructions-mbarrier-init"
msgstr ""

#: of tvm.tir.op.ptx_init_barrier_thread_count:6
msgid "Number of threads expected to arrive at the barrier."
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:1
msgid ""
"TVM intrinsic for ptx load matrix from shared memory "
"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-"
"level-matrix-instructions-ldmatrix"
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:6
msgid "The matrix is loaded in column-major format."
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:8
msgid "The number of matrices."
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:10
msgid "The data type of the matrices."
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:12
msgid "The local pointer variable."
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:14
msgid "The offset of local pointer."
msgstr ""

#: of tvm.tir.op.ptx_ldmatrix:18
msgid "The offset of shared memort pointer."
msgstr ""

#: of tvm.tir.op.ptx_mma:1
msgid ""
"TVM intrinsic for ptx tensor core mma instructions "
"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-"
"level-matrix-instructions-for-mma"
msgstr ""

#: of tvm.tir.op.ptx_mma:8 tvm.tir.op.ptx_mma_sp:8
msgid "The layout of multiplicand fragment A."
msgstr ""

#: of tvm.tir.op.ptx_mma:10 tvm.tir.op.ptx_mma_sp:10
msgid "The layout of multiplicand fragment B."
msgstr ""

#: of tvm.tir.op.ptx_mma:12 tvm.tir.op.ptx_mma_sp:12
msgid "The data type of multiplicand fragment A."
msgstr ""

#: of tvm.tir.op.ptx_mma:14 tvm.tir.op.ptx_mma_sp:14
msgid "The data type of multiplicand fragment B."
msgstr ""

#: of tvm.tir.op.ptx_mma:16
msgid "The data type of accumulator fragment C."
msgstr ""

#: of tvm.tir.op.ptx_mma:18 tvm.tir.op.ptx_mma_sp:18
msgid "The multiplicand fragment A variable."
msgstr ""

#: of tvm.tir.op.ptx_mma:20 tvm.tir.op.ptx_mma:24 tvm.tir.op.ptx_mma_sp:20
msgid "The index of multiplicand fragment A."
msgstr ""

#: of tvm.tir.op.ptx_mma:22 tvm.tir.op.ptx_mma_sp:22
msgid "The multiplicand fragment B variable."
msgstr ""

#: of tvm.tir.op.ptx_mma:26 tvm.tir.op.ptx_mma_sp:26
msgid "The accumulator fragment C variable."
msgstr ""

#: of tvm.tir.op.ptx_mma:28 tvm.tir.op.ptx_mma_sp:28
msgid "The index of accumulator fragment C."
msgstr ""

#: of tvm.tir.op.ptx_mma:30 tvm.tir.op.ptx_mma_sp:36
msgid "The optional saturation at the output."
msgstr ""

#: of tvm.tir.op.ptx_mma:32
msgid "The 1-bit operator."
msgstr ""

#: of tvm.tir.op.ptx_mma_sp:1
msgid ""
"TVM intrinsic for sparse tensor core ptx instructions "
"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-"
"level-matrix-instructions-for-sparse-mma"
msgstr ""

#: of tvm.tir.op.ptx_mma_sp:16
msgid "The data type of multiplicand fragment C."
msgstr ""

#: of tvm.tir.op.ptx_mma_sp:24
msgid "The index of multiplicand fragment B."
msgstr ""

#: of tvm.tir.op.ptx_mma_sp:30
msgid "The metadata of operand."
msgstr ""

#: of tvm.tir.op.ptx_mma_sp:32
msgid "The metadata index of operand."
msgstr ""

#: of tvm.tir.op.ptx_mma_sp:34
msgid "The sparse selector indicating the thread that stores the metadata."
msgstr ""

#: of tvm.tir.op.ptx_wait_barrier:1
msgid ""
"TVM intrinsic for ptx barrier wait using mbarrier.try_wait "
"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html"
"#parallel-synchronization-and-communication-instructions-mbarrier-test-"
"wait-mbarrier-try-wait"
msgstr ""

#: of tvm.tir.op.ptx_wait_group:1
msgid ""
"TVM intrinsic for ptx async copy wait https://docs.nvidia.com/cuda"
"/parallel-thread-execution/index.html#data-movement-and-conversion-"
"instructions-cp-async-wait-group"
msgstr ""

#: of tvm.tir.op.ptx_wait_group:4
msgid "The number of the most recent uncommitted pending cp.async groups to wait."
msgstr ""

#: of tvm.tir.op.q_multiply_shift:1
msgid ""
"Execute a multiplication between two Q-numbers x and y followed by a "
"right shift s. The mathematical expression is:"
msgstr ""

#: of tvm.tir.op.q_multiply_shift:4
msgid "out = round(x*y*2^-s)"
msgstr ""

#: of tvm.tir.op.q_multiply_shift:6
msgid ""
"More about Q-numbers here: "
"https://en.wikipedia.org/wiki/Q_(number_format) The rounding rule is to "
"the nearest value, rounding half up (i.e., round(x.1) = x and round (x.5)"
" = x+1)"
msgstr ""

#: of tvm.tir.op.q_multiply_shift:10
msgid "First Q-number"
msgstr ""

#: of tvm.tir.op.q_multiply_shift:12
msgid "Second Q-number"
msgstr ""

#: of tvm.tir.op.q_multiply_shift:14
msgid "Number of fractional bits in x and y. Needs to be > 0"
msgstr ""

#: of tvm.tir.op.q_multiply_shift:16
msgid "Integer shift"
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:1
msgid "Execute a multiplication between two Q-numbers x and y"
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:3
msgid "First Q-number."
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:5
msgid "Second Q-number."
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:7
msgid "Integer left shift."
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:9
msgid "Integer right shift."
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:11
msgid "Number of fractional bits in x and y. Needs to be > 0."
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:13
msgid "Whether we need to do left shift or not."
msgstr ""

#: of tvm.tir.op.q_multiply_shift_per_axis:15
msgid "Whether we need to do right shift or not."
msgstr ""

#: of tvm.tir.op.reinterpret:5
msgid "The input value."
msgstr ""

#: of tvm.tir.op.reinterpret:10
msgid "**value** -- The reinterpret cast value of dtype."
msgstr ""

#: of tvm.tir.op.ret:1
msgid "Create a tir return expression"
msgstr ""

#: of tvm.tir.op.ret:3
msgid ""
"The returned tir expression, whose data type is int, float or void "
"pointer."
msgstr ""

#: of tvm.tir.op.ret:8 tvm.tir.op.tvm_throw_last_error:3
msgid "**ret** -- The return expression"
msgstr ""

#: of tvm.tir.op.round:1
msgid "Round elements of the array to the nearest integer."
msgstr ""

#: of tvm.tir.op.rsqrt:1
msgid "Take reciprocal of square root of input x."
msgstr ""

#: of tvm.tir.op.shift_left:1
msgid "Return the result of x left shifted by y bits."
msgstr ""

#: of tvm.tir.op.shift_right:1
msgid "Return the result of x right shifted by y bits."
msgstr ""

#: of tvm.tir.op.sigmoid:1
msgid "Quick function to get sigmoid"
msgstr ""

#: of tvm.tir.op.simdgroup_load:1
msgid "Load data from device memory or threadgroup memory to simdgroup"
msgstr ""

#: of tvm.tir.op.simdgroup_load:7 tvm.tir.op.simdgroup_store:7
msgid "The pointer."
msgstr ""

#: of tvm.tir.op.simdgroup_load:9 tvm.tir.op.simdgroup_store:9
msgid "The stride."
msgstr ""

#: of tvm.tir.op.simdgroup_load:15 tvm.tir.op.simdgroup_store:17
msgid "Whether to transpose the matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:1
msgid "Multiply and accumulate two matrices in simdgroup i.e. d = a * b + c"
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:4
msgid "The destination matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:6
msgid "The index of the destination matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:8
msgid "The first matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:10
msgid "The index of the first matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:12
msgid "The second matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:14
msgid "The index of the second matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:16
msgid "The third matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_multiply_accumulate:18
msgid "The index of the third matrix."
msgstr ""

#: of tvm.tir.op.simdgroup_store:1
msgid "Store data from simdgroup to device memory or threadgroup memory"
msgstr ""

#: of tvm.tir.op.simdgroup_store:3
msgid "The SIMDGroup."
msgstr ""

#: of tvm.tir.op.simdgroup_store:16
msgid "transpose_matrix"
msgstr ""

#: of tvm.tir.op.simdgroup_store:-1
msgid "bool"
msgstr ""

#: of tvm.tir.op.sin:1
msgid "Take sin of input x."
msgstr ""

#: of tvm.tir.op.sinh:1
msgid "Take sinh of input x."
msgstr ""

#: of tvm.tir.op.sqrt:1
msgid "Take square root of input x."
msgstr ""

#: of tvm.tir.op.start_profile_intrinsic:1
msgid "Start profile intrinsic. :param id: The intrinsic id. :type id: int"
msgstr ""

#: of tvm.tir.stmt.stmt_list:1
msgid "Make list of stmt from blocks."
msgstr ""

#: of tvm.tir.stmt.stmt_list:3
msgid "The input statement."
msgstr ""

#: of tvm.tir.stmt.stmt_list:6
msgid "**stmt_list** -- The unpacked list of statements"
msgstr ""

#: of tvm.tir.stmt.stmt_seq:1
msgid "Make sequence of statements"
msgstr ""

#: of tvm.tir.stmt.stmt_seq:3
msgid "List of statements to be combined as sequence."
msgstr ""

#: of tvm.tir.stmt.stmt_seq:6
msgid "**stmt** -- The combined statement."
msgstr ""

#: of tvm.tir.generic.subtract:1
msgid "Generic subtract operator."
msgstr ""

#: of tvm.tir.generic.subtract:10
msgid "**op** -- The result Expr of subtract operaton."
msgstr ""

#: of tvm.tir.op.comm_reducer.<locals>.reducer:1
msgid "Create a sum expression over axis."
msgstr ""

#: of tvm.tir.op.tan:1
msgid "Take tan of input x."
msgstr ""

#: of tvm.tir.op.tanh:1
msgid "Take hyperbolic tanh of input x."
msgstr ""

#: of tvm.tir.op.trace:1
msgid "Trace tensor data at the runtime."
msgstr ""

#: of tvm.tir.op.trace:3
msgid ""
"The trace function allows to trace specific tensor at the runtime. The "
"tracing value should come as last argument. The trace action should be "
"specified, by default tvm.default_trace_action is used."
msgstr ""

#: of tvm.tir.op.trace:10
msgid "The name of the trace action."
msgstr ""

#: of tvm.tir.op.trace:18
msgid ":obj:`tvm.tir.call_packed`"
msgstr ""

#: of tvm.tir.op.trace:19
msgid "Creates packed function."
msgstr ""

#: of tvm.tir.op.trunc:1
msgid "Get truncated value of the input."
msgstr ""

#: of tvm.tir.op.trunc:3
msgid ""
"The truncated value of the scalar x is the nearest integer i which is "
"closer to zero than x is."
msgstr ""

#: of tvm.tir.op.truncdiv:1
msgid "Compute the truncdiv of two expressions."
msgstr ""

#: of tvm.tir.op.truncdiv:13 tvm.tir.op.truncmod:13
msgid "This is the default integer division behavior in C."
msgstr ""

#: of tvm.tir.op.truncmod:1
msgid "Compute the truncmod of two expressions."
msgstr ""

#: of tvm.tir.op.tvm_access_ptr:1
msgid "Get head access address with memory access pattern info"
msgstr ""

#: of tvm.tir.op.tvm_access_ptr:3
msgid "The data type of pointer."
msgstr ""

#: of tvm.tir.op.tvm_access_ptr:5
msgid "The data of pointer."
msgstr ""

#: of tvm.tir.op.tvm_access_ptr:7
msgid "The offset of pointer."
msgstr ""

#: of tvm.tir.op.tvm_access_ptr:11
msgid "The read write mask."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:1
msgid "TVM intrinsic for tensor core bmma_sync operators"
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:3
msgid "The bwmma fragment_d."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:5 tvm.tir.op.tvm_mma_sync:5
msgid "The fragment_d index."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:7
msgid "The bwmma fragment_a."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:9 tvm.tir.op.tvm_mma_sync:9
msgid "The fragment_a index."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:11
msgid "The bwmma fragment_b."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:13 tvm.tir.op.tvm_mma_sync:13
msgid "The fragment_b index."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:15
msgid "The bwmma fragment_c."
msgstr ""

#: of tvm.tir.op.tvm_bmma_sync:17 tvm.tir.op.tvm_mma_sync:17
msgid "The fragment_c index."
msgstr ""

#: of tvm.tir.op.tvm_check_return:1
msgid ""
"Return new on stack dtype[num] :param expected: The expected return code."
" :type expected: int :param return_unexpected: The unexpected return "
"code. :type return_unexpected: int :param nested_call: The call "
"expression to check return. :type nested_call: PrimExpr"
msgstr ""

#: of tvm.tir.op.tvm_fill_fragment:1
msgid "TVM intrinsic for tensor core fill_fragment operators"
msgstr ""

#: of tvm.tir.op.tvm_fill_fragment:3
msgid "The wmma fragment"
msgstr ""

#: of tvm.tir.op.tvm_fill_fragment:5 tvm.tir.op.tvm_fill_fragment:7
#: tvm.tir.op.tvm_fill_fragment:9 tvm.tir.op.tvm_load_matrix_sync:5
#: tvm.tir.op.tvm_load_matrix_sync:7 tvm.tir.op.tvm_load_matrix_sync:9
#: tvm.tir.op.tvm_store_matrix_sync:5 tvm.tir.op.tvm_store_matrix_sync:7
#: tvm.tir.op.tvm_store_matrix_sync:9
msgid "The shape of wmma fragment."
msgstr ""

#: of tvm.tir.op.tvm_fill_fragment:11 tvm.tir.op.tvm_load_matrix_sync:11
#: tvm.tir.op.tvm_store_matrix_sync:11
msgid "The fragment index."
msgstr ""

#: of tvm.tir.op.tvm_fill_fragment:13
msgid "The value to be filled in fragment."
msgstr ""

#: of tvm.tir.op.tvm_load_matrix_sync:1
msgid "TVM intrinsic for tensor core load operators"
msgstr ""

#: of tvm.tir.op.tvm_load_matrix_sync:3 tvm.tir.op.tvm_store_matrix_sync:3
msgid "The wmma fragment."
msgstr ""

#: of tvm.tir.op.tvm_load_matrix_sync:13 tvm.tir.op.tvm_store_matrix_sync:13
msgid "The fragment buffer pointer."
msgstr ""

#: of tvm.tir.op.tvm_load_matrix_sync:15 tvm.tir.op.tvm_store_matrix_sync:15
msgid "The fragment stride."
msgstr ""

#: of tvm.tir.op.tvm_load_matrix_sync:17 tvm.tir.op.tvm_store_matrix_sync:17
msgid "The fragment layout."
msgstr ""

#: of tvm.tir.op.tvm_mma_sync:1
msgid "TVM intrinsic for tensor core mma_sync operators"
msgstr ""

#: of tvm.tir.op.tvm_mma_sync:3
msgid "The wmma fragment_d."
msgstr ""

#: of tvm.tir.op.tvm_mma_sync:7
msgid "The wmma fragment_a."
msgstr ""

#: of tvm.tir.op.tvm_mma_sync:11
msgid "The wmma fragment_b."
msgstr ""

#: of tvm.tir.op.tvm_mma_sync:15
msgid "The wmma fragment_c."
msgstr ""

#: of tvm.tir.op.tvm_stack_alloca:1
msgid "Return new on stack dtype[num]"
msgstr ""

#: of tvm.tir.op.tvm_stack_alloca:3 tvm.tir.op.tvm_stack_make_array:11
msgid "The data type of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_alloca:5
msgid "The size of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_make_array:1
msgid "Allocate a NDArray(DLTensor) on stack, return the handle"
msgstr ""

#: of tvm.tir.op.tvm_stack_make_array:3
msgid "The data of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_make_array:5
msgid "The shape of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_make_array:7
msgid "The strides of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_make_array:9
msgid "The dimensions of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_make_array:13
msgid "The element offset of array."
msgstr ""

#: of tvm.tir.op.tvm_stack_make_shape:1
msgid "Allocate a shape tuple on stack, return the handle"
msgstr ""

#: of tvm.tir.op.tvm_stack_make_shape:3
msgid "The tuple shape."
msgstr ""

#: of tvm.tir.op.tvm_store_matrix_sync:1
msgid "TVM intrinsic for tensor core store operators"
msgstr ""

#: of tvm.tir.op.tvm_struct_get:1
msgid "Get struct field value in array"
msgstr ""

#: of tvm.tir.op.tvm_struct_get:3
msgid "The date type of the result."
msgstr ""

#: of tvm.tir.op.tvm_struct_get:5 tvm.tir.op.tvm_struct_set:3
msgid "The array of struct."
msgstr ""

#: of tvm.tir.op.tvm_struct_get:7 tvm.tir.op.tvm_struct_set:5
msgid "The index of struct."
msgstr ""

#: of tvm.tir.op.tvm_struct_get:9 tvm.tir.op.tvm_struct_set:7
msgid "The field of struct."
msgstr ""

#: of tvm.tir.op.tvm_struct_set:1
msgid "Set value in struct field in array"
msgstr ""

#: of tvm.tir.op.tvm_struct_set:9
msgid "The value to be set in field."
msgstr ""

#: of tvm.tir.op.tvm_thread_allreduce:1
msgid "Perform allreduce inside threadblock."
msgstr ""

#: of tvm.tir.op.tvm_thread_allreduce:3
msgid "The args."
msgstr ""

#: of tvm.tir.op.tvm_throw_last_error:1
msgid "Throw TVMGetLastError()"
msgstr ""

#: of tvm.tir.op.tvm_tuple:1
msgid "Create a tuple structure in value field of AttrStmt"
msgstr ""

#: of tvm.tir.op.tvm_tuple:3
msgid "The value in tuple."
msgstr ""

#: of tvm.tir.op.type_annotation:1
msgid "Create a type annotation expression"
msgstr ""

#: of tvm.tir.op.undef:1
msgid "Returns an initialized but arbitrary value"
msgstr ""

#: of tvm.tir.op.vectorcombine:1
msgid "Concat two vectors"
msgstr ""

#: of tvm.tir.op.vectorhigh:1
msgid "Get the high level half of the vector"
msgstr ""

#: of tvm.tir.op.vectorlow:1
msgid "Get the low level half of the vector"
msgstr ""

#: of tvm.tir.op.vscale:1
msgid ""
"Get the target's vscale value. It will be lowered to llvm.vscale "
"intrinsic (https://llvm.org/docs/LangRef.html#llvm-vscale-intrinsic) "
":returns: **call** -- Call to the vscale intrinsic :rtype: PrimExpr"
msgstr ""


# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-11-17 09:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../notebook/docs/reference/api/python/graph_executor.rst:19
msgid "tvm.contrib.graph_executor"
msgstr ""

#~ msgid "Return the 'shape' and 'dtype' dictionaries of the graph."
#~ msgstr ""

#~ msgid ""
#~ "We can't simply get the input "
#~ "tensors from a TVM graph because "
#~ "weight tensors are treated equivalently. "
#~ "Therefore, to find the input tensors "
#~ "we look at the 'arg_nodes' in the"
#~ " graph (which are either weights or"
#~ " inputs) and check which ones don't"
#~ " appear in the params (where the "
#~ "weights are stored). These nodes are "
#~ "therefore inferred to be input tensors."
#~ msgstr ""

#~ msgid ""
#~ "* **shape_dict** (*Map*) -- Shape "
#~ "dictionary - {input_name: tuple}. * "
#~ "**dtype_dict** (*Map*) -- dtype dictionary "
#~ "- {input_name: dtype}."
#~ msgstr ""

#~ msgid "**shape_dict** (*Map*) -- Shape dictionary - {input_name: tuple}."
#~ msgstr ""

#~ msgid "**dtype_dict** (*Map*) -- dtype dictionary - {input_name: dtype}."
#~ msgstr ""

#~ msgid "Minimum graph executor that executes graph containing TVM PackedFunc."
#~ msgstr ""

#~ msgid "Wrapper runtime module."
#~ msgstr ""

#~ msgid ""
#~ "This is a thin wrapper of the "
#~ "underlying TVM module. you can also "
#~ "directly call set_input, run, and "
#~ "get_output of underlying module functions"
#~ msgstr ""

#~ msgid "参数"
#~ msgstr ""

#~ msgid "The internal tvm module that holds the actual graph functions."
#~ msgstr ""

#~ msgid "type"
#~ msgstr ""

#~ msgid "tvm.runtime.Module"
#~ msgstr ""

#~ msgid "实际案例"
#~ msgstr ""

#~ msgid "Calculate runtime of a function by repeatedly calling it."
#~ msgstr ""

#~ msgid ""
#~ "Use this function to get an "
#~ "accurate measurement of the runtime of"
#~ " a function. The function is run "
#~ "multiple times in order to account "
#~ "for variability in measurements, processor "
#~ "speed or other external factors.  Mean,"
#~ " median, standard deviation, min and "
#~ "max runtime are all reported.  On "
#~ "GPUs, CUDA and ROCm specifically, "
#~ "special on-device timers are used "
#~ "so that synchonization and data transfer"
#~ " operations are not counted towards "
#~ "the runtime. This allows for fair "
#~ "comparison of runtimes across different "
#~ "functions and models. The `end_to_end` "
#~ "flag switches this behavior to include"
#~ " data transfer operations in the "
#~ "runtime."
#~ msgstr ""

#~ msgid "The benchmarking loop looks approximately like so:"
#~ msgstr ""

#~ msgid "The function to benchmark. This is ignored if `end_to_end` is true."
#~ msgstr ""

#~ msgid ""
#~ "Number of times to run the outer"
#~ " loop of the timing code (see "
#~ "above). The output will contain `repeat`"
#~ " number of datapoints."
#~ msgstr ""

#~ msgid ""
#~ "Number of times to run the inner"
#~ " loop of the timing code. This "
#~ "inner loop is run in between the"
#~ " timer starting and stopping. In "
#~ "order to amortize any timing overhead,"
#~ " `number` should be increased when "
#~ "the runtime of the function is "
#~ "small (less than a 1/10 of a "
#~ "millisecond)."
#~ msgstr ""

#~ msgid ""
#~ "If set, the inner loop will be "
#~ "run until it takes longer than "
#~ "`min_repeat_ms` milliseconds. This can be "
#~ "used to ensure that the function "
#~ "is run enough to get an accurate"
#~ " measurement."
#~ msgstr ""

#~ msgid ""
#~ "If set, include time to transfer "
#~ "input tensors to the device and "
#~ "time to transfer returned tensors in "
#~ "the total runtime. This will give "
#~ "accurate timings for end to end "
#~ "workloads."
#~ msgstr ""

#~ msgid ""
#~ "Named arguments to the function. These"
#~ " are cached before running timing "
#~ "code, so that data transfer costs "
#~ "are not counted in the runtime."
#~ msgstr ""

#~ msgid "返回"
#~ msgstr ""

#~ msgid ""
#~ "**timing_results** -- Runtimes of the "
#~ "function. Use `.mean` to access the "
#~ "mean runtime, use `.results` to access"
#~ " the individual runtimes (in seconds)."
#~ msgstr ""

#~ msgid "返回类型"
#~ msgstr ""

#~ msgid "Run graph up to node and get the output to out"
#~ msgstr ""

#~ msgid "The node index or name"
#~ msgstr ""

#~ msgid "The output array container"
#~ msgstr ""

#~ msgid "Get index-th input to out"
#~ msgstr ""

#~ msgid "The input index"
#~ msgstr ""

#~ msgid "Get inputs index via input name."
#~ msgstr ""

#~ msgid "The input key name"
#~ msgstr ""

#~ msgid ""
#~ "**index** -- The input index. -1 "
#~ "will be returned if the given "
#~ "input name is not found."
#~ msgstr ""

#~ msgid "Get the number of inputs to the graph"
#~ msgstr ""

#~ msgid "**count** -- The number of inputs."
#~ msgstr ""

#~ msgid "Get the number of outputs from the graph"
#~ msgstr ""

#~ msgid "**count** -- The number of outputs."
#~ msgstr ""

#~ msgid "Get index-th output to out"
#~ msgstr ""

#~ msgid "The output index"
#~ msgstr ""

#~ msgid "Load parameters from serialized byte array of parameter dict."
#~ msgstr ""

#~ msgid "The serialized parameter dict."
#~ msgstr ""

#~ msgid "Run forward execution of the graph"
#~ msgstr ""

#~ msgid "List of input values to be feed to"
#~ msgstr ""

#~ msgid "Set inputs to the module via kwargs"
#~ msgstr ""

#~ msgid "The input key"
#~ msgstr ""

#~ msgid "Additional arguments"
#~ msgstr ""

#~ msgid "Share parameters from pre-existing GraphExecutor instance."
#~ msgstr ""

#~ msgid ""
#~ "The parent GraphExecutor from which this"
#~ " instance should share it's parameters."
#~ msgstr ""

#~ msgid "The serialized parameter dict (used only for the parameter names)."
#~ msgstr ""

#~ msgid "Create a runtime executor module given a graph and module."
#~ msgstr ""

#~ msgid ""
#~ "The graph to be deployed in json"
#~ " format output by json graph. The "
#~ "graph can contain operator(tvm_op) that "
#~ "points to the name of PackedFunc "
#~ "in the libmod."
#~ msgstr ""

#~ msgid "The module of the corresponding function"
#~ msgstr ""

#~ msgid ""
#~ "The device to deploy the module. "
#~ "It can be local or remote when "
#~ "there is only one Device. Otherwise, "
#~ "the first device in the list will"
#~ " be used as this purpose. All "
#~ "device should be given for heterogeneous"
#~ " execution."
#~ msgstr ""

#~ msgid ""
#~ "**graph_module** -- Runtime graph module "
#~ "that can be used to execute the"
#~ " graph."
#~ msgstr ""

#~ msgid ""
#~ "See also "
#~ ":py:class:`tvm.contrib.graph_executor.GraphModule` for "
#~ "examples to directly construct a "
#~ "GraphModule from an exported relay "
#~ "compiled library."
#~ msgstr ""

#~ msgid "Parse and validate all the device(s)."
#~ msgstr ""

#~ msgid ""
#~ "* **device** (*list of Device*) * "
#~ "**num_rpc_dev** (*Number of rpc devices*) "
#~ "* **device_type_id** (*List of device "
#~ "type and device id*)"
#~ msgstr ""

#~ msgid "**device** (*list of Device*)"
#~ msgstr ""

#~ msgid "**num_rpc_dev** (*Number of rpc devices*)"
#~ msgstr ""

#~ msgid "**device_type_id** (*List of device type and device id*)"
#~ msgstr ""

#~ msgid "Optional[float]"
#~ msgstr ""

#~ msgid "Parameters"
#~ msgstr ""

#~ msgid "Attributes"
#~ msgstr ""

#~ msgid "Examples"
#~ msgstr ""

#~ msgid "Returns"
#~ msgstr ""

#~ msgid "Note"
#~ msgstr ""

#~ msgid "module"
#~ msgstr ""

#~ msgid "Get internal module function"
#~ msgstr ""

#~ msgid "key"
#~ msgstr ""

#~ msgid "str"
#~ msgstr ""

#~ msgid "The key to the module."
#~ msgstr ""

#~ msgid "func_name"
#~ msgstr ""

#~ msgid "repeat"
#~ msgstr ""

#~ msgid "int"
#~ msgstr ""

#~ msgid "number"
#~ msgstr ""

#~ msgid "min_repeat_ms"
#~ msgstr ""

#~ msgid "Optional[int]"
#~ msgstr ""

#~ msgid "limit_zero_time_iterations"
#~ msgstr ""

#~ msgid ""
#~ "The maximum number of repeats when "
#~ "measured time is equal to 0. It"
#~ " helps to avoid hanging during "
#~ "measurements."
#~ msgstr ""

#~ msgid "end_to_end"
#~ msgstr ""

#~ msgid "bool"
#~ msgstr ""

#~ msgid "cooldown_interval_ms: Optional[int]"
#~ msgstr ""

#~ msgid ""
#~ "The cooldown interval in milliseconds "
#~ "between the number of repeats defined"
#~ " by `repeats_to_cooldown`."
#~ msgstr ""

#~ msgid "repeats_to_cooldown: Optional[int]"
#~ msgstr ""

#~ msgid "The number of repeats before the cooldown is activated."
#~ msgstr ""

#~ msgid "kwargs"
#~ msgstr ""

#~ msgid "Dict[str, Object]"
#~ msgstr ""

#~ msgid "timing_results"
#~ msgstr ""

#~ msgid "BenchmarkResult"
#~ msgstr ""

#~ msgid ""
#~ "Runtimes of the function. Use `.mean`"
#~ " to access the mean runtime, use "
#~ "`.results` to access the individual "
#~ "runtimes (in seconds)."
#~ msgstr ""

#~ msgid "node"
#~ msgstr ""

#~ msgid "int / str"
#~ msgstr ""

#~ msgid "out"
#~ msgstr ""

#~ msgid "NDArray"
#~ msgstr ""

#~ msgid "index"
#~ msgstr ""

#~ msgid "name"
#~ msgstr ""

#~ msgid "index: int"
#~ msgstr ""

#~ msgid ""
#~ "The input index. -1 will be "
#~ "returned if the given input name "
#~ "is not found."
#~ msgstr ""

#~ msgid "shape_dict"
#~ msgstr ""

#~ msgid "Map"
#~ msgstr ""

#~ msgid "Shape dictionary - {input_name: tuple}."
#~ msgstr ""

#~ msgid "dtype_dict"
#~ msgstr ""

#~ msgid "dtype dictionary - {input_name: dtype}."
#~ msgstr ""

#~ msgid "count"
#~ msgstr ""

#~ msgid "The number of inputs."
#~ msgstr ""

#~ msgid "The number of outputs."
#~ msgstr ""

#~ msgid "params_bytes"
#~ msgstr ""

#~ msgid "bytearray"
#~ msgstr ""

#~ msgid "input_dict: dict of str to NDArray"
#~ msgstr ""

#~ msgid "int or str"
#~ msgstr ""

#~ msgid "value"
#~ msgstr ""

#~ msgid "the input value."
#~ msgstr ""

#~ msgid "The input value"
#~ msgstr ""

#~ msgid "params"
#~ msgstr ""

#~ msgid "dict of str to NDArray"
#~ msgstr ""

#~ msgid "Set inputs to the module via kwargs with zero memory copy"
#~ msgstr ""

#~ msgid "the input value in DLPack"
#~ msgstr ""

#~ msgid "Set outputs to the module with zero memory copy"
#~ msgstr ""

#~ msgid "The output key"
#~ msgstr ""

#~ msgid "the output value in DLPack"
#~ msgstr ""

#~ msgid "The output value"
#~ msgstr ""

#~ msgid "other: GraphExecutor"
#~ msgstr ""

#~ msgid "graph_json_str"
#~ msgstr ""

#~ msgid "libmod"
#~ msgstr ""

#~ msgid "device"
#~ msgstr ""

#~ msgid "Device or list of Device"
#~ msgstr ""

#~ msgid "graph_module"
#~ msgstr ""

#~ msgid "GraphModule"
#~ msgstr ""

#~ msgid "Runtime graph module that can be used to execute the graph."
#~ msgstr ""

#~ msgid "device : Device or list of Device"
#~ msgstr ""

#~ msgid ""
#~ "device : list of Device num_rpc_dev "
#~ ": Number of rpc devices device_type_id"
#~ " : List of device type and "
#~ "device id"
#~ msgstr ""


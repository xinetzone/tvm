# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-02-05 13:19+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.16.0\n"

#: ../../doc/docs/reference/api/python/graph_executor.rst:19
msgid "tvm.contrib.graph_executor"
msgstr ""

#: of tvm.contrib.graph_executor:1
msgid "Minimum graph executor that executes graph containing TVM PackedFunc."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule:1
msgid "Wrapper runtime module."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule:3
msgid ""
"This is a thin wrapper of the underlying TVM module. you can also "
"directly call set_input, run, and get_output of underlying module "
"functions"
msgstr ""

#: ../../doc/docs/reference/api/python/graph_executor.rst
msgid "参数"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule:7
#: tvm.contrib.graph_executor.GraphModule:12
msgid "The internal tvm module that holds the actual graph functions."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule
msgid "type"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule:14
msgid "tvm.runtime.Module"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule:17
msgid "示例"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:1
msgid "Calculate runtime of a function by repeatedly calling it."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:3
msgid ""
"Use this function to get an accurate measurement of the runtime of a "
"function. The function is run multiple times in order to account for "
"variability in measurements, processor speed or other external factors.  "
"Mean, median, standard deviation, min and max runtime are all reported.  "
"On GPUs, CUDA and ROCm specifically, special on-device timers are used so"
" that synchonization and data transfer operations are not counted towards"
" the runtime. This allows for fair comparison of runtimes across "
"different functions and models. The `end_to_end` flag switches this "
"behavior to include data transfer operations in the runtime."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:11
msgid "The benchmarking loop looks approximately like so:"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:23
msgid "The function to benchmark. This is ignored if `end_to_end` is true."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:25
msgid ""
"Number of times to run the outer loop of the timing code (see above). The"
" output will contain `repeat` number of datapoints."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:28
msgid ""
"Number of times to run the inner loop of the timing code. This inner loop"
" is run in between the timer starting and stopping. In order to amortize "
"any timing overhead, `number` should be increased when the runtime of the"
" function is small (less than a 1/10 of a millisecond)."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:33
msgid ""
"If set, the inner loop will be run until it takes longer than "
"`min_repeat_ms` milliseconds. This can be used to ensure that the "
"function is run enough to get an accurate measurement."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:37
msgid ""
"The maximum number of repeats when measured time is equal to 0. It helps "
"to avoid hanging during measurements."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:40
msgid ""
"If set, include time to transfer input tensors to the device and time to "
"transfer returned tensors in the total runtime. This will give accurate "
"timings for end to end workloads."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:44
msgid ""
"The cooldown interval in milliseconds between the number of repeats "
"defined by `repeats_to_cooldown`."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:47
msgid "The number of repeats before the cooldown is activated."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:49
msgid ""
"Named arguments to the function. These are cached before running timing "
"code, so that data transfer costs are not counted in the runtime."
msgstr ""

#: ../../doc/docs/reference/api/python/graph_executor.rst
msgid "返回"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.benchmark:53
msgid ""
"**timing_results** -- Runtimes of the function. Use `.mean` to access the"
" mean runtime, use `.results` to access the individual runtimes (in "
"seconds)."
msgstr ""

#: ../../doc/docs/reference/api/python/graph_executor.rst
msgid "返回类型"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.debug_get_output:1
msgid "Run graph up to node and get the output to out"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.debug_get_output:3
msgid "The node index or name"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.debug_get_output:5
#: tvm.contrib.graph_executor.GraphModule.get_input:5
#: tvm.contrib.graph_executor.GraphModule.get_output:5
msgid "The output array container"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_input:1
msgid "Get index-th input to out"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_input:3
msgid "The input index"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_input_index:1
msgid "Get inputs index via input name."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_input_index:3
msgid "The input key name"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_input_index:6
msgid ""
"**index** -- The input index. -1 will be returned if the given input name"
" is not found."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_input_info:1
#: tvm.contrib.graph_executor.GraphModule.get_output_info:1
msgid "Return the 'shape' and 'dtype' dictionaries of the graph."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_input_info:4
msgid ""
"We can't simply get the input tensors from a TVM graph because weight "
"tensors are treated equivalently. Therefore, to find the input tensors we"
" look at the 'arg_nodes' in the graph (which are either weights or "
"inputs) and check which ones don't appear in the params (where the "
"weights are stored). These nodes are therefore inferred to be input "
"tensors."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_input_info:11
msgid ""
"* **shape_dict** (*Map*) -- Shape dictionary - {input_name: tuple}. * "
"**dtype_dict** (*Map*) -- dtype dictionary - {input_name: dtype}."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_input_info:11
msgid "**shape_dict** (*Map*) -- Shape dictionary - {input_name: tuple}."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_input_info:12
msgid "**dtype_dict** (*Map*) -- dtype dictionary - {input_name: dtype}."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_num_inputs:1
msgid "Get the number of inputs to the graph"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_num_inputs:3
msgid "**count** -- The number of inputs."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_num_outputs:1
msgid "Get the number of outputs from the graph"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_num_outputs:3
msgid "**count** -- The number of outputs."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_output:1
msgid "Get index-th output to out"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_output:3
msgid "The output index"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_output_index:1
msgid "Get outputs index via output name."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_output_index:3
msgid "The output key name"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_output_index:6
msgid ""
"**index** -- The output index. -1 will be returned if the given output "
"name is not found."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_output_info:3
msgid ""
"* **shape_dict** (*Map*) -- Shape dictionary - {output_name: tuple}. * "
"**dtype_dict** (*Map*) -- dtype dictionary - {output_name: dtype}."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_output_info:3
msgid "**shape_dict** (*Map*) -- Shape dictionary - {output_name: tuple}."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.get_output_info:4
msgid "**dtype_dict** (*Map*) -- dtype dictionary - {output_name: dtype}."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.load_params:1
msgid "Load parameters from serialized byte array of parameter dict."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.load_params:3
msgid "The serialized parameter dict."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.run:1
msgid "Run forward execution of the graph"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.run:3
msgid "List of input values to be feed to"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.set_input:1
msgid "Set inputs to the module via kwargs"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.set_input:3
#: tvm.contrib.graph_executor.GraphModule.set_input_zero_copy:3
msgid "The input key"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.set_input:5
#: tvm.contrib.graph_executor.GraphModule.set_input_zero_copy:5
msgid "The input value"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.set_input:7
#: tvm.contrib.graph_executor.GraphModule.set_input_zero_copy:7
msgid "Additional arguments"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.set_input_zero_copy:1
msgid "Set inputs to the module via kwargs with zero memory copy"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.set_output_zero_copy:1
msgid "Set outputs to the module with zero memory copy"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.set_output_zero_copy:3
msgid "The output key"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.set_output_zero_copy:5
msgid "The output value"
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.share_params:1
msgid "Share parameters from pre-existing GraphExecutor instance."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.share_params:3
msgid ""
"The parent GraphExecutor from which this instance should share it's "
"parameters."
msgstr ""

#: of tvm.contrib.graph_executor.GraphModule.share_params:6
msgid "The serialized parameter dict (used only for the parameter names)."
msgstr ""

#: of tvm.contrib.graph_executor.create:1
msgid "Create a runtime executor module given a graph and module."
msgstr ""

#: of tvm.contrib.graph_executor.create:3
msgid ""
"The graph to be deployed in json format output by json graph. The graph "
"can contain operator(tvm_op) that points to the name of PackedFunc in the"
" libmod."
msgstr ""

#: of tvm.contrib.graph_executor.create:7
#: tvm.contrib.graph_executor.get_device:3
msgid "The module of the corresponding function"
msgstr ""

#: of tvm.contrib.graph_executor.create:9
msgid ""
"The device to deploy the module. It can be local or remote when there is "
"only one Device. Otherwise, the first device in the list will be used as "
"this purpose. All device should be given for heterogeneous execution."
msgstr ""

#: of tvm.contrib.graph_executor.create:15
msgid ""
"**graph_module** -- Runtime graph module that can be used to execute the "
"graph."
msgstr ""

#: of tvm.contrib.graph_executor.create:20
msgid ""
"See also :py:class:`tvm.contrib.graph_executor.GraphModule` for examples "
"to directly construct a GraphModule from an exported relay compiled "
"library."
msgstr ""

#: of tvm.contrib.graph_executor.get_device:1
msgid "Parse and validate all the device(s)."
msgstr ""

#: of tvm.contrib.graph_executor.get_device:8
msgid ""
"* **device** (*list of Device*) * **num_rpc_dev** (*Number of rpc "
"devices*) * **device_type_id** (*List of device type and device id*)"
msgstr ""

#: of tvm.contrib.graph_executor.get_device:8
msgid "**device** (*list of Device*)"
msgstr ""

#: of tvm.contrib.graph_executor.get_device:9
msgid "**num_rpc_dev** (*Number of rpc devices*)"
msgstr ""

#: of tvm.contrib.graph_executor.get_device:10
msgid "**device_type_id** (*List of device type and device id*)"
msgstr ""


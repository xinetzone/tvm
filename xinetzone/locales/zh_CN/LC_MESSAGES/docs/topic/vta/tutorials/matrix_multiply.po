# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-02-09 00:02+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:10003
msgid "简单的矩阵乘法"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:10005
msgid "**原作者**: [Thierry Moreau](https://homes.cs.washington.edu/~moreau/)"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:10007
msgid "在本教程构建在 {ref}`vta-get-started` 教程的基础上，并介绍在 VTA 上使用 TVM 工作流实现矩阵乘法所需的额外概念。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:10009
msgid "RPC 设置"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:10011
msgid "从编程 Pynq 的 FPGA 和构建它的 RPC 运行时开始，就像在 VTA 介绍性教程中做的那样。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:40002
msgid "计算声明"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:40004
msgid "在这个例子中，描述了简单的矩阵乘法加法，它需要多个计算阶段，如下面的数据流图所示。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:40006
msgid "首先描述存在于 main memory 中的输入张量 `A` 和 `B`。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:40007
msgid ""
"其次，需要声明中间张量 `A_buf` 和 `B_buf`，它们将存在于 VTA 的 on-chip buffers "
"中。有了这个额外的计算阶段，就可以显式地分阶段 cached 读和写。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:40008
msgid "接着，描述了 `A_buf` 和 `B_buf` 上的矩阵乘法运算，以产生 product matrix `C_buf`。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:40009
msgid "最后的运算是强制转换和复制回 DRAM，到结果张量 `C`。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50002
msgid "数据布局"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50004
msgid "以平铺数据格式描述占位符张量 `A`和 `B`，以匹配 VTA 张量核心施加的数据布局要求。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50006
msgid "数据平铺（Tiling）"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50009
msgid ""
"在瞄准加速器时，复杂性的来源之一是确保数据布局与加速器设计施加的布局相匹配。VTA 是围绕 *tensor core* "
"设计的，它在激活矩阵和权值矩阵之间执行周期的矩阵-矩阵运算，将结果矩阵添加到累加器矩阵，如下图所示。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50016
msgid ""
"矩阵-矩阵乘法的维度在 `vta_config.json` 配置文件中指定。激活矩阵为 `(BATCH, BLOCK_IN)` 形状，权重矩阵为 "
"`(BLOCK_OUT, BLOCK_IN)` 形状，由此推断，得到的输出矩阵为 `(BATCH, BLOCK_OUT)` 形状。因此，VTA "
"处理的输入和输出张量需要根据上述尺寸平铺。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50019
msgid "数学公式表示："
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50021
msgid ""
"\n"
"\\begin{cases}\n"
"X = \\begin{pmatrix}\n"
"   x_1 \\\\\n"
"   \\vdots \\\\\n"
"   x_{\\colorbox{aqua}{BATCH}}\n"
"\\end{pmatrix}\\\\\n"
"W = \\begin{pmatrix}\n"
"   w_1 \\\\\n"
"   \\vdots \\\\\n"
"   w_{\\colorbox{aqua}{BLOCK_OUT}}\n"
"\\end{pmatrix}\n"
"\\end{cases}\n"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50036
msgid "其中 $x_i, w_j \\in \\mathbb{R}^{\\colorbox{aqua}{BLOCK_IN}}$。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50038
msgid "故而"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50040
msgid ""
"\n"
"O = X W^T = \\begin{pmatrix}\n"
"\\braket{x_i, w_j}\n"
"\\end{pmatrix}\n"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50047
msgid ""
"下图显示了数据平铺对最初形状为 (4,8) 的矩阵的影响。平铺 (2,2) tile 保证了每个平铺内的数据是连续的。得到的平铺张量的形状是 "
"(2, 4, 2, 2)。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50055
msgid ""
"首先定义变量 `m`，`n`，`o` 来表示矩阵乘法的形状。这些变量分别是 `BLOCK_OUT`、`BLOCK_IN` 和 `BATCH` "
"张量维度上的乘法因子。默认情况下，配置文件将 `BATCH`、`BLOCK_IN` 和 `BLOCK_OUT` 分别设置为 1、16 和 16（将"
" `BATCH` 设置为 1 意味着计算构建块是向量-矩阵乘法）。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50057
msgid "数据类型"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50060
msgid ""
"重要的是，不仅要匹配 VTA 张量核心的内部 tile 维度，而且要匹配 VTA 期望的特定数据类型。VTA 目前只支持定点数据类型（fixed "
"point data types），整数宽度在 `vta_config.json` 中指定。`INP_WIDTH` 和 `WGT_WIDTH` "
"分别用于激活和权重数据类型。此外，累加器数据类型整型宽度由 `ACC_WIDTH` 指定。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:50063
msgid ""
"默认情况下，配置文件将 `INP_WIDTH` 和 `WGT_WIDTH` 设置为 8。累加器宽度 `ACC_WIDTH` 被设置为 "
"32，以避免累加时溢出。结果是 `env.inp_dtype` 和 `env.wgt_dtype` 都是窄化的 8 位整型，而 "
"`env.acc_dtype` 是标准的 32 位整型。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:70002
msgid "矩阵乘法"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:70004
msgid ""
"描述矩阵乘法的结果张量 `C`，还有另一个 compute 运算。compute 函数采用张量的形式，以及描述张量每个位置的计算规则的 "
"lambda 函数。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:70006
msgid ""
"为了实现矩阵乘法，lambda 函数需要包含输入通道维度轴上的 reduction 公式。要创建 reduction 公式，可以使用 "
"`te.reduce_axis` 声明 reduction axis，它在 reduction 的范围内。`te.sum` 接受要 "
"reduction 的表达式和 reduction axes，以计算声明范围内所有 k 的值的和。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:70008
msgid "注意 reduction 需要在 32 位 `env.acc_dtype` 累加器数据类型上执行。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:70010
msgid "在这个阶段没有计算发生，因为只是声明应该如何进行计算。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:90002
msgid "Casting 结果"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:90004
msgid "计算完成后，需要将 VTA 计算的结果发送回 main memory。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:90006
msgid "内存存储的限制"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:90009
msgid ""
"VTA 的特点之一是，它只支持 DRAM 存储在窄化的 `env.inp_dtype` "
"数据类型格式。这使能够减少内存传输的数据占用，但也使能够将宽的累加器数据类型量化为与输入激活数据类型匹配的数据格式。这意味着在神经网络推理的背景下，激活某一层后的输出可以直接被下一层"
" consumed。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:90012
msgid "对窄化输入激活数据格式执行最后一次 typecast 运算。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:110002
msgid "本教程的计算声明部分到此结束。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:120002
msgid "调度计算"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:120004
msgid "虽然上面几行描述了计算规则，但可以通过多种方式得到 `C`。TVM 要求用户提供名为 schedule 的计算实现。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:120006
msgid ""
"调度是对原始计算的一组变换，它在不影响正确性的情况下变换计算的实现。这个简单的 VTA 编程教程旨在演示基本的调度变换，将原始的调度映射到 VTA"
" 硬件原语（primitive）。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:120008
msgid "默认调度"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:120010
msgid "在构造了调度后，默认情况下，调度按以下方式计算 `C`："
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:140002
msgid ""
"虽然此调度有意义，但它不会编译到 VTA。为了获得正确的代码生成，需要应用调度原语和代码注解，将调度变换为可以直接 lower 至 VTA 硬件 "
"intrinsic 的调度。这些包括："
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:140004
msgid "DMA 复制运算，将全局作用域张量复制到局部作用域张量。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:140005
msgid "用来做矩阵乘法的张量运算。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:140007
msgid "Buffer 作用域"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:140009
msgid ""
"首先，设置 buffer 的作用域来告诉 TVM 这些 buffer 将存在于 VTA 的 on-chip SRAM cache 中。下面，告诉 "
"TVM, `A_buf`，`B_buf`，`C_buf` 将分别存在于 VTA 的 on-chip "
"输入，权重和累加器（accumulator）内存中。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:150002
msgid "VTA's On-Chip SRAMs"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:150005
msgid "VTA 有三个不同的内存作用域，每个都对应于不同的片上 SRAM buffer。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:150007
msgid ""
"`env.inp_scope`：输入 buffer，这是只读的 SRAM buffer，存储形状为 `(env.BATCH, "
"env.BLOCK_IN)`，类型为 `env.inp_dtype` 的矩阵。输入 buffer 包含 $2 ^ "
"\\text{LOG_INP_BUFF_SIZE}$ 个矩阵元素（在 `vta_config.json` 文件中指定）。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:150008
msgid ""
"`env.wgt_scope`：权重 buffer，这是只读的 SRAM buffer，存储形状为 `(env.BLOCK_OUT, "
"env.BLOCK_IN)`，类型为 `env.wgt_dtype` 的矩阵。权重 buffer 包含 $2 ^ "
"\\text{LOG_WGT_BUFF_SIZE}$ 个矩阵元素。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:150009
msgid ""
"`env.acc_scope`： Accumulator buffer，这是读/写 SRAM buffer，存储形状为 `(env.BATCH, "
"env.BLOCK_OUT)`，类型为 `env.acc_dtype` 的累加矩阵。累加器 buffer 是 VTA "
"的通用寄存器文件：它既保存卷积和矩阵乘法的中间结果，也保存池化、batch normalization 和激活层的中间结果。累加器缓冲区包含 $2"
" ^ \\text{LOG_ACC_BUFF_SIZE}$ 个矩阵元素。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:170002
msgid "DMA 传输"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:170004
msgid ""
"需要调度 DMA transfer 来将存在于 DRAM 中的数据移动到 VTA on-chip buffer。这可以使用 "
"`compute_at` 调度原语实现，该原语将 buffer 的复制嵌套到执行矩阵乘法的计算循环中。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:170006
msgid ""
"插入 `dma_copy` pragmas 来指示编译器，复制运算将通过 DMA "
"批量执行，这在硬件加速器中很常见。最后，打印临时调度，观察将复制运算移动到矩阵乘法循环中的效果。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:190002
msgid "张量化"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:190004
msgid ""
"调度 transformation 的最后一步是对调度应用 "
"*tensorization*。张量化类似于向量化，但将这个概念扩展到了高维计算单元。因此，在声明数据布局输入占位符时，张量化会施加数据布局约束。我们已经以平铺的形式排列了张量，所以接下来需要做的是循环重新排序以适应张量化。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:190006
msgid ""
"在这里，选择将最外面的 reduction 轴移出。这表明首先遍历输入通道，然后是 batch "
"维度，最后是输出通道。最后，应用张量调度原语沿着最内层矩阵的矩阵乘法张量块的外轴张量。打印最终的调度，该调度已准备好由 VTA 运行时 JIT "
"编译器生成代码。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:210002
msgid "本教程的调度部分到此结束。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:210004
msgid "TVM 计算"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:210006
msgid "在完成了调度的指定之后，可以将它编译成 TVM 函数。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:230002
msgid "运行函数"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:230004
msgid "编译后的 TVM 函数使用简洁的 C API，可以从代码语言调用。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:230006
msgid ""
"TVM 在 python 中提供了数组 API 来帮助快速测试和创建原型。数组 API 基于 "
"[DLPac](https://github.com/dmlc/dlpack) 标准。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:230008
msgid "首先创建远程上下文（remote context）（用于在 Pynq 上远程执行）。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:230009
msgid "然后 {func}`tvm.nd.array` 相应地格式化数据。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:230010
msgid "{func}`f` 运行实际的计算。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:230011
msgid "`numpy()` 以可解释的格式将结果数组复制回来。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:250002
msgid "验证正确性"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:250004
msgid "用 numpy 计算参考结果，并断言矩阵乘法的输出确实是正确的："
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:270002
msgid "小结"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:270004
msgid "本教程展示了在 VTA 上实现简单矩阵乘法的 TVM 工作流。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:270006
msgid "一般工作流程包括："
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:270008
msgid "编程带有 VTA bitstream 的 FPGA 上的 RPC。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:270009
msgid "通过一系列计算描述矩阵乘法。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:270010
msgid "描述希望如何使用调度原语执行计算。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:270011
msgid "编译函数到 VTA 目标。"
msgstr ""

#: ../../xin/docs/topic/vta/tutorials/matrix_multiply.ipynb:270012
msgid "运行编译后的模块，并根据 numpy 实现来验证它。"
msgstr ""


# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-10-13 11:16+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../notebook/docs/arch/debugger.rst:20
msgid "Debugger"
msgstr "调试器"

#: ../../notebook/docs/arch/debugger.rst:22
msgid ""
"TVM Debugger is an interface for debugging TVM's computation graph "
"execution. It helps to provide access to graph structures and tensor "
"values at the TVM runtime."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:26
msgid "Debug Exchange Format"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:29
msgid "1. Computational Graph"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:30
msgid ""
"The optimized graph build by relay in json serialized format is dumped as"
" it is. This contains the whole information about the graph. The UX can "
"either use this graph directly or transform this graph to the format UX "
"can understand."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:35
msgid "The Graph JSON format is explained below"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:37
msgid ""
"1. ``nodes`` Nodes are either placeholders or computational nodes in "
"json. The nodes are stored as a list. A node contains the below "
"information"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:41
msgid ""
"``op`` - operation type, ``null`` means it is a "
"placeholder/variable/input node and``tvm_op`` means this node can be "
"executed"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:42
msgid "``name`` - Name of the node"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:43
msgid ""
"``inputs`` - Position of the inputs for this operation, Inputs is a list "
"of tuples with (nodeid, index, version). (Optional)"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:44
msgid ""
"``attrs`` - Attributes of the node which contains the following "
"information"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:46
msgid "``flatten_data`` - Whether this data need to be flattened before execution"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:47
msgid ""
"``func_name`` - Fused function name, corresponds to the symbol in the lib"
" generated by relay compilation process."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:48
msgid "``num_inputs`` - Number of inputs for this node"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:49
msgid "``num_outputs`` - Number of outputs this node produces"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:51
msgid ""
"2. ``arg_nodes`` arg_nodes is a list of indices of nodes which is "
"placeholder/variable/input or constant/param to the graph."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:54
msgid "3. ``heads`` heads is a list of entries as the output of the graph."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:57
msgid ""
"4. ``node_row_ptr`` node\\_row\\_ptr stores the history of forward path, "
"so you can skip constructing the entire graph in inference tasks."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:60
msgid ""
"5. ``attrs`` attrs can contain version numbers or similar helpful "
"information."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:63
msgid "``storage_id`` - Memory slot id for each node in the storage layout."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:64
msgid "``dtype`` - Datatype of each node (enum value)."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:65
msgid "``dltype`` - Datatype of each node in order."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:66
msgid "``shape`` - Shape of each node k order."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:67
msgid "``device_index`` - Device assignment for each entry in the graph."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:69
msgid "Example of dumped graph:"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:109
#, fuzzy
msgid "2. Tensor dumping"
msgstr "2. Tensor 转储"

#: ../../notebook/docs/arch/debugger.rst:111
msgid ""
"The tensor received after execution is in ``tvm.ndarray`` type. All the "
"tensors will be saved as binary bytes in serialized format.  The result "
"binary bytes can be loaded by the API \"load_params\"."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:120
msgid "Example of loading the parameters"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:120
msgid "::"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:118
msgid "with open(path_params, \"rb\") as fi:"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:118
msgid "loaded_params = bytearray(fi.read())"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:120
msgid "module.load_params(loaded_params)"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:124
msgid "How to use Debugger?"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:126
msgid "In ``config.cmake`` set the ``USE_PROFILER`` flag to ``ON``"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:133
msgid "Do 'make' tvm, so that it will make the ``libtvm_runtime.so``"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:135
msgid ""
"In frontend script file instead of ``from tvm.contrib import "
"graph_executor`` import the ``GraphModuleDebug`` ``from "
"tvm.contrib.debugger.debug_executor import GraphModuleDebug``"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:158
msgid ""
"If network previously was exported to external library using "
"``lib.export_library(\"network.so\")``"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:157
msgid ""
"like shared object file/dynamic linked library, the initialization of "
"debug runtime will be slightly different"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:172
msgid ""
"The outputs are dumped to a temporary folder in ``/tmp`` folder or the "
"folder specified while creating the runtime."
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:177
msgid "Sample Output"
msgstr ""

#: ../../notebook/docs/arch/debugger.rst:179
msgid "The below is the an example output of the debugger."
msgstr ""

#~ msgid ""
#~ "In frontend script file instead of "
#~ "``from tvm.contrib import graph_executor`` "
#~ "import the ``debug_executor`` ``from "
#~ "tvm.contrib.debugger import debug_executor as "
#~ "graph_executor``"
#~ msgstr ""

#~ msgid ""
#~ "If network previously was exported to"
#~ " external libray using "
#~ "``lib.export_library(\"network.so\")``"
#~ msgstr ""

#~ msgid ""
#~ "TVM Debugger is an interface for "
#~ "debugging TVM's computation graph execution."
#~ " It helps to provide access to "
#~ "graph structures and tensor values at"
#~ " the TVM runtime."
#~ msgstr "TVM 调试器是调试 TVM 计算图执行的接口。它有助于在 TVM 运行时提供对图结构和张量值的访问。"

#~ msgid "Debug Exchange Format"
#~ msgstr "调试交换格式"

#~ msgid "1. Computational Graph"
#~ msgstr "1. 计算图"

#~ msgid ""
#~ "The optimized graph build by relay "
#~ "in json serialized format is dumped "
#~ "as it is. This contains the whole"
#~ " information about the graph. The UX"
#~ " can either use this graph directly"
#~ " or transform this graph to the "
#~ "format UX can understand."
#~ msgstr ""
#~ "通过 relay 以 json "
#~ "序列化格式构建的优化计算图被转储。它包含了关于图的全部信息。UX 可以直接使用这个图，也可以将这个图转换成 UX"
#~ " 可以理解的格式。"

#~ msgid "The Graph JSON format is explained below"
#~ msgstr "下面将解释 Graph JSON 格式"

#~ msgid ""
#~ "1. ``nodes`` Nodes are either "
#~ "placeholders or computational nodes in "
#~ "json. The nodes are stored as a"
#~ " list. A node contains the below "
#~ "information"
#~ msgstr "1. ``nodes`` 在 json 中，节点是占位符或可计算节点。节点存储为列表。节点包含以下信息"

#~ msgid ""
#~ "``op`` - operation type, ``null`` means"
#~ " it is a placeholder/variable/input node"
#~ " and``tvm_op`` means this node can be"
#~ " executed"
#~ msgstr "``op``：运算类型， ``null`` 意味着它是占位符/变量/输入节点，``tvm_op`` 意味着这个节点可以被执行"

#~ msgid "``name`` - Name of the node"
#~ msgstr "``name``：节点名字"

#~ msgid ""
#~ "``inputs`` - Position of the inputs "
#~ "for this operation, Inputs is a "
#~ "list of tuples with (nodeid, index, "
#~ "version). (Optional)"
#~ msgstr ""
#~ "``inputs``：此运算的 inputs 位置，inputs 是包含 (nodeid,"
#~ " index, version) 的元组列表。(可选)"

#~ msgid ""
#~ "``attrs`` - Attributes of the node "
#~ "which contains the following information"
#~ msgstr "``attrs``：包含以下信息的节点属性"

#~ msgid ""
#~ "``flatten_data`` - Whether this data "
#~ "need to be flattened before execution"
#~ msgstr "``flatten_data``：是否需要在执行前将数据扁平化（flattened）"

#~ msgid ""
#~ "``func_name`` - Fused function name, "
#~ "corresponds to the symbol in the "
#~ "lib generated by relay compilation "
#~ "process."
#~ msgstr "``func_name``：融合函数名，对应于 Relay 编译过程生成的库中的符号。"

#~ msgid "``num_inputs`` - Number of inputs for this node"
#~ msgstr "``num_inputs``：此节点的 inputs 个数"

#~ msgid "``num_outputs`` - Number of outputs this node produces"
#~ msgstr "``num_outputs``：此节点产生的 outputs 个数"

#~ msgid ""
#~ "2. ``arg_nodes`` arg_nodes is a list "
#~ "of indices of nodes which is "
#~ "placeholder/variable/input or constant/param to "
#~ "the graph."
#~ msgstr ""
#~ "2. ``arg_nodes`` 是节点的索引列表，它是图的 "
#~ "placeholder/variable/input 或 constant/param。"

#~ msgid "3. ``heads`` heads is a list of entries as the output of the graph."
#~ msgstr "3. ``heads`` 作为图的 output 项的列表。"

#~ msgid ""
#~ "4. ``node_row_ptr`` node\\_row\\_ptr stores "
#~ "the history of forward path, so "
#~ "you can skip constructing the entire "
#~ "graph in inference tasks."
#~ msgstr "4. ``node_row_ptr`` 存储 forward 路径的历史，所以您可以跳过在推断任务中构建整个图。"

#~ msgid ""
#~ "5. ``attrs`` attrs can contain version"
#~ " numbers or similar helpful information."
#~ msgstr "5. ``attrs`` 可以包含版本号或类似的有用信息。"

#~ msgid "``storage_id`` - Memory slot id for each node in the storage layout."
#~ msgstr "``storage_id``：存储布局中每个节点的内存 slot id。"

#~ msgid "``dtype`` - Datatype of each node (enum value)."
#~ msgstr "``dtype``：每个节点的数据类型 (enum 值)。"

#~ msgid "``dltype`` - Datatype of each node in order."
#~ msgstr "``dltype``：每个节点的数据类型按顺序排列。"

#~ msgid "``shape`` - Shape of each node k order."
#~ msgstr "``shape``：每个节点的形状 k 阶。"

#~ msgid "``device_index`` - Device assignment for each entry in the graph."
#~ msgstr "``device_index``：为图中的每个条目分配设备。"

#~ msgid "Example of dumped graph:"
#~ msgstr "转储图的示例："

#~ msgid ""
#~ "The tensor received after execution is"
#~ " in ``tvm.ndarray`` type. All the "
#~ "tensors will be saved as binary "
#~ "bytes in serialized format.  The result"
#~ " binary bytes can be loaded by "
#~ "the API \"load_params\"."
#~ msgstr ""
#~ "执行后收到的张量在 ``tvm.ndarray`` "
#~ "类型中。所有的张量将以二进制字节的序列化格式保存。结果二进制字节可以通过 API \"load_params\""
#~ " 加载。"

#~ msgid "Example of loading the parameters"
#~ msgstr "加载参数的示例"

#~ msgid "::"
#~ msgstr ""

#~ msgid "with open(path_params, \"rb\") as fi:"
#~ msgstr ""

#~ msgid "loaded_params = bytearray(fi.read())"
#~ msgstr ""

#~ msgid "module.load_params(loaded_params)"
#~ msgstr ""

#~ msgid "How to use Debugger?"
#~ msgstr "如果使用 Debugger？"

#~ msgid "In ``config.cmake`` set the ``USE_PROFILER`` flag to ``ON``"
#~ msgstr "在 ``config.cmake`` 中设置 ``USE_PROFILER`` 为 ``ON``"

#~ msgid "Do 'make' tvm, so that it will make the ``libtvm_runtime.so``"
#~ msgstr "执行 'make' tvm，这样它就会生成 ``libtvm_runtime.so``"

#~ msgid ""
#~ "In frontend script file instead of "
#~ "``from tvm.contrib import graph_executor`` "
#~ "import the ``GraphModuleDebug`` ``from "
#~ "tvm.contrib.debugger.debug_executor import "
#~ "GraphModuleDebug``"
#~ msgstr ""

#~ msgid ""
#~ "If network previously was exported to"
#~ " external library using "
#~ "``lib.export_library(\"network.so\")``"
#~ msgstr ""

#~ msgid ""
#~ "like shared object file/dynamic linked "
#~ "library, the initialization of debug "
#~ "runtime will be slightly different"
#~ msgstr ""

#~ msgid ""
#~ "The outputs are dumped to a "
#~ "temporary folder in ``/tmp`` folder or"
#~ " the folder specified while creating "
#~ "the runtime."
#~ msgstr ""

#~ msgid "Sample Output"
#~ msgstr ""

#~ msgid "The below is the an example output of the debugger."
#~ msgstr ""

#~ msgid ""
#~ "通过 json 序列化格式的 Relay "
#~ "构建的优化图被丢弃了。它包含了关于图的全部信息。UX 可以直接使用这个图，也可以将这个图转换成 UX "
#~ "可以理解的格式。"
#~ msgstr ""

#~ msgid "TVM 调试器是调试 TVM 计算图执行的接口。它有助于在 TVM 运行时提供对图结构和张量值的访问。"
#~ msgstr ""

#~ msgid "调试交换格式"
#~ msgstr ""

#~ msgid "1. 计算图"
#~ msgstr ""

#~ msgid ""
#~ "通过 relay 以 json "
#~ "序列化格式构建的优化计算图被转储。它包含了关于图的全部信息。UX 可以直接使用这个图，也可以将这个图转换成 UX"
#~ " 可以理解的格式。"
#~ msgstr ""

#~ msgid "下面将解释 Graph JSON 格式："
#~ msgstr ""

#~ msgid "nodes"
#~ msgstr ""

#~ msgid "在 json 中，节点是占位符或可计算节点。节点存储为列表。节点包含以下信息："
#~ msgstr ""

#~ msgid "``op``：运算类型， ``null`` 意味着它是占位符/变量/输入节点，``tvm_op`` 意味着这个节点可以被执行"
#~ msgstr ""

#~ msgid "``name``：节点名字"
#~ msgstr ""

#~ msgid ""
#~ "``inputs``：此运算的 inputs 位置，inputs 是包含 (nodeid,"
#~ " index, version) 的元组列表。(可选)"
#~ msgstr ""

#~ msgid "``attrs``：包含以下信息的节点属性"
#~ msgstr ""

#~ msgid "``flatten_data``：是否需要在执行前将数据扁平化（flattened）"
#~ msgstr ""

#~ msgid "``func_name``：融合函数名，对应于 Relay 编译过程生成的库中的符号。"
#~ msgstr ""

#~ msgid "``num_inputs``：此节点的 inputs 个数"
#~ msgstr ""

#~ msgid "``num_outputs``：此节点产生的 outputs 个数"
#~ msgstr ""

#~ msgid "arg_nodes"
#~ msgstr ""

#~ msgid "节点的索引列表，它是计算图的占位符/变量/输入节点 或 constant/param。"
#~ msgstr ""

#~ msgid "heads"
#~ msgstr ""

#~ msgid "作为图的 output 项的列表。"
#~ msgstr ""

#~ msgid "node_row_ptr"
#~ msgstr ""

#~ msgid "存储 forward 路径的历史，所以您可以跳过在推断任务中构建整个图。"
#~ msgstr ""

#~ msgid "attrs"
#~ msgstr ""

#~ msgid "可以包含版本号或类似的有用信息。"
#~ msgstr ""

#~ msgid "``storage_id``：存储布局中每个节点的内存 slot id。"
#~ msgstr ""

#~ msgid "``dtype``：每个节点的数据类型 (enum 值)。"
#~ msgstr ""

#~ msgid "``dltype``：每个节点的数据类型按顺序排列。"
#~ msgstr ""

#~ msgid "``shape``：每个节点的形状 k 阶。"
#~ msgstr ""

#~ msgid "``device_index``：为图中的每个条目分配设备。"
#~ msgstr ""

#~ msgid "转储图的示例："
#~ msgstr ""

#~ msgid ""
#~ "执行后收到的张量在 ``tvm.ndarray`` "
#~ "类型中所有的张量将以二进制字节的序列化格式保存。结果二进制字节可以通过 API `load_params` "
#~ "加载。"
#~ msgstr ""

#~ msgid "加载参数的示例"
#~ msgstr ""

#~ msgid "如果使用 Debugger？"
#~ msgstr "调试器"

#~ msgid "在 ``config.cmake`` 中设置 ``USE_PROFILER`` 为 ``ON``"
#~ msgstr ""

#~ msgid "执行 `make tvm`，这样它就会生成 ``libtvm_runtime.so``"
#~ msgstr ""

#~ msgid ""
#~ "在前端脚本中替换 ``from tvm.contrib import "
#~ "graph_executor`` 导入为 ``from "
#~ "tvm.contrib.debugger.debug_executor import "
#~ "GraphModuleDebug``"
#~ msgstr ""

#~ msgid ""
#~ "如果 network 之前使用 "
#~ "``lib.export_library(\"network.so\")`` "
#~ "像共享对象文件/动态链接库一样导出到外部库，调试运行时的初始化将略有不同"
#~ msgstr ""

#~ msgid "输出被转储到 ``/tmp`` 文件夹中的临时文件夹或创建运行时指定的文件夹。"
#~ msgstr ""

#~ msgid "输出示例"
#~ msgstr ""

#~ msgid "下面是调试器的输出示例："
#~ msgstr ""


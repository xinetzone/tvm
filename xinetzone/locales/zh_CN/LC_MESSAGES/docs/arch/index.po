# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2024.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm doc\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-06-13 13:14+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../doc/docs/arch/index.rst:19
msgid "Design and Architecture"
msgstr "设计和架构"

#: ../../doc/docs/arch/index.rst:21
msgid ""
"This document is intended for developers who want to understand the "
"architecture of Apache TVM and/or actively develop on the project. This "
"page is organized as follows:"
msgstr "本文档旨在为希望了解 Apache TVM 架构的开发者，以及积极参与该项目开发的人员提供参考。页面内容组织如下："

#: ../../doc/docs/arch/index.rst:24
msgid ""
"The `Overall Flow`_ gives an overview of the steps that TVM takes to turn"
" a high level description of a model into a deployable module. To get "
"started, please read this section first."
msgstr "`Overall Flow`_ 部分概述了 TVM 将模型的高级描述转化为可部署模块所采取的步骤。要开始使用，请首先阅读本节"

#: ../../doc/docs/arch/index.rst:26
msgid ""
"Brief introduction to the key components of the TVM stack. Feel free to "
"also check out the :ref:`TensorIR Deep Dive <tensor-ir-deep-dive>` and "
":ref:`Relax Deep Dive <relax-deep-dive>` for more details about the two "
"major components in the TVM stack."
msgstr ""
"TVM 堆栈的关键组件简介。您也可以参考 :ref:`TensorIR 深入解析 <tensor-ir-deep-dive>` 和 "
":ref:`Relax 深入解析 <relax-deep-dive>`，以了解更多关于 TVM 堆栈中两个主要组件的详细信息。"

#: ../../doc/docs/arch/index.rst:29
msgid ""
"This guide provides a few complementary views of the architecture. First,"
" we review a single end-to-end compilation flow and discuss the key data "
"structures and the transformations. This runtime-based view focuses on "
"the interactions of each components when running the compiler. Then we "
"will review the logical modules of the codebase and their relationship. "
"This part provides a static overarching view of the design."
msgstr "本指南提供了对架构的几种补充视角。首先回顾单一的端到端的编译流程，并讨论关键的数据结构及其转换。这种基于运行时的观点着重于编译器运行时各组件之间的交互作用。接下来，将审视代码库的逻辑模块及其相互关系。这部分提供了静态的、全面的设计概览。"

#: ../../doc/docs/arch/index.rst:35
msgid "Overall Flow"
msgstr "整体流程"

#: ../../doc/docs/arch/index.rst:37
msgid ""
"In this guide, we will study an example compilation flow in the compiler."
" The figure below shows the flow. At a high-level, it contains several "
"steps:"
msgstr "在本指南中，将研究编译器中的编译流程示例。下图展示了该流程。从高层次来看，它包含几个步骤："

#: ../../doc/docs/arch/index.rst:39
msgid ""
"**Model Creation**: Create the IRModule to be optimized and compiled, "
"which contains a collection of functions that internally represent the "
"model. Users can manually construct IRModule via NNModule, TVMScript, or "
"import a pre-trained model from from Relax frontend."
msgstr ""
"**模型创建**：构建待优化和编译的 IRModule，该模块包含一系列函数集合，这些函数在内部表示“模型”。用户可以通过 "
"NNModule、TVMScript 手动构建 IRModule，或者从 Relax 前端导入预训练模型。"

#: ../../doc/docs/arch/index.rst:41
msgid ""
"**Transformation**: The compiler transforms an IRModule to another "
"functionally equivalent or approximately equivalent(e.g. in the case of "
"quantization) IRModule. Many of the transformations are target (backend) "
"independent. We also allow target to affect the configuration of the "
"transformation pipeline."
msgstr ""
"**变换**：编译器将 IRModule 变换为另一个功能上等效或近似等效（例如，在量化的情况下）的 "
"IRModule。许多变换是针对目标（target 后端）独立的。还允许目标影响变换管道的配置。"

#: ../../doc/docs/arch/index.rst:44
msgid ""
"**Target Translation**: The compiler translates(codegen) the IRModule to "
"an executable format specified by the target. The target translation "
"result is encapsulated as a `runtime.Module` that can be exported, "
"loaded, and executed on the target runtime environment."
msgstr ""
"**目标翻译**：编译器将 IRModule 编译（codegen）成由目标(target)指定的可执行格式。目标翻译的结果被封装为 "
"`runtime.Module`，这个模块可以被导出、加载并在目标运行时环境中执行。"

#: ../../doc/docs/arch/index.rst:46
msgid ""
"**Runtime Execution**: the user loads back a `runtime.Module` and runs "
"the compiled functions in the supported runtime environment."
msgstr "**运行时执行**：用户重新加载 `runtime.Module`，并在支持的运行时环境中运行编译好的函数。"

#: ../../doc/docs/arch/index.rst:55
msgid "Key data structures"
msgstr "关键数据结构"

#: ../../doc/docs/arch/index.rst:57
msgid ""
"One of the best ways to design and understand a complex system is to "
"identify the key data structures and APIs that manipulate (transform) "
"these data structures. Once we identified the key data structures, we can"
" then breakdown a system into logical components that either define a "
"collection of key data structures or transformations among the data "
"structures."
msgstr ""
"设计并理解复杂系统的最佳方法之一是识别关键数据结构以及操作（变换）这些数据结构的 "
"API。一旦确定了关键数据结构，就可以将系统分解为逻辑组件，这些组件要么定义了一组关键数据结构，要么定义了在数据结构之间进行变换。"

#: ../../doc/docs/arch/index.rst:61
msgid ""
"**IRModule** is the primary data structure used across the entire stack. "
"An IRModule (intermediate representation module) contains a collection of"
" functions. Currently, we support two primary variants of functions."
msgstr ""
"**IRModule** "
"是在整个堆栈中广泛使用的主要数据结构。IRModule（中间表示模块）包含了一系列函数的集合。目前，支持两种主要形式的函数变体。"

#: ../../doc/docs/arch/index.rst:64
msgid ""
"**relax::Function** is a high-level functional program representation. A "
"relax.Function represents high-level graph structure, usually corresponds"
" to an end-to-end model or a sub-graph of the overall model. You can view"
" a relax.Function as a computational graph with additional support for "
"control-flow, and complex data structures."
msgstr ""
"**relax::Function** 是一种高级的函数式程序表示。relax.Function "
"代表高级的计算图结构，通常对应于端到端的模型或者整个模型的子图。你可以将 relax.Function "
"视为计算图，它额外支持控制流和复杂的数据结构。"

#: ../../doc/docs/arch/index.rst:67
msgid ""
"**tir::PrimFunc** is a low-level program representation that contains "
"elements including loop-nest choices, multi-dimensional load/store, "
"threading, and vector/tensor instructions. It is usually used to "
"represent an operator program that executes a (possibly-fused) layer in a"
" model."
msgstr ""
"**tir::PrimFunc** "
"是一种低级程序表示，它包含了循环嵌套选择、多维加载/存储、线程处理以及向量/张量指令等元素。这种表示通常用于描述执行模型中（可能是融合的）层的算子程序。"

#: ../../doc/docs/arch/index.rst:70
msgid ""
"During the compilation and transformation, all relax operators are "
"lowered to ``tir::PrimFunc`` or ``TVM PackedFunc``, which can be executed"
" directly on the target device, while the calls to relax operators are "
"lowered to calls to low-level functions (e.g. ``R.call_tir`` or "
"``R.call_dps``)."
msgstr ""
"在编译和变换过程中，所有 relax 算子都被“降级”为可以直接在目标设备上执行的 ``tir::PrimFunc`` 或 ``TVM "
"PackedFunc``，而对 relax 算子的调用则被降级为对低级函数（例如 ``R.call_tir`` 或 ``R.call_dps`` "
"）的调用。"

#: ../../doc/docs/arch/index.rst:74
msgid "Transformations"
msgstr "变换"

#: ../../doc/docs/arch/index.rst:76
msgid ""
"Now that we have covered the key data structures, let us talk about the "
"transformations. Each transformation could serve one of the following "
"purposes:"
msgstr "既然已经介绍了关键的数据结构，接下来让讨论一下“变换”。每一种变换都可能服务于以下目的之一："

#: ../../doc/docs/arch/index.rst:78
msgid ""
"optimization: transform a program to an equivalent, possibly more "
"optimized version."
msgstr "优化：将程序变换成等价的，可能更加优化的版本。"

#: ../../doc/docs/arch/index.rst:79
msgid ""
"lowering: transform a program to a lower-level representation that is "
"closer to the target."
msgstr "降级：将程序变换为更接近目标的低级表示。"

#: ../../doc/docs/arch/index.rst:82
msgid "relax transformations"
msgstr "relax 变换"

#: ../../doc/docs/arch/index.rst:83
msgid ""
"relax transformations contain a collection of passes that apply to relax "
"functions. The optimizations include common graph-level optimizations "
"such as constant folding and dead-code elimination for operators, and "
"backend-specific optimizations such as library dispatch."
msgstr ""
"relax 变换包含了一组应用于 relax "
"函数的传递。这些优化包括常见的计算图级别优化，例如常量折叠和算子的死代码消除，以及特定于后端的优化，如库调度。"

#: ../../doc/docs/arch/index.rst:87
msgid "tir transformations"
msgstr "tir 变换"

#: ../../doc/docs/arch/index.rst:88
msgid ""
"tir transformations contain a collection of passes that apply to tir "
"functions. There are two major types of transformations:"
msgstr "tir 转换包含一系列适用于 tir 函数的变换。主要有两种类型的变换："

#: ../../doc/docs/arch/index.rst:90
msgid ""
"**TensorIR schedule**: TensorIR schedules are designed to optimize the "
"TensorIR functions for a specific target, with user-guided instructions "
"and control how the target code is generated. For CPU targets, TIR "
"PrimFunc can generate valid code and execute on the target device without"
" schedule but with very-low performance. However, for GPU targets, the "
"schedule is essential for generating valid code with thread bindings. For"
" more details, please refer to the :ref:`TensorIR Transformation <tir-"
"transform>` section. Additionally, we provides ``MetaSchedule`` to "
"automate the search of TensorIR schedule."
msgstr ""
"**TensorIR 调度**：TensorIR 调度旨在优化特定目标的 TensorIR 函数，通过用户指导的指令控制目标代码的生成方式。对于 "
"CPU 目标，TIR PrimFunc 可以生成有效的代码并在目标设备上执行，无需调度但性能非常低。然而，对于 GPU "
"目标来说，调度对于生成带有线程绑定的有效代码至关重要。更多详情，请参阅： :ref:`TensorIR 变换 <tir-transform>` "
"部分。此外，也提供了 ``MetaSchedule`` 来自动化寻找 TensorIR 调度。"

#: ../../doc/docs/arch/index.rst:94
msgid ""
"**Lowering Passes**: These passes usually perform after the schedule is "
"applied, transforming a TIR PrimFunc into another functionally equivalent"
" PrimFunc, but closer to the target-specific representation. For example,"
" there are passes to flatten multi-dimensional access to one-dimensional "
"pointer access, to expand the intrinsics into target-specific ones, and "
"to decorate the function entry to meet the runtime calling convention."
msgstr ""
"**降低阶段**：这些阶段通常在调度应用后执行，将 TIR PrimFunc 变换为另一个功能上等价的 "
"PrimFunc，但更接近目标特定的表示形式。例如，有些阶段会将多维访问展平成一维指针访问，将 intrinsics "
"扩展为目标特定的函数，并装饰函数入口点以符合运行时调用约定。"

#: ../../doc/docs/arch/index.rst:98
msgid ""
"Many low-level optimizations can be handled in the target phase by the "
"LLVM, CUDA C, and other target compilers. As a result, we leave low-level"
" optimizations such as register allocation"
msgstr "许多低级优化可以在目标阶段由 LLVM、CUDA C 以及其他目标编译器处理。因此，将诸如寄存器分配之类的低级优化留给它们来处理。"

#: ../../doc/docs/arch/index.rst:99
msgid ""
"to the downstream compilers and only focus on optimizations that are not "
"covered by them."
msgstr "对于下游编译器而言，仅专注于那些未被它们覆盖的优化。"

#: ../../doc/docs/arch/index.rst:102
msgid "cross-level transformations"
msgstr "跨层次变换"

#: ../../doc/docs/arch/index.rst:103
msgid ""
"Apache TVM brings a unity strategy to optimize the end-to-end models. As "
"the IRModule includes both relax and tir functions, the cross-level "
"transformations are designed to mutate the IRModule by applying different"
" transformations to these two types of functions."
msgstr ""
"Apache TVM 采用一种统一策略来优化端到端模型。由于 IRModule 同时包含 relax 和 tir "
"函数，因此跨层次的变换设计旨在通过对这两种类型函数应用不同的变换来改变 IRModule。"

#: ../../doc/docs/arch/index.rst:106
msgid ""
"For example, ``relax.LegalizeOps`` pass mutates the IRModule by lowering "
"relax operators, add corresponding TIR PrimFunc into the IRModule, and "
"replace the relax operators with calls to the lowered TIR PrimFunc. "
"Another example is operator fusion pipeline in relax (including "
"``relax.FuseOps`` and ``relax.FuseTIR``), which fuse multiple consecutive"
" tensor operations into one. Different from the previous implementations,"
" relax fusion pipeline analyzes the pattern of TIR functions and detects "
"the best fusion rules automatically rather than human-defined operator "
"fusion patterns."
msgstr ""
"例如，``relax.LegalizeOps`` 传递通过降低 relax 算子，向 IRModule 中添加相应的 TIR "
"PrimFunc，并且将 relax 算子替换为对降低后的 TIR PrimFunc 的调用。另一个例子是 relax 中的算子融合管道（包括 "
"``relax.FuseOps`` 和 ``relax.FuseTIR``），它将多个连续的张量运算融合为一个。与之前的实现不同，relax "
"融合管道分析 TIR 函数的模式，并自动检测最佳的融合规则，而不是由人为定义的算子融合模式。"

#: ../../doc/docs/arch/index.rst:112
msgid "Target Translation"
msgstr "目标翻译"

#: ../../doc/docs/arch/index.rst:114
#, fuzzy
msgid ""
"The target translation phase transforms an IRModule to the corresponding "
"target executable format. For backends such as x86 and ARM, we use the "
"LLVM IRBuilder to build in-memory LLVM IR. We can also generate source-"
"level languages such as CUDA C and OpenCL. Finally, we support direct "
"translations of a Relax function (sub-graph) to specific targets via "
"external code generators. It is important that the final code generation "
"phase is as lightweight as possible. Vast majority of transformations and"
" lowering should be performed before the target translation phase."
msgstr ""
"目标翻译阶段将 IRModule 变换成对应的“目标可执行格式”。对于诸如 x86 和 ARM 这样的后端，使用 LLVM IRBuilder "
"来构建内存中的LLVM IR。还可以生成源代码级别的语言，例如 CUDA C 和 OpenCL。最后，支持通过外部代码生成器直接将 Relay "
"函数（子图）翻译成特定目标。确保最终的代码生成阶段尽可能轻量级是非常重要的。大部分变换和降低操作应该在目标翻译阶段之前完成。"

#: ../../doc/docs/arch/index.rst:121
msgid ""
"We also provide a Target structure to specify the compilation target. The"
" transformations before the target translation phase can also be affected"
" by the target — for example, a target's vector length would change the "
"vectorization behavior."
msgstr "还提供了目标结构来指定编译目标。在目标翻译阶段之前的变换也可能受到目标的影响——例如，目标的向量长度会改变“向量化行为”。"

#: ../../doc/docs/arch/index.rst:127
msgid "Runtime Execution"
msgstr "运行时执行"

#: ../../doc/docs/arch/index.rst:129
msgid ""
"The main goal of TVM's runtime is to provide a minimal API for loading "
"and executing the compiled artifact in a language of their choice, "
"including Python, C++, Rust, Go, Java, and JavaScript. The code snippet "
"below shows such an example in Python:"
msgstr ""
"TVM 运行时的主要目标是为加载和执行用户所选语言的编译后产物提供最简化的 API，这些语言包括 Python、C++、Rust、Go、Java "
"以及 JavaScript。以下代码片段展示了在 Python 中的例子："

#: ../../doc/docs/arch/index.rst:142
msgid ""
":py:class:`tvm.runtime.Module` encapsulates the result of compilation. A "
"runtime.Module contains a GetFunction method to obtain PackedFuncs by "
"name."
msgstr ""
":py:class:`tvm.runtime.Module` 封装了编译的结果。`runtime.Module` 包含 `GetFunction`"
" 方法，通过名称获取 PackedFuncs。"

#: ../../doc/docs/arch/index.rst:144
msgid ""
":py:class:`tvm.runtime.PackedFunc` is a type-erased function interface "
"for both the generated functions. A runtime.PackedFunc can take arguments"
" and return values with the following types: POD types(int, float), "
"string, runtime.PackedFunc, runtime.Module, runtime.NDArray, and other "
"sub-classes of runtime.Object."
msgstr ""
":py:class:`tvm.runtime.PackedFunc` 是类型擦除的函数接口，适用于生成的函数。runtime.PackedFunc"
" 可以接受以下类型的参数和返回值：POD 类型（int, "
"float）、字符串、runtime.PackedFunc、runtime.Module、runtime.NDArray，以及其他 "
"runtime.Object 的子类。"

#: ../../doc/docs/arch/index.rst:147
msgid ""
":py:class:`tvm.runtime.Module` and :py:class:`tvm.runtime.PackedFunc` are"
" powerful mechanisms to modularize the runtime. For example, to get the "
"above `addone` function on CUDA, we can use LLVM to generate the host-"
"side code to compute the launching parameters(e.g. size of the thread "
"groups) and then call into another PackedFunc from a CUDAModule that is "
"backed by the CUDA driver API. The same mechanism can be used for OpenCL "
"kernels."
msgstr ""
":py:class:`tvm.runtime.Module` 和 :py:class:`tvm.runtime.PackedFunc` "
"是模块化运行时的有力机制。例如，要在 CUDA 上获取上述的 `addone` 函数，可以使用 LLVM "
"来生成主机端代码，以计算启动参数（例如线程组的大小），然后调用另一个由 CUDA 驱动 API 支持的 CUDAModule 中的 "
"PackedFunc。同样的机制也可以用于 OpenCL 内核。"

#: ../../doc/docs/arch/index.rst:149
msgid ""
"The above example only deals with a simple `addone` function. The code "
"snippet below gives an example of an end-to-end model execution using the"
" same interface:"
msgstr "上述例子仅处理了简单的 `addone` 函数。下面的代码片段展示了使用相同接口进行端到端模型执行的示例："

#: ../../doc/docs/arch/index.rst:166
msgid ""
"The main take away is that runtime.Module and runtime.PackedFunc are "
"sufficient to encapsulate both operator level programs (such as addone), "
"as well as the end-to-end models."
msgstr "主要的理解是，runtime.Module 和 runtime.PackedFunc 足以封装算子级别的程序（例如 addone）以及端到端的模型。"

#: ../../doc/docs/arch/index.rst:169
msgid "Summary and Discussions"
msgstr "总结与讨论"

#: ../../doc/docs/arch/index.rst:171
msgid "In summary, the key data structures in the compilation flows are:"
msgstr "总的来说，编译流程中的关键数据结构包括："

#: ../../doc/docs/arch/index.rst:173
#, fuzzy
msgid "IRModule: contains relax.Function and tir.PrimFunc"
msgstr "IRModule：包含 relay.Function 和 tir.PrimFunc"

#: ../../doc/docs/arch/index.rst:174
msgid "runtime.Module: contains runtime.PackedFunc"
msgstr "runtime.Module: 包含 runtime.PackedFunc"

#: ../../doc/docs/arch/index.rst:176
msgid ""
"Most parts of the compilation are transformations among the key data "
"structures."
msgstr "该编译的大部分内容涉及关键数据结构之间的变换。"

#: ../../doc/docs/arch/index.rst:178
#, fuzzy
msgid ""
"relax/transform and tir/transform are determinstic rule-based "
"transformations"
msgstr "relay/transform 和 tir/transform 是基于确定性规则的变换。"

#: ../../doc/docs/arch/index.rst:179
#, fuzzy
msgid "meta-schedule contains the search-based transformations"
msgstr "auto_scheduler和 autotvm 包含了基于搜索的变换技术。"

#: ../../doc/docs/arch/index.rst:181
msgid ""
"Finally, the compilation flow example is only a typical use-case of the "
"TVM stack. We expose these key data structures and transformations to "
"python and C++ APIs. As a result, you can use TVM just like the way you "
"use numpy, except that the data structure of interest changes from the "
"numpy.ndarray to tvm.IRModule. Here are some example use-cases:"
msgstr ""
"最后，提供的编译流程示例仅是 TVM 堆栈的典型使用案例之一。将这些关键的数据结构和变换暴露给 Python 和 C++ 的 API "
"接口。因此，您可以像使用 NumPy 一样使用TVM，只不过关注的不再是 numpy.ndarray 数据结构，而是 "
"tvm.IRModule。以下是一些示例用例："

#: ../../doc/docs/arch/index.rst:185
msgid "Directly construct IRModule using the python API."
msgstr "直接使用 Python API 构建 IRModule。"

#: ../../doc/docs/arch/index.rst:186
msgid "Compose a custom set of transformations(e.g. customize quantization)."
msgstr "编写一组自定义的变换（例如，定制量化）。"

#: ../../doc/docs/arch/index.rst:187
msgid "Manipulate the IR directly using TVM's python API."
msgstr "使用 TVM 的 Python API 直接操作 IR。"

#: ../../doc/docs/arch/index.rst:191
msgid "tvm/support"
msgstr ""

#: ../../doc/docs/arch/index.rst:192
msgid ""
"The support module contains the most common utilities for the "
"infrastructure, such as generic arena allocator, socket, and logging."
msgstr "支持模块包含基础设施中最常见的实用工具，例如通用 arena 分配器、套接字和日志记录。"

#: ../../doc/docs/arch/index.rst:196
msgid "tvm/runtime"
msgstr ""

#: ../../doc/docs/arch/index.rst:198
msgid ""
"The runtime serves as the foundation of the TVM stack. It provides the "
"mechanism to load and execute compiled artifacts. The runtime defines a "
"stable standard set of C APIs to interface with frontend languages such "
"as Python and Rust."
msgstr ""
"运行时作为 TVM 栈的基础，它提供了加载和执行编译工件的机制。运行时定义了一套稳定的标准 C API 集合，以与前端语言（如 Python 和 "
"Rust）进行接口交互。"

#: ../../doc/docs/arch/index.rst:201
#, fuzzy
msgid ""
"`runtime::Object` is one of the primary data structures in TVM runtime "
"besides the `ffi::Function`. It is a reference-counted base class with a "
"type index to support runtime type checking and downcasting. The object "
"system allows the developer to introduce new data structures to the "
"runtime, such as Array, Map, and new IR data structures."
msgstr ""
"`runtime::Object` 是 TVM 运行时中的主要数据结构之一，仅次于 "
"`runtime::PackedFunc`。它是一个引用计数的基类，带有类型索引以支持运行时类型检查和向下转型(downcasting)。这个对象系统允许开发者向运行时引入新的数据结构，例如数组、映射以及新的中间表示（IR）数据结构。"

#: ../../doc/docs/arch/index.rst:205
msgid ""
"Besides deployment use-cases, the compiler itself also makes heavy use of"
" TVM's runtime mechanism. All of the IR data structures are subclasses of"
" `runtime::Object`, as a result, they can be directly accessed and "
"manipulated from the Python frontend. We use the PackedFunc mechanism to "
"expose various APIs to the frontend."
msgstr ""
"除了部署用例，编译器本身也大量利用了 TVM 的运行时机制。所有的中间表示(IR)数据结构都是 `runtime::Object` "
"的子类，因此它们可以直接从 Python 前端访问和操作。使用 PackedFunc 机制向前端暴露各种 API。"

#: ../../doc/docs/arch/index.rst:209
msgid ""
"Runtime support for different hardware backends are defined in "
"subdirectories of runtime(e.g. runtime/opencl). These hardware-specific "
"runtime modules define APIs for device memory allocation and device "
"function serialization."
msgstr ""
"不同硬件后端的运行时支持在“runtime”子目录下定义（例如：runtime/opencl）。这些特定于硬件的运行时模块定义了设备内存分配和设备函数序列化的"
" API。"

#: ../../doc/docs/arch/index.rst:212
msgid ""
"`runtime/rpc` implements an RPC support for PackedFunc. We can use the "
"RPC mechanism to send a cross-compiled library to a remote device and "
"benchmark the execution performance. The rpc infrastructure enables data "
"collection from a wide range of hardware backends for learning-based "
"optimizations."
msgstr ""
"`runtime/rpc` 实现了对 PackedFunc 的 RPC 支持。可以利用这一 RPC "
"机制将跨平台编译的库发送到远程设备，并对执行性能进行基准测试。该 RPC 基础设施能够从广泛的硬件后端收集数据，以支持基于学习的优化。"

#: ../../doc/docs/arch/index.rst:230
msgid "tvm/node"
msgstr ""

#: ../../doc/docs/arch/index.rst:231
msgid ""
"The node module adds additional features on top of the `runtime::Object` "
"for IR data structures. The main features include reflection, "
"serialization, structural equivalence, and hashing."
msgstr "这个节点模块在 `runtime::Object` 的基础上为 IR 数据结构增加了额外的功能。主要特性包括反射、序列化、结构等价性以及哈希处理。"

#: ../../doc/docs/arch/index.rst:234
msgid ""
"Thanks to the node module, we can directly access any field of the TVM's "
"IRNode by their name in Python."
msgstr "由于节点模块的存在，我们可以直接通过名称在 Python 中访问 TVM 的 IRNode 的任何字段。"

#: ../../doc/docs/arch/index.rst:244
msgid ""
"We can also serialize arbitrary IR node into a JSON format, and load them"
" back. The ability to save/store, and inspect an IR node provides a "
"foundation for making the compiler more accessible."
msgstr "还可以序列化任意中间表示（IR）节点为 JSON 格式，并能将其加载回来。保存、存储和检查 IR 节点的能力为使编译器更加易于访问提供了基础。"

#: ../../doc/docs/arch/index.rst:248
msgid "tvm/ir"
msgstr ""

#: ../../doc/docs/arch/index.rst:249
#, fuzzy
msgid ""
"The `tvm/ir` folder contains the unified data structure and interfaces "
"across for all IR function variants. The components in `tvm/ir` are "
"shared by `tvm/relax` and `tvm/tir`, notable ones include"
msgstr ""
"`tvm/ir` 文件夹包含了所有 IR 函数变体的统一数据结构和接口。`tvm/ir` 中的组件被 `tvm/relay` 和 "
"`tvm/tir` 共享，其中显著的包括"

#: ../../doc/docs/arch/index.rst:252
msgid "IRModule"
msgstr ""

#: ../../doc/docs/arch/index.rst:253
msgid "Type"
msgstr ""

#: ../../doc/docs/arch/index.rst:254
msgid "PassContext and Pass"
msgstr "PassContext 和 Pass"

#: ../../doc/docs/arch/index.rst:255
msgid "Op"
msgstr ""

#: ../../doc/docs/arch/index.rst:257
#, fuzzy
msgid ""
"Different variants of functions(e.g. relax.Function and tir.PrimFunc) can"
" co-exist in an IRModule. While these variants may not have the same "
"content representation, they use the same data structure to represent "
"types. As a consequence, we use the same data structure to represent "
"function (type) signatures of these variants. The unified type system "
"allows one function variant to call another function once we clearly "
"define the calling convention. This opens doors for future cross-"
"function-variant optimizations."
msgstr ""
"在 IRModule 中，不同的函数变体（例如 relay.Function 和 "
"tir.PrimFunc）可以共存。尽管这些变体的“内容表示”可能不同，但它们使用相同的数据结构来表示类型。因此，采用同一数据结构来表示这些变体的函数（类型）签名。统一的类型系统允许一种函数变体在明确了调用约定后调用另一种函数。这为未来跨函数变体的优化开辟了道路。"

#: ../../doc/docs/arch/index.rst:263
msgid ""
"We also provide a unified PassContext for configuring the pass behavior, "
"and common composite passes to execute a pass pipeline. The following "
"code snippet gives an example of PassContext configuration."
msgstr ""
"还提供了统一的 PassContext 来配置 pass 行为，并提供了常见的复合 pass 来执行 pass 管道。下面的代码片段展示了 "
"PassContext 配置的示例。"

#: ../../doc/docs/arch/index.rst:273
msgid ""
"Op is the common class to represent all system-defined primitive "
"operator/intrinsics. Developers can register new Ops as well as their "
"additional attributes(e.g. whether the Op is elementwise) to the system."
msgstr ""
"Op 是用于表示所有系统定义的 primitive operator/intrinsics 的通用类。开发者可以向系统中注册新的 Op "
"以及它们的附加属性（例如，Op 是否为逐元素运算）。"

#: ../../doc/docs/arch/index.rst:283
msgid "tvm/target"
msgstr ""

#: ../../doc/docs/arch/index.rst:284
msgid ""
"The target module contains all the code generators that translate an "
"IRModule to a target runtime.Module. It also provides a common `Target` "
"class that describes the target."
msgstr "目标模块包含所有将 IRModule 变换为目标 runtime.Module 的代码生成器。它还提供了通用的 Target 类，用于描述目标。"

#: ../../doc/docs/arch/index.rst:290
msgid ""
"The compilation pipeline can be customized according to the target by "
"querying the attribute information in the target and builtin information "
"registered to each target id(cuda, opencl)."
msgstr "根据目标的不同，编译流水线可以进行定制化设置。这可以通过“查询目标中的属性信息以及每个目标ID（如CUDA、OpenCL）注册的内置信息”来实现。"

#: ../../doc/docs/arch/index.rst:299
msgid "tvm/relax"
msgstr ""

#: ../../doc/docs/arch/index.rst:301
msgid ""
"Relax is the high-level IR used to represent the computational graph of a"
" model. Various optimizations are defined in ``relax.transform``. Note "
"that Relax usually works closely the the TensorIR IRModule, most of the "
"transformations are applied on the both Relax and TensorIR functions in "
"the IRModule. Please refer to the :ref:`Relax Deep Dive <relax-deep-"
"dive>` for more details."
msgstr ""
"Relax 是一种高级的中间表示（IR），用于表达计算图。在 ``relax.transform`` "
"中定义了各种优化技术。需要注意的是，Relax 通常与 TensorIR 的 IRModule 紧密合作，大多数变换同时应用于 Relax 和 "
"TensorIR 的功能上。更多详细信息请参见 :ref:`Relax 深入探讨 <relax-deep-dive>`。"

#: ../../doc/docs/arch/index.rst:306
msgid "tvm/tir"
msgstr ""

#: ../../doc/docs/arch/index.rst:308
msgid ""
"TIR contains the definition of the low-level program representations. We "
"use `tir::PrimFunc` to represent functions that can be transformed by TIR"
" passes. Besides the IR data structures, the tir module also includes:"
msgstr ""
"TIR 包含了低级程序表示的定义。使用 `tir::PrimFunc` 来表示可以通过 TIR 变换的函数。除了中间表示的数据结构，tir "
"模块还包括了："

#: ../../doc/docs/arch/index.rst:311
msgid ""
"A set of schedule primitives to control the generated code in "
"``tir/schedule``."
msgstr "在 ``tir/schedule`` 中，一组用于控制生成代码的调度原语。"

#: ../../doc/docs/arch/index.rst:312
msgid "A set of builtin intrinsics in ``tir/tensor_intrin``."
msgstr "在 ``tir/tensor_intrin`` 中，有一组内建的 intrinsics。"

#: ../../doc/docs/arch/index.rst:313
msgid "A set of analysis passes to analyze the TIR functions in ``tir/analysis``."
msgstr "一组分析通过用于在 ``tir/analysis`` 中分析 TIR 功能。"

#: ../../doc/docs/arch/index.rst:314
msgid ""
"A set of transformation passes to lower or optimize the TIR functions in "
"``tir/transform``."
msgstr "在 ``tir/transform`` 中，一系列变换被用于降低或优化 TIR 函数。"

#: ../../doc/docs/arch/index.rst:316
msgid ""
"Please refer to the :ref:`TensorIR Deep Dive <tensor-ir-deep-dive>` for "
"more details."
msgstr "请参阅 :ref:`TensorIR 深度解析 <tensor-ir-deep-dive>` 以获取更多详细信息。"

#: ../../doc/docs/arch/index.rst:319
msgid "tvm/arith"
msgstr ""

#: ../../doc/docs/arch/index.rst:321
msgid ""
"This module is closely tied to the TIR. One of the key problems in the "
"low-level code generation is the analysis of the indices' arithmetic "
"properties — the positiveness, variable bound, and the integer set that "
"describes the iterator space. arith module provides a collection of tools"
" that do (primarily integer) analysis. A TIR pass can use these analyses "
"to simplify and optimize the code."
msgstr ""
"这个模块与中间表示（TIR）密切相关。在低级代码生成中的关键问题是分析索引的算术属性——包括正性、变量界限以及描述迭代器空间的整数集。arith "
"模块提供了一套工具，主要进行整数分析。TIR 阶段可以使用这些分析来简化和优化代码。"

#: ../../doc/docs/arch/index.rst:326
msgid "tvm/te and tvm/topi"
msgstr ""

#: ../../doc/docs/arch/index.rst:328
msgid ""
"TE stands for Tensor Expression. TE is a domain-specific language (DSL) "
"for describing tensor computations. Importantly, a tensor expression "
"itself is not a self-contained function that can be stored into IRModule."
" We can use ``te.create_prim_func`` to convert a tensor expression to a "
"``tir::PrimFunc`` and then integrate it into the IRModule."
msgstr ""
"TE 代表张量表达式。TE 是一种特定领域语言 (DSL)，用于描述张量计算。重要的是，张量表达式本身并不是可以存储到 IRModule "
"中的自包含函数。可以使用 ``te.create_prim_func`` 将张量表达式转换为 ``tir::PrimFunc``，然后将其集成到 "
"IRModule 中。"

#: ../../doc/docs/arch/index.rst:332
msgid ""
"While possible to construct operators directly via TIR or tensor "
"expressions (TE) for each use case it is tedious to do so. `topi` (Tensor"
" operator inventory) provides a set of pre-defined operators defined by "
"numpy and found in common deep learning workloads."
msgstr ""
"尽管可以通过 TIR 或张量表达式（TE）为每个用例直接构造算子，但这样做既繁琐又低效。`topi` （张量算子库）提供了一组由 numpy "
"定义且在常见深度学习工作负载中常见的预定义算子集。"

#: ../../doc/docs/arch/index.rst:336
msgid "tvm/meta_schedule"
msgstr ""

#: ../../doc/docs/arch/index.rst:338
msgid ""
"MetaSchedule is a system for automated search-based program optimization."
" It is designed to be a drop-in replacement for AutoTVM and "
"AutoScheduler, and can be used to optimize TensorIR schedules. Note that "
"MetaSchedule only works with static-shape workloads."
msgstr ""
"MetaSchedule 是基于自动化搜索的程序优化系统。它旨在作为 AutoTVM 和 AutoScheduler 的直接替代方案，可用于优化 "
"TensorIR 的调度。需要注意的是，MetaSchedule 仅适用于静态形状的工作负载。"

#: ../../doc/docs/arch/index.rst:342
msgid "tvm/dlight"
msgstr ""

#: ../../doc/docs/arch/index.rst:344
msgid ""
"DLight is a set of pre-defined, easy-to-use, and performant TIR "
"schedules. DLight aims:"
msgstr "DLight 是一套预先定义的、易于使用且性能优异的 TIR 调度方案。DLight 旨在："

#: ../../doc/docs/arch/index.rst:346
msgid "Fully support **dynamic shape workloads**."
msgstr "完全支持 **动态形状工作负载**。"

#: ../../doc/docs/arch/index.rst:347
msgid ""
"**Light weight**. DLight schedules provides tuning-free or (very few-"
"shots tuning) schedule with reasonable performance."
msgstr "**轻量**。DLight 调度器提供无需调优或仅需极少量（shots tuning）调优的调度方案，并保持合理的性能。"

#: ../../doc/docs/arch/index.rst:348
msgid ""
"**Robust**. DLight schedules are designed to be robust and general-"
"purpose for a single rule. And if the rule is not applicable, DLight not "
"raise any error and switch to the next rule automatically."
msgstr ""
"**稳健性**。DLight 调度旨在为单一规则提供稳健（鲁棒）且通用的调度，如果该规则不适用，DLight "
"不会引发任何错误，并会自动切换到下一条规则。"


# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-02-09 00:02+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:22
msgid "Bring Your Own Codegen To TVM"
msgstr "带你自己的 Codegen 到 TVM"

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:24
#, fuzzy
msgid ""
"As the number of hardware devices targeted by deep learning workloads "
"keeps increasing, the required knowledge for users to achieve high "
"performance on various devices keeps increasing as well. To free data "
"scientists from worrying about the performance when developing a new "
"model, hardware backend providers either provide libraries such as "
"DNNL(Intel OneDNN) or cuDNN with many commonly used deep learning "
"operators, or provide frameworks such as TensorRT to let users describe "
"their models in a certain way to achieve high performance. However, users"
" have to learn a new programming interface when they attempt to work on a"
" new library or device. As a result, the demand for a unified programming"
" interface becomes more and more important to 1) let all users and "
"hardware backend providers stand on the same page, and 2) provide a "
"feasible solution to allow specialized hardware or library to only "
"support widely used operators with extremely high performance, but "
"fallback unsupported operators to general devices like CPU/GPU."
msgstr ""
"随着深度学习工作负载针对的硬件设备数量不断增加，用户在各种设备上实现高性能所需的知识也在不断增加。为了让数据科学家在开发新模型时不再担心性能问题，硬件后端提供商要么提供"
" DNNL(Intel OneDNN) 或 cuDNN等库，其中包含许多常用的深度学习算子，要么提供 TensorRT "
"等框架，让用户以某种方式描述他们的模型，以实现高性能。然而，当用户尝试使用新的库或设备时，他们必须学习新的编程接口。因此，对统一编程接口的需求变得越来越重要，1)"
" "
"让所有用户和硬件后端提供者站在同一个页面上，2)提供一个可行的解决方案，允许专门的硬件或库只支持广泛使用的、具有极高性能的算子，而将不支持的算子退到像"
" CPU/GPU 这样的通用设备上。"

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:26
msgid ""
"In this developer guide, we demonstrate how you, as a hardware backend "
"provider, can easily implement your own codegen and register it as a "
"Relay backend compiler to support your hardware device/library. This "
"guide covers two types of codegen based on different graph "
"representations you need:"
msgstr ""
"在本开发指南中，将演示作为硬件后端提供者，如何轻松实现自己的代码生成，并将其注册为 Relay "
"后端编译器，以支持硬件设备/库。本指南根据你需要的不同 graph 表示涵盖了两种类型的代码："

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:28
msgid "**1. You want to generate C code.**"
msgstr "**1. 您需要生成 C 代码。**"

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:30
msgid ""
"If your hardware already has a well-optimized C/C++ library, such as "
"Intel CBLAS/MKL to CPU and NVIDIA CUBLAS to GPU, then this is what you "
"are looking for. Fortunately, C source code module is fully compatible "
"with TVM runtime module, which means the generated code could be compiled"
" by any C/C++ compiler with proper compilation flags, so the only task "
"you have is to implement a codegen that generates C code for subgraphs "
"and a C source module to integrate into TVM runtime module. We will "
"demonstrate how to implement a C code generator for your hardware in the "
"following section."
msgstr ""
"如果您的硬件已经有一个良好优化的 C/C++ 库，如 Intel CBLAS/MKL 到 CPU 和 NVIDIA CUBLAS 到 "
"GPU，那么这就是您要寻找的。幸运的是，C 源代码模块与 TVM 运行时模块完全兼容，这意味着生成的代码可以由任何具有适当编译标志的 C/C++ "
"编译器编译，因此您唯一的任务是实现一个代码生成器，为子图生成 C 代码，并实现一个 C source module 集成到 TVM "
"运行时模块中。将在下一节中演示如何为您的硬件实现一个 C 代码生成器。"

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:32
msgid "**2. You want to generate any other graph representations.**"
msgstr "**2. 希望生成任何其他 graph 表示。**"

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:34
msgid ""
"Your hardware may require other forms of graph representation, such as "
"JSON. In this case, you need to implement not only a codegen but also a "
"customized TVM runtime module to let TVM runtime know how this graph "
"representation should be executed. If you already have a complete graph "
"execution engine for your hardware, such as TensorRT for GPU, then this "
"is a solution you can consider."
msgstr ""
"您的硬件可能需要其他形式的 graph 表示，例如 JSON。在这种情况下，您不仅需要实现 codegen，还需要实现定制 TVM "
"运行时模块，以便让 TVM 运行时知道应该如何执行这个 graph 表示。如果您的硬件已经有了一个完整的 graph 执行引擎，比如 GPU 的 "
"tensort，那么这是一个可以考虑的解决方案。"

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:36
msgid ""
"After you finish the codegen and runtime, you can then let your customers"
" annotate their models with your customized tag to make use of them. The "
"tutorial for end-users to annotate and launch a specific codegen is "
"**here (TBA)**."
msgstr ""
"在您完成代码生成和运行时之后，您就可以让您的客户使用您的定制 tag 来注解他们的模型，以使用它们。最终用户注解和启动特定 codegen "
"的教程在这里(TBA)。"

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:40
msgid "Implement a C Codegen"
msgstr "实现 C Codegen"

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:42
msgid ""
"In this part, we demonstrate how to implement a codegen that generates C "
"code with pre-implemented operator functions. To simplify, our example "
"codegen does not depend on third-party libraries. Instead, we manually "
"implement two macros in C:"
msgstr ""
"在本部分中，将演示如何实现代码生成器，它生成带有预先实现的算子函数的 C 代码。为了简化，示例代码生成不依赖于第三方库。相反，我们在 C "
"中手动实现了两个宏："

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:63
msgid ""
"With the two macros, we can generate binary operators for 1-D and 2-D "
"tensors. For example, given a subgraph as follows. Assuming all inputs "
"are 2-D tensors with shape (10, 10)."
msgstr "利用这两个宏，我们可以生成一维和二维张量的二元算子。例如，给定如下的子图。假设所有输入都是形状为 ``(10,10)`` 的二维张量。"

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:77
msgid ""
"Our goal is to generate the following compilable code to execute the "
"subgraph:"
msgstr "我们的目标是生成以下可编译代码来执行子图："

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:132
msgid "Here we highlight the notes marked in the above code:"
msgstr "这里高亮了上面代码中标记的注解："

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:134
msgid ""
"**Note 1** is the function implementation for the three nodes in the "
"subgraph."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:136
msgid ""
"**Note 2** is a function to execute the subgraph by allocating "
"intermediate buffers and invoking corresponding functions."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:138
msgid ""
"**Note 3** is a TVM runtime compatible wrapper function. It accepts a "
"list of input tensors and one output tensor (the last argument), casts "
"them to the right data type, and invokes the subgraph function described "
"in Note 2. In addition, ``TVM_DLL_EXPORT_TYPED_FUNC`` is a TVM macro that"
" generates another function ``gcc_0`` with unified the function arguments"
" by packing all tensors to ``TVMArgs``. As a result, the TVM runtime can "
"directly invoke ``gcc_0`` to execute the subgraph without additional "
"efforts. With the above code generated, TVM is able to compile it along "
"with the rest parts of the graph and export a single library for "
"deployment."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:140
msgid ""
"In the rest of this section, we will implement a codegen step-by-step to "
"generate the above code. Your own codegen has to be located at "
"``src/relay/backend/contrib/<your-codegen-name>/``. In our example, we "
"name our codegen \"codegen_c\" and put it under "
"`/src/relay/backend/contrib/codegen_c/ "
"<https://github.com/apache/tvm/blob/main/src/relay/backend/contrib/codegen_c/codegen.cc>`_."
" Feel free to check this file for a complete implementation."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:142
msgid ""
"Specifically, we are going to implement two classes in this file and here"
" is their relationship:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:153
msgid ""
"When TVM backend finds a function (subgraph) in a Relay graph is "
"annotated with the registered compiler tag (``ccompiler`` in this "
"example), TVM backend invokes ``CSourceCodegen`` and passes the subgraph."
" ``CSourceCodegen``'s member function ``CreateCSourceModule`` will 1) "
"generate C code for the subgraph, and 2) wrap the generated C code to a C"
" source runtime module for TVM backend to compile and deploy. In "
"particular, the C code generation is transparent to the ``CodegenC`` "
"class because it provides many useful utilities to ease the code "
"generation implementation. The following sections will implement these "
"two classes in the bottom-up order."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:156
msgid "Implement CodegenC"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:158
msgid ""
"In ``src/relay/backend/contrib/codegen_c/codegen.cc``, we first create a "
"codegen class skeleton under the namespace of ``tvm.relay.contrib``:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:204
msgid ""
"The ``CodegenC`` class inherits two classes: ``ExprVisitor`` provides "
"abilities to traverse subgraphs and collects the required information and"
" generate subgraph functions such as ``gcc_0_``; ``CodegenCBase`` "
"provides abilities and utilities to generate wrapper functions such as "
"``gcc_0`` in the above example. As can be seen, we only need to implement"
" three functions in this codegen class to make it work."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:207
msgid "Code Generation for Operators"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:209
msgid ""
"We first implement ``VisitExpr_(const CallNode* call)``. This function "
"visits all call nodes when traversing the subgraph. Each call node "
"contains an operator that we want to offload to your hardware. As a "
"result, we need to generate the corresponding C code with correct "
"operators in topological order. We implement this function step-by-step "
"as follows."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:211
msgid "**1. Generate the function declaration**"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:213
msgid "Example Result: ``GCC_BINARY_OP_2D(gcc_0_0, *, 10, 10);``"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:215
msgid ""
"To generate the function declaration, as shown above, we need 1) a "
"function name (e.g., ``gcc_0_0``), 2) the type of operator (e.g., ``*``),"
" and 3) the input tensor shape (e.g., ``(10, 10)``). Fortunately, this "
"information can be obtained easily from ``CallNode``:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:248
msgid ""
"As can be seen, we push the generated code to class member variables "
"``func_decl_``. It means after we finish traversing the entire subgraph, "
"we have collected all required function declarations and the only thing "
"we need to do is having them compiled by GCC. The rest implementation of "
"``VisitExpr_(const CallNode* call)`` also follow this concept."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:250
msgid "**2. Generate the function call**"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:252
msgid "Example Result: ``gcc_0_0(buf_1, gcc_input3, out);``"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:254
msgid ""
"After generating the function declaration, we need to generate a function"
" call with proper inputs and outputs. To know which inputs or buffers we "
"should put when calling this function, we have to visit its arguments:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:272
msgid "Again, we want to highlight the notes in the above code:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:274
msgid ""
"**Note 1**: ``VisitExpr(call->args[i])`` is a recursive call to visit "
"arguments of the current function. An argument could be an output of "
"another node or an input tensor. In our example implementation, we make "
"sure every node updates a class variable ``out_`` before leaving the "
"visitor. Here is an illustration:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:285
msgid ""
"We can see in the above figure, class variable ``out_`` is empty before "
"visiting the argument node, and it was filled with the output buffer name"
" and size of ``arg_node``. As a result, when we finished visiting the "
"argument node, we know the proper input buffer we should put by looking "
"at ``out_``. You will find out how we update ``out_`` at the end of this "
"section as well as the next section."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:287
msgid ""
"**Note 2**: You may notice that we did not close the function call string"
" in this step. The current function call string looks like: "
"``gcc_0_0(buf_1, gcc_input3``. This is because we have not put the last "
"argument (i.e., the output) to this call. The output of a function call "
"could be either an allocated temporary buffer or the subgraph output "
"tensor. For simplify, in this example, we allocate an output buffer for "
"every call node (next step) and copy the result in the very last buffer "
"to the output tensor."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:289
msgid "**3. Generate the output buffer**"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:291
msgid "Example Result: ``float* buf_0 = (float*)malloc(4 * 100);``"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:293
msgid ""
"As mentioned in the previous step, in addition to the subgraph input and "
"output tensors, we may also need buffers to keep the intermediate "
"results. To generate the buffer, we extract the shape information to "
"determine the buffer type and size:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:316
msgid ""
"After we have allocated the output buffer, we can now close the function "
"call string and push the generated function call to a class variable "
"``ext_func_body``."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:323
msgid "**4. Update output buffer**"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:325
msgid ""
"To let the next node, which accepts the output of the current call node "
"as its input, know which buffer it should take, we need to update the "
"class variable ``out_`` before leaving this visit function:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:332
msgid ""
"Congratulations! we have finished the most difficult function in this "
"class. In the next two sections, we just need to make up some minor "
"missing parts in this function."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:335
msgid "Code Generation for Input Variables"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:337
msgid ""
"Recall that we collected the input buffer information by visiting the "
"arguments of a call node (2nd step in the previous section), and handled "
"the case when its argument is another call node (4th step). In this "
"section, we demonstrate how to handle other nodes by taking ``VarNode`` "
"as an example."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:339
msgid ""
"``VarNode`` represents input tensors in a model. The only but important "
"information it has is a name hint (e.g., ``data``, ``weight``, etc). When"
" visiting a ``VarNode``, we simply update class variable ``out_`` to pass"
" the name hint so that the descendant call nodes can generate the correct"
" function call."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:349
msgid ""
"Note that in this example we assume the subgraph we are offloading has "
"only call nodes and variable nodes. If your subgraphs contain other types"
" of nodes, such as ``TupleNode``, then you also need to visit them and "
"bypass the output buffer information."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:352
msgid "Code Emitting"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:354
msgid ""
"The final part in this codegen class is a ``JIT`` function that emits a C"
" function for the subgraph and uses the C code we just generated as the "
"function body. Remember, in addition to the subgraph function we "
"generated in the previous sections, we also need a wrapper function with "
"a unified argument for TVM runtime to invoke and pass data. Fortunately, "
"the base class we inherited already provides an implementation, "
"``JitImpl``, to generate the function. For example, we can invoke "
"``JitImpl`` as follows:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:364
msgid ""
"The above call will generate three functions (one from the TVM wrapper "
"macro):"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:366
msgid ""
"The subgraph function ``gcc_0_`` (with one more underline at the end of "
"the function name) with all C code we generated to execute a subgraph."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:368
msgid ""
"The wrapper function ``gcc_0__wrapper_`` with a list of ``DLTensor`` "
"arguments that casts data to the right type and invokes ``gcc_0_``."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:370
msgid ""
"The TVM runtime compatible function ``gcc_0`` with TVM unified function "
"arguments that unpacks TVM packed tensors and invokes "
"``gcc_0__wrapper_``."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:372
msgid ""
"Accordingly, the only thing we need in ``JIT`` implementation is passing "
"all subgraph function code we generated to ``JitImpl``:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:384
msgid ""
"All variables (``ext_func_id``, etc) we passed are class variables and "
"were filled when we traversed the subgraph."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:387
msgid "Implement CSourceCodegen"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:389
msgid ""
"Again, let's create a class skeleton and implement the required "
"functions. Note that it inherits ``CSourceModuleCodegenBase``"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:406
msgid "Implement GenCFunc"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:408
msgid ""
"``GenCFunc`` simply uses the ``CodegenC`` we just implemented to traverse"
" a Relay function (subgraph) and obtains the generated C code. The "
"builtin function ``GetExtSymbol`` retrieves a unique symbol name (e.g., "
"``gcc_0``) in the Relay function and we **must** use it as the C function"
" name, because this symbol is going to be used for DSO runtime lookup."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:424
msgid "Implement CreateCSourceModule"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:426
msgid ""
"This function creates a runtime module for the external library. In this "
"example, we create a CSourceModule that can be directly compiled and "
"linked together with a TVM generated DSOModule. After you have "
"implemented ``CodegenC``, implementing this function is relatively "
"straightforward:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:482
msgid "Register Your Codegen"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:484
msgid ""
"The last step is registering your codegen to TVM backend. We first "
"implement a simple function to invoke our codegen and generate a runtime "
"module."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:493
msgid "Finally, we register this function to TVM backend:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:499
msgid ""
"where ``ccompiler`` is a customized tag to let TVM know this is the "
"codegen it should use to generate and offload subgraphs when the subgraph"
" is annotated with ``ccompiler``."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:501
msgid ""
"Finally, a good practice is to set up a CMake configuration flag to "
"include your compiler only for your customers. We first create a cmake "
"file: ``cmake/modules/contrib/CODEGENC.cmake``:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:510
msgid ""
"So that users can configure whether to include your compiler when "
"configuring TVM using ``config.cmake``:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:518
msgid "Implement a Codegen for Your Representation"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:520
msgid ""
"Although we have demonstrated how to implement a C codegen, your hardware"
" may require other forms of graph representation, such as JSON. In this "
"case, you could modify ``CodegenC`` class we have implemented to generate"
" your own graph representation and implement a customized runtime module "
"to let TVM runtime know how this graph representation should be executed."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:522
msgid ""
"To simplify, we define a graph representation named \"ExampleJSON\" in "
"this guide. ExampleJSON does not mean the real JSON but just a simple "
"representation for graphs without a control flow. For example, assuming "
"we have the following subgraph named ``subgraph_0``:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:536
msgid "Then the ExampleJON of this subgraph looks like:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:549
msgid ""
"The ``input`` keyword declares an input tensor with its ID and shape; "
"while the other statements describes computations in ``<op> <output ID> "
"inputs: [input ID] shape: [shape]`` syntax."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:551
msgid ""
"In this section, our goal is to implement the following customized TVM "
"runtime module to execute ExampleJSON graphs."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:564
msgid ""
"**Note 1**: We will implement a customized codegen later to generate a "
"ExampleJSON code string by taking a subgraph."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:566
msgid ""
"**Note 2**: This line obtains a pointer to a function for creating the "
"customized runtime module. You can see that it takes subgraph code in "
"ExampleJSON format we just generated and initializes a runtime module."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:568
msgid ""
"In the following sections, we are going to introduce 1) how to implement "
"``ExampleJsonCodeGen`` and 2) how to implement and register "
"``examplejson_module_create``."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:571
msgid "Implement ExampleJsonCodeGen"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:573
msgid ""
"Similar to the C codegen, we also derive ``ExampleJsonCodeGen`` from "
"``ExprVisitor`` to make use of visitor patterns for subgraph traversing. "
"On the other hand, we do not have to inherit ``CodegenCBase`` because we "
"do not need TVM C++ wrappers. The codegen class is implemented as "
"follows:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:619
msgid ""
"**Note 1**: We again implement corresponding visitor functions to "
"generate ExampleJSON code and store it to a class variable ``code`` (we "
"skip the visitor function implementation in this example as their "
"concepts are basically the same as C codegen). After finished the graph "
"visiting, we should have an ExampleJSON graph in ``code``."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:621
msgid ""
"**Note 2**: We define an internal API ``gen`` to take a subgraph and "
"generate a ExampleJSON code. This API can be in an arbitrary name you "
"prefer."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:623
msgid ""
"The next step is to implement a customized runtime to make use of the "
"output of ``ExampleJsonCodeGen``."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:626
msgid "Implement a Customized Runtime"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:628
msgid ""
"In this section, we will implement a customized TVM runtime step-by-step "
"and register it to TVM runtime modules. The customized runtime should be "
"located at ``src/runtime/contrib/<your-runtime-name>/``. In our example, "
"we name our runtime \"example_ext_runtime\"."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:630
msgid ""
"Again, we first define a customized runtime class as follows. The class "
"has to be derived from TVM ``ModuleNode`` in order to be compatible with "
"other TVM runtime modules."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:686
msgid ""
"In particular, there are some functions derived from ``ModuleNode`` that "
"we must implement in ``ExampleJsonModule``:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:688
msgid ""
"Constructor: The constructor of this class should accept a subgraph (in "
"your representation), process and store it in any format you like. The "
"saved subgraph could be used by the following two functions."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:690
msgid ""
"``GetFunction``: This is the most important function in this class. When "
"TVM runtime wants to execute a subgraph with your compiler tag, TVM "
"runtime invokes this function from your customized runtime module. It "
"provides the function name as well as runtime arguments, and "
"``GetFunction`` should return a packed function implementation for TVM "
"runtime to execute."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:692
msgid ""
"``SaveToBinary`` and ``LoadFromBinary``: ``SaveToBinary`` serialize the "
"runtime module to a binary format for later deployment. This function "
"will be called by TVM when users use ``export_library`` API. On the other"
" hand, since we are now using our own graph representation, we have to "
"make sure that ``LoadFromBinary`` is able to construct the same runtime "
"module by taking the serialized binary generated by ``SaveToBinary``."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:694
msgid ""
"``GetSource`` (optional): If you would like to see the generated "
"ExampleJSON code, you can implement this function to dump it; otherwise "
"you can skip the implementation."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:696
msgid ""
"Other functions and class variables will be introduced along with the "
"implementation of above must-have functions."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:699
msgid "Implement Constructor"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:708
msgid ""
"Then, we implement ``ParseJson`` to parse a subgraph in ExampleJSON "
"format and construct a graph in memory for later usage. Since we do not "
"support subgraph with branches in this example, we simply use an array to"
" store every nodes in a subgraph in order."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:767
msgid ""
"**Note 1**: We use a class variable ``op_id_`` to map from subgraph node "
"ID to the operator name (e.g., ``add``) so that we can invoke the "
"corresponding operator function in runtime."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:769
msgid ""
"**Note 2**: We use a class variable ``graph_`` to map from subgraph name "
"to an array of nodes. ``GetFunction`` will query graph nodes by a "
"subgraph ID in runtime."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:771
msgid ""
"**Note 3**: We use a class variable `data_entry_` to map from a subgraph "
"node ID to a tensor data placeholder. We will put inputs and outputs to "
"the corresponding data entry in runtime."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:774
msgid "Implement GetFunction"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:776
msgid ""
"After the construction, we should have the above class variables ready. "
"We then implement ``GetFunction`` to provide executable subgraph "
"functions to TVM runtime:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:822
msgid ""
"As can be seen, ``GetFunction`` is composed of three major parts. The "
"first part copies data from TVM runtime arguments to the corresponding "
"data entries we assigned in the constructor. The second part executes the"
" subgraph with ``Run`` function (will implement later) and saves the "
"results to another data entry. The third part copies the results from the"
" output data entry back to the corresponding TVM runtime argument for "
"output."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:825
msgid "Implement Run"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:827
msgid ""
"Now let's implement ``Run`` function. This function accepts 1) a subgraph"
" ID, 2) a list of input data entry indexs, and 3) an output data entry "
"index."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:862
msgid ""
"``Run`` function mainly has two parts. The first part allocates a list of"
" ``TVMValue``, and maps corresponding data entry blocks. This will become"
" the arguments of our operator functions. The second part than invokes "
"our operator functions. Although we use the same C functions as the "
"previous example, you can replace ``Add``, ``Sub``, and ``Mul`` with your"
" own engine. You only need to make sure your engine stores the results to"
" the last argument so that they can be transferred back to TVM runtime."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:864
msgid ""
"With above functions implemented, our customized codegen and runtime can "
"now execute subgraphs. The last step is registering an API "
"(``examplejson_module_create``) to create this module:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:875
msgid "Implement SaveToBinary and LoadFromBinary"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:877
msgid ""
"So far we have implemented the main features of a customized runtime so "
"that it can be used as other TVM runtimes. However, when users want to "
"save the built runtime to a disk for deployment, TVM has no idea about "
"how to save it. This is the reason we want to implement ``SaveToBinary`` "
"and ``LoadFromBinary``, which tell TVM how should this customized runtime"
" be persist and restored."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:879
msgid ""
"We first implement ``SaveToBinary`` function to allow users to save this "
"module in disk."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:887
msgid ""
"We can find that this function is pretty simple. Recall that the only "
"argument we took in constructor is a subgraph representation, meaning "
"that we only need a subgraph representation to construct/recover this "
"customized runtime module. As a result, ``SaveToBinary`` simply writes "
"the subgraph to an output DMLC stream. That is, when users use "
"``export_library`` API to export the module, the customized module will "
"be an ExampleJSON stream of a subgraph."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:889
msgid ""
"Similarity, ``LoadFromBinary`` reads the subgraph stream and re-"
"constructs the customized runtime module:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:901
msgid ""
"We also need to register this function to enable the corresponding Python"
" API:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:908
msgid ""
"The above registration means when users call "
"``tvm.runtime.load_module(lib_path)`` API and the exported library has an"
" ExampleJSON stream, our ``LoadFromBinary`` will be invoked to create the"
" same customized runtime module."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:910
msgid ""
"In addition, if you want to support module creation directly from an "
"ExampleJSON file, you can also implement a simple function and register a"
" Python API as follows:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:933
msgid ""
"It means users can manually write/modify an ExampleJSON file, and use "
"Python API ``tvm.runtime.load_module(\"mysubgraph.examplejson\", "
"\"examplejson\")`` to construct a customized module."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:937
msgid "Summary"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:939
msgid "In summary, here is a checklist for you to refer:"
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:941
msgid ""
"A codegen class derived from ``ExprVisitor`` and ``CodegenCBase`` (only "
"for C codegen) with following functions."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:943
msgid "``VisitExpr_(const CallNode* call)`` to collect call node information."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:944
msgid "Other visitor functions you needed to collect subgraph information."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:945
msgid "``JIT`` to generate subgraph code."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:946
msgid "Register codegen."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:948
msgid "A function to create ``CSourceModule`` (for C codegen)."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:950
msgid ""
"A runtime module class derived from ``ModuleNode`` with following "
"functions (for your graph representation)."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:952
msgid "Constructor."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:953
msgid "``GetFunction`` to generate a TVM runtime compatible ``PackedFunc``."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:954
msgid "``Run`` to execute a subgraph."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:955
msgid "Register a runtime creation API."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:956
msgid ""
"``SaveToBinary`` and ``LoadFromBinary`` to serialize/deserialize "
"customized runtime module."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:957
msgid ""
"Register ``LoadFromBinary`` API to support "
"``tvm.runtime.load_module(your_module_lib_path)``."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:958
msgid ""
"(optional) ``Create`` to support customized runtime module construction "
"from subgraph file in your representation."
msgstr ""

#: ../../xin/docs/dev/how_to/relay_bring_your_own_codegen.rst:960
msgid ""
"An annotator to annotate a user Relay program to make use of your "
"compiler and runtime (TBA)."
msgstr ""


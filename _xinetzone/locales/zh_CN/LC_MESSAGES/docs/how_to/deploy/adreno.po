# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-02-09 00:02+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../xin/docs/how_to/deploy/adreno.rst:19
msgid "Deploy to Adreno GPU"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:21
msgid "**Authors**: Daniil Barinov, Egor Churaev, Andrey Malyshev"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:24
msgid "Introduction"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:26
msgid ""
"Adreno is a series of graphics processing unit (GPU) semiconductor "
"intellectual property cores developed by Qualcomm and used in many of "
"their SoCs."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:30
msgid ""
"The Adreno GPU accelerates the rendering of complex geometries to deliver"
" high-performance graphics and a rich user experience with low power "
"consumption."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:34
msgid ""
"This guide will demonstrate :ref:`the benefits of using textures with "
"Adreno<advantages_of_the_textures>`, how to :ref:`build TVM with "
"OpenCL<building_tvm_for_adreno>` (needed by Adreno devices) and TVM RPC "
"enabled. It will also provide :ref:`example "
"code<build_and_deploy_model_for_adreno>` to better understand the "
"differences in compiling and deploying models for Adreno devices."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:42
msgid "Advantages of the Textures"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:44
msgid ""
"One of the Adreno's advantages is the clever handling of textures. At the"
" moment, TVM is able to benefit from this by having texture support for "
"Adreno. The graph below shows the Adreno A5x architecture."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:48
msgid "|High-level overview of the Adreno A5x architecture for OpenCL|"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:335
msgid "High-level overview of the Adreno A5x architecture for OpenCL"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:50
msgid "*Fig. 1 High-level overview of the Adreno A5x architecture for OpenCL*"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:52
msgid ""
"*source:* `OpenCL Optimization and Best Practices for Qualcomm Adreno "
"GPUs <https://dl.acm.org/doi/10.1145/3204919.3204935>`_"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:54
msgid "Reasons of using textures:"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:56
msgid ""
"Texture processor (TP) has a dedicated L1 cache, which is read-only cache"
" and stores data fetched from level-2 (L2) cache for texture operations "
"(primary reason)"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:60
msgid "The handling of image boundaries is built-in."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:62
msgid ""
"Supports numerous image format and data type combinations with support "
"for automatic format conversions"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:65
msgid ""
"Overall, with textures, it is possible to achieve a significant "
"performance boost compared to OpenCL buffer based solutions."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:71
msgid "Building TVM for Adreno"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:73
msgid ""
"This section gives instructions on how to build the Android part of TVM "
"with OpenCL and TVM RPC Server in order to deploy models on Adreno."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:76
msgid ""
"Since the process of building TVM for Adreno is exactly the same as the "
"process of building TVM for Android, please refer to these instructions: "
"`TVM RPC Server <https://github.com/apache/tvm/tree/main/apps/cpp_rpc>`_."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:81
msgid ""
"Since there are many required packages for Android, you can use the "
"official Docker Image to build TVM. For more information refer to this "
"guide: `Deploy the Pretrained Model on Android "
"<https://tvm.apache.org/docs/how_to/deploy_models/deploy_model_on_android.html>`_."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:84
msgid ""
"**Prerequisites**: Android NDK and Android Debug Bridge must be "
"installed, the desired device must have OpenCL support and Android part "
"of TVM must be built:"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:87
msgid ""
"Read documentation about *Android NDK installation* here: "
"https://developer.android.com/ndk"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:88
msgid ""
"To get access to adb tools you can see *Android Debug Bridge "
"installation* here: https://developer.android.com/studio/command-line/adb"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:90
msgid ""
"You can also build the android part of TVM locally. From the root folder "
"of TVM:"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:100
msgid "where **N** is the number of cores available on your *CPU*."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:102
msgid "At this stage you have built TVM for Adreno."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:107
msgid "Build and deploy model for Adreno"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:109
msgid ""
"In this section we will focus on target, needed to compile and deploy "
"models for Adreno, demonstrate the differences in generated kernels with "
"and without textures and, in addition, the possibility of choosing a "
"different precision for model compilation will be considered."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:114
msgid ""
"For the complete step-py-step process of compiling and deploying models "
"on Adreno, including selection of precision, running the inference of the"
" model, getting the predictions, and measuring the performance please "
"refer to this tutorial: `How To Deploy model on Adreno "
"<https://tvm.apache.org/docs/how_to/deploy_models/deploy_model_on_adreno.html>`_"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:118
msgid "|Android deployment pipeline|"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:336
msgid "Android deployment pipeline"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:120
msgid "*Fig.2 Deployment pipeline on Adreno devices*"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:122
msgid ""
"The figure above demonstrates a generalized pipeline for deploying and "
"running neural network models on android devices. As can be seen from the"
" figure, the compiled model has a set_input() and a run() methods, which "
"*prepare the inputs* for inference and *execute the inference* on the "
"remote device using the Graph Executor runtime module."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:127
msgid "Adreno target"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:129
msgid ""
"Normally, when compiling models for Android using OpenCL, the "
"corresponding target is used"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:136
msgid ""
"Using Adreno, we want to get all the benefits of textures, so we have to "
"use the following target to generate texture leveraging kernels"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:143
msgid ""
"Let's write a simple model with one convolutional (conv2d) layer and take"
" a look at generated kernels for these two targets"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:166
msgid ""
"Now compile our model with the classic OpenCL target and print its "
"modules:"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:176
msgid ""
"Notice that the generated convolution kernel has pointers in the "
"initialization of the function. The kernels generated with the above "
"target are buffer-based."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:185
msgid "Now take a look at “opencl -device=adreno” target:"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:195
msgid ""
"The kernels generated this way is actually working with 2d arrays, "
"leveraging textures"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:202
msgid ""
"*image2d_t* is a built-in OpenCL types that represents two-dimensional "
"image object and provides several additional functions. When we use "
"*image2d_t* we read *4 elements at one time*, and it helps to utilize "
"hardware in a more efficient way."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:206
msgid "Precisions"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:207
msgid ""
"The right choice of precision for a specific workload can greatly "
"increase the efficiency of the solution, shifting the initial balance of "
"precision and speed to the side that is a priority for the problem."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:210
msgid ""
"We can choose from *float16*, *float16_acc32* (Mixed Precision), "
"*float32* (standard)."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:212
msgid "**Float16**"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:214
msgid ""
"To leverage the GPU hardware capabilities and utilize the benefits of "
"half precision computation and memory management, we can convert an "
"original model having floating points operation to a model operating with"
" half precision. Choosing lower precision will positively affect the "
"performance of the model, but it may also have a decrease in the accuracy"
" of the model. To do the conversion you need to write a simple conversion"
" function and specify the *dtype* value of \"float16\" before calling the"
" function:"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:240
msgid "We then can compile our model in any convinient way"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:249
msgid "**float16_acc32 (Mixed Precision)**"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:251
msgid ""
"ToMixedPrecision pass traverse over the network and split network to "
"clusters of ops dealing with float or float16 data types. The clusters "
"are defined by three types of operations: - Operations always be "
"converted into float16 data type - Operations which can be converted if "
"they follow by converted cluster - Operations never be converted to the "
"float16 data type This list is defined in the ToMixedPrecision "
"implementation here `relay/transform/mixed_precision.py "
"<https://github.com/apache/tvm/blob/main/python/tvm/relay/transform/mixed_precision.py#L34>`_"
" and can be overridden by user"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:260
msgid ""
"In some cases, we want higher precision in accumulation than the input "
"data. This is supported, for example, for conv2d and dense operations. To"
" override accumulation type you need to register function with "
"``@register_mixed_precision_conversion`` decorator to modify parameters "
"of ``ToMixedPrecision`` conversion"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:293
msgid ""
"Now we need to modify the conversion function by adding some logical "
"\"forks\" and ToMixedPrecision() call, then create a Relay graph from "
"desired model in any convinient way and obtain **mod** (which is IR "
"representation of the model), after which we can convert it to the "
"required **dtype** and then assemble our model sequentialy"
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:322
msgid ""
"The ``ToMixedPrecision`` method is a pass to convert an FP32 relay graph "
"into an FP16 version (with FP16 or FP32 accumulation dtypes). Doing this "
"transformation is useful for reducing model size as it halves the "
"expected size of the weights (FP16_acc16 case)."
msgstr ""

#: ../../xin/docs/how_to/deploy/adreno.rst:326
msgid "From this point onwards, we can compile our model as normal"
msgstr ""


# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-02-09 00:02+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../xin/docs/tutorial/introduction.md:2
msgid "TVM 和模型优化的概述"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:4
msgid ""
"Apache TVM 是开源的机器学习编译器框架，用于 CPU、GPU "
"和机器学习加速器。它的目标是让机器学习工程师在任何硬件后端优化和高效运行计算。本教程的目的是通过定义和演示关键概念，引导读者了解 TVM "
"的所有主要特性。新用户应该能够从头到尾地学习本教程，并能够操作 TVM 进行自动模型优化，同时对 TVM 体系结构及其工作原理有基本的了解。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:6
msgid "下图说明了机器学习模型在用 TVM 优化编译器框架进行变换时的步骤。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:8
msgid ""
"![A High Level View of "
"TVM](https://tvm.apache.org/images/tutorial/overview.png)"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:8
msgid "A High Level View of TVM"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:10
msgid "1. 从 *Tensorflow*、*PyTorch* 或 *Onnx* 等框架导入模型（model）。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:13
msgid ""
"importer 层是 TVM 可以从其他框架中导入模型的地方，比如 Tensorflow、PyTorch 或 "
"ONNX。由于此开源项目在不断改进，TVM 为每个前端提供的支持水平也不尽相同。如果你在将模型导入 TVM 时遇到问题，你可能想尝试将其转换为 "
"ONNX。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:15
msgid "2. 翻译成 *Relay*"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:18
msgid ""
"Relay 是 TVM 的高级模型语言。导入到 TVM 的模型是用 Relay 表示的。Relay 是一种函数式语言（functional "
"language）和神经网络的中间表示法（IR）。它支持以下内容："
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:20
msgid "传统的数据流图式表示法"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:21
msgid "Functional-style scoping 和 let-binding 使其成为一种功能齐全的可微分语言"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:22
msgid "能够允许用户混合两种编程风格"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:24
msgid "Relay 应用图级（graph-level）优化 passes 来优化模型。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:26
msgid "3. lower 到 *张量表达式*。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:29
msgid ""
"lower 是指高层表示被变换为低层表示。在应用高层优化后，Relay 运行 FuseOps，将模型分割成许多小的子图，并将子图 lower 到 "
"TE 表示。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:31
msgid "张量表达式（Tensor Expression，简称 TE）是用于描述张量计算的专属域语言。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:33
msgid ""
"TE 还提供了几个 *schedule* "
"原语来指定低级的循环优化，例如平铺（tiling）、矢量化（vectorization）、并行化（parallelization）、unrolling"
" 和 fusion。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:35
msgid ""
"为了帮助将 Relay 表示转换为 TE 表示的过程，TVM 包含张量算子清单（Tensor Operator Inventory，简称 "
"TOPI），它有预先定义的常见张量算子的模板（如 conv2d、transpose）。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:37
msgid "4. 使用 auto-tuning 模块 *AutoTVM* 或 *AutoScheduler* 搜索最佳 schedule。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:40
msgid ""
"schedule 指定在 TE 中定义了算子或子图的低级循环优化。auto-tuning 模块搜索最佳 schedule 并将其与 cost "
"模型和设备上的测量结果进行比较。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:42
msgid "在 TVM 中，有两个 auto-tuning 模块："
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:44
msgid "**AutoTVM**：基于模板的 auto-tuning 模块。它运行搜索算法为用户定义的模板中的可调节旋钮找到最佳值。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:46
msgid "对于常见的运算符，其模板已经在 TOPI 中提供。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:48
msgid "**AutoScheduler** （别名 Ansor） ：无模板的自动调谐模块。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:50
msgid "它不需要预先定义的 schedule 模板。相反，它通过分析计算的定义自动生成搜索空间。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:52
msgid "然后，它在生成的搜索空间中搜索最佳 schedule。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:54
msgid "5. 选择最佳配置进行模型编译。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:57
msgid ""
"tuning 后，auto-tuning 模块会生成 JSON 格式的 auto-tuning 记录。这一步为每个子图挑选出最佳的 "
"schedule。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:59
msgid "6. lower 到 TIR。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:62
msgid "TIR 是张量级的中间表示（Tensor Intermediate Representation），TVM 的低层次中间表示。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:64
msgid "在根据 tuning 步骤选择最佳配置后，每个 TE 子图被降低到 TIR，并通过低级别的优化 passes 进行优化。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:66
msgid "接下来，优化后的 TIR 被 lower 到硬件平台的目标编译器中。这是最后的代码生成阶段，产生可以部署到生产中的优化模型。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:68
msgid "TVM 支持几种不同的编译器后端，包括："
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:70
msgid ""
"LLVM：它可以针对任意的微处理器架构，包括 标准 x86 和 ARM 处理器，AMDGPU 和 NVPTX 代码生成，以及 LLVM "
"支持的任何其他平台。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:71
msgid "专门的编译器，如 NVCC，NVIDIA 的编译器。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:72
msgid "嵌入式和专用目标，通过 TVM 的 Bring Your Own Codegen（BYOC）框架实现。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:74
msgid "7. 编译成机器码。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:77
msgid "在这个过程结束时，特定的编译器生成的代码可以 lower 为机器码。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:79
msgid ""
"TVM 可以将模型编译成可链接的对象模块，然后可以用轻量级的 TVM 运行时来运行，该运行时提供 C 语言的 API "
"来动态加载模型，以及其他语言的入口，如 Python 和 Rust。TVM 还可以建立捆绑式部署，其中运行时与模型结合在一个包中。"
msgstr ""

#: ../../xin/docs/tutorial/introduction.md:81
msgid "本教程的其余部分将更详细地介绍 TVM 的这些方面。"
msgstr ""

#~ msgid "下图说明了机器学习模型在用 TVM 优化编译器框架进行转换时的步骤。"
#~ msgstr ""

#~ msgid "从 *Tensorflow*、*PyTorch* 或 *Onnx* 等框架导入模型。"
#~ msgstr ""

#~ msgid ""
#~ "importer 层是 TVM 可以从其他框架中导入模型的地方，比如 "
#~ "Tensorflow、PyTorch 或 ONNX。由于这个开源项目在不断改进，TVM "
#~ "为每个前端提供的支持水平也不尽相同。如果你在将模型导入 TVM 时遇到问题，你可能想尝试将其转换为 "
#~ "ONNX。"
#~ msgstr ""

#~ msgid "翻译成 *Relay*，TVM 的高级模型语言。"
#~ msgstr ""

#~ msgid ""
#~ "已经导入 TVM 的模型是用 Relay 表示的。Relay "
#~ "是一种函数式语言（functional language）和神经网络的中间表示法（IR）。它支持以下内容："
#~ msgstr ""

#~ msgid "传统的数据流式表示法"
#~ msgstr ""

#~ msgid "Functional-style scoping 和 let-binding 使其成为一种功能齐全的可区分语言"
#~ msgstr ""

#~ msgid "Relay 应用图级（graph-level）优化通道来优化模型。"
#~ msgstr ""

#~ msgid "lower 到 *张量表达式* （Tensor Expression，简称 TE）表示。"
#~ msgstr ""

#~ msgid ""
#~ "lower 是指高层表示被转化为低层表示。在应用高层优化后，Relay 运行 "
#~ "FuseOps，将模型分割成许多小的子图，并将子图 lower 到 TE 表示。"
#~ msgstr ""

#~ msgid "张量表达式（TE）是用于描述张量计算的专属域语言。"
#~ msgstr ""

#~ msgid "使用 auto-tuning 模块 *AutoTVM* 或 *AutoScheduler* 搜索最佳 schedule。"
#~ msgstr ""

#~ msgid ""
#~ "选择最佳配置进行模型编译。tuning 后，auto-tuning 模块会生成 JSON"
#~ " 格式的 auto-tuning 记录。这一步为每个子图挑选出最佳的 "
#~ "schedule。"
#~ msgstr ""

#~ msgid ""
#~ "lower 到张量级的中间表示（Tensor Intermediate "
#~ "Representation，简称 TIR），TVM 的低层次中间表示。"
#~ msgstr ""

#~ msgid "在根据 tuning 步骤选择最佳配置后，每个 TE 子图被降低到 TIR，并通过低级别的优化通道进行优化。"
#~ msgstr ""

#~ msgid "接下来，优化后的 TIR 被降低到硬件平台的目标编译器中。这是最后的代码生成阶段，产生可以部署到生产中的优化模型。"
#~ msgstr ""

#~ msgid "编译成机器码。在这个过程结束时，特定的编译器生成的代码可以 lower 为机器码。"
#~ msgstr ""


# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# xinetzone <735613050@qq.com>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-01-10 21:32+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../docs/arch/index.rst:19
msgid "Design and Architecture"
msgstr "设计与架构"

#: ../../docs/arch/index.rst:21
msgid ""
"This document is intended for developers who want to understand the "
"architecture of TVM and/or actively develop on the project. This page is "
"organized as follows:"
msgstr ""
"本文档是为那些想了解 TVM 架构和/或积极开发项目的开发者准备的。本页的组织结构如下："

#: ../../docs/arch/index.rst:25
msgid ""
"The `Example Compilation Flow`_ gives an overview of the steps that TVM "
"takes to turn a high level description of a model into a deployable "
"module. To get started, please read this section first."
msgstr ""
"`编译流程示例`_ 概述了 TVM 将模型的高级别描述转化为可部署模块的步骤。"
"要开始使用，请先阅读本节。"

#: ../../docs/arch/index.rst:28
msgid ""
"The `Logical Architecture Components`_ section describes the logical "
"components. The sections after are specific guides focused on each "
"logical component, organized by the component's name."
msgstr ""
"`逻辑架构组件`_ 部分描述了逻辑组件。"
"之后的章节是专注于每个逻辑组件的具体指南，按照组件的名称组织。"

#: ../../docs/arch/index.rst:32
msgid ""
"The :ref:`Device/Target Interactions <tvm-target-specific-overview>` page"
" describes how TVM interacts with each supported physical device and "
"code-generation target."
msgstr ""
":ref:`设备/目标交互 <tvm-target-specific-overview>` 页面描述了 TVM "
"如何与每个支持的物理设备和代码生成目标交互。"

#: ../../docs/arch/index.rst:36
msgid ""
"Feel free to also check out the :ref:`dev-how-to` for useful development "
"tips."
msgstr ""
"请随时查看 :ref:`dev-how-to`，了解有用的开发技巧。"

#: ../../docs/arch/index.rst:38
msgid ""
"This guide provides a few complementary views of the architecture. First,"
" we review a single end-to-end compilation flow and discuss the key data "
"structures and the transformations. This runtime-based view focuses on "
"the interactions of each components when running the compiler. Then we "
"will review the logical modules of the codebase and their relationship. "
"This part provides a static overarching view of the design."
msgstr ""
"本指南提供了关于架构的几个互补性观点。"
"首先，回顾了单一的端到端编译流程，并讨论了关键的数据结构和变换。"
"这种基于运行时的观点着重于运行编译器时每个组件的相互作用。"
"然后，将回顾代码库的逻辑模块和它们之间的关系。这一部分提供了一个静态的总体设计视图。"

#: ../../docs/arch/index.rst:45
msgid "Example Compilation Flow"
msgstr "编译流程示例"

#: ../../docs/arch/index.rst:47
msgid ""
"In this guide, we will study an example compilation flow in the compiler."
" The figure below shows the flow. At a high-level, it contains several "
"steps:"
msgstr ""
"在本指南中，将研究编译器中编译流程的示例。"
"下图显示了流程。在高层，它包含几个步骤："

#: ../../docs/arch/index.rst:49
msgid ""
"Import: The frontend component ingests a model into an IRModule, which "
"contains a collection of functions that internally represent the model."
msgstr ""
"Import：frontend 组件将模型摄取到 IRModule 中，"
"IRModule 包含了一组内部表示（internally represent）模型的函数。"

#: ../../docs/arch/index.rst:50
msgid ""
"Transformation: The compiler transforms an IRModule to another "
"functionally equivalent or approximately equivalent(e.g. in the case of "
"quantization) IRModule. Many of the transformations are target (backend) "
"independent. We also allow target to affect the configuration of the "
"transformation pipeline."
msgstr ""
"Transformation：编译器将 IRModule 变换成另一个在功能上等价或近似等价的"
"（例如，在量化的情况下）IRModule。"
"许多变换都是独立于目标（后端）的。我们还允许目标影响变换管道的配置。"

#: ../../docs/arch/index.rst:53
msgid ""
"Target Translation: The compiler translates(codegen) the IRModule to an "
"executable format specified by the target. The target translation result "
"is encapsulated as a `runtime.Module` that can be exported, loaded, and "
"executed on the target runtime environment."
msgstr ""
"Target Translation：编译器将 IRModule 翻译（codegen）为目标指定的可执行格式。"
"目标翻译结果封装为 ``runtime.Module``，可以导出、加载并在目标运行时环境中执行。"

#: ../../docs/arch/index.rst:55
msgid ""
"Runtime Execution: the user loads back a `runtime.Module` and runs the "
"compiled functions in the supported runtime environment."
msgstr ""
"Runtime Execution：用户加载回 ``runtime.Module``，并在受支持的运行时环境中运行已编译的函数。"

#: ../../docs/arch/index.rst:64
msgid "Key data structures"
msgstr "关键数据结构"

#: ../../docs/arch/index.rst:66
msgid ""
"One of the best ways to design and understand a complex system is to "
"identify the key data structures and APIs that manipulate (transform) "
"these data structures. Once we identified the key data structures, we can"
" then breakdown a system into logical components that either define a "
"collection of key data structures or transformations among the data "
"structures."
msgstr ""
"设计和理解复杂系统的最佳方法之一是识别操纵（变换）这些数据结构的关键数据结构和 API。"
"一旦确定了关键数据结构，就可以将系统分解成逻辑组件，"
"这些逻辑组件要么定义了关键数据结构的集合，要么定义了数据结构之间的变换。"

#: ../../docs/arch/index.rst:70
msgid ""
"**IRModule** is the primary data structure used across the entire stack. "
"An IRModule (intermediate representation module) contains a collection of"
" functions. Currently, we support two primary variants of functions."
msgstr ""
"**IRModule** 是整个堆栈中使用的主要数据结构。"
"IRModule（中间表示模块）包含函数集合。目前，支持两种主要的函数变体。"

#: ../../docs/arch/index.rst:73
msgid ""
"**relay::Function** is a high-level functional program representation. A "
"relay.Function usually corresponds to an end-to-end model. You can view a"
" relay.Function as a computational graph with additional support for "
"control-flow, recursion, and complex data structures."
msgstr ""
"**relay::Function** 是高级函数式程序表示。"
"relay.Function 通常对应于端到端模型。"
"您可以视 relay.Function 作为计算图，具有对控制流、递归和复杂数据结构的额外支持。"

#: ../../docs/arch/index.rst:75
msgid ""
"**tir::PrimFunc** is a low-level program representation that contains "
"elements including loop-nest choices, multi-dimensional load/store, "
"threading, and vector/tensor instructions. It is usually used to "
"represent an operator program that executes a (possibly-fused) layer in a"
" model."
msgstr ""
"**tir::PrimFunc** 是低级的程序表示，它包含的元素有"
"循环嵌套选择、多维加载/存储、线程化和矢量/张量指令。"
"它通常用于表示在模型中执行（可能融合的）层的算子程序。"

#: ../../docs/arch/index.rst:78
msgid ""
"During the compilation, a relay function may be lowered to multiple "
"tir::PrimFunc functions and a top-level function that calls into those "
"tir::PrimFunc functions."
msgstr ""
"在编译过程中，relay 函数可能被降级为多个 tir::PrimFunc 函数和调用 tir::PrimFunc 函数的顶级函数。"

#: ../../docs/arch/index.rst:82
msgid "Transformations"
msgstr "变换"

#: ../../docs/arch/index.rst:84
msgid ""
"Now that we have covered the key data structures, let us talk about the "
"transformations. Each transformation could serve one of the following "
"purposes:"
msgstr ""
"既然已经介绍了关键的数据结构，现在讨论一下变换。每个变换都可以用于以下目的之一："

#: ../../docs/arch/index.rst:86
msgid ""
"optimization: transform a program to an equivalent, possibly more "
"optimized version."
msgstr ""
"optimization：将程序转化为等价的，可能是更优化的版本。"

#: ../../docs/arch/index.rst:87
msgid ""
"lowering: transform a program to a lower-level representation that is "
"closer to the target."
msgstr ""
"lowering：将程序转换为更接近目标的较低层次表示。"

#: ../../docs/arch/index.rst:89
msgid ""
"**relay/transform** contains a collection of passes that optimize the "
"model. The optimizations include common program optimizations such as "
"constant folding and dead-code elimination, and tensor-computation "
"specific passes such as layout transformation and scaling factor folding."
msgstr ""
"**relay/transform** 包含优化模型的 passes 集合。"
"优化包括常见的程序优化，如常数折叠和死代码消除，以及张量计算专用的 passes，如布局变换和缩放因子折叠。"

#: ../../docs/arch/index.rst:93
msgid ""
"Near the end of the relay optimization pipeline, we will run a "
"pass(FuseOps) to break the end-to-end function(e.g. MobileNet) into sub-"
"function(e.g. conv2d-relu) segments. We call these segments of functions."
" This process helps us to divide the original problem into two sub-"
"problems:"
msgstr ""
"在 relay 优化管道接近尾声的时候，将运行 pass（FuseOps）将端到端函数（例如 MobileNet）分解为子函数（例如：conv2d-relu）段。"
"称这些为函数片段。"
"这个过程帮助我们将原始问题划分为两个子问题："

#: ../../docs/arch/index.rst:97
msgid "Compilation and optimization for each sub-function."
msgstr "对每个子函数进行编译和优化。"

#: ../../docs/arch/index.rst:98
msgid ""
"Overall execution structure: we need to do a sequence of calls into the "
"generated sub-functions to execute the whole model."
msgstr ""
"整体执行结构：需要对生成的子函数进行一系列调用，以执行整个模型。"

#: ../../docs/arch/index.rst:100
msgid ""
"We use the low-level tir phase to compile and optimize each sub-"
"functions. For specific targets, we may also directly go to the target "
"translation phase and use external code generators."
msgstr ""
"使用低级 tir 阶段来编译和优化每个子函数。"
"对于特定的目标，也可以直接进入目标变换阶段，并使用外部代码生成器。"

#: ../../docs/arch/index.rst:103
msgid ""
"There are a few different ways(in relay/backend) to handle the calls into"
" the overall execution problem. For simple models with known shapes and "
"no control flow, we can lower to a graph executor that stores the "
"execution structure in a graph. We also support a virtual machine backend"
" for dynamic executions. Finally, we plan to support ahead of time "
"compilation that compiles the high-level execution structure into the "
"executable and generated primitive functions. All of these execution "
"modes are encapsulated by a unified **runtime.Module** interface, which "
"we will discuss in the latter part of the guide."
msgstr ""
"有几种不同的方法（relay/backend）处理对整体执行问题的调用。"
"对于形状已知且没有控制流的简单模型，可以使用计算图执行器将执行结构存储在计算图中。"
"还支持动态执行的虚拟机后端。最后，计划支持提前编译，将高级执行结构编译成可执行文件和生成的原语函数。"
"所有这些执行模式都封装在统一的 **runtime.Module** 接口，将在本指南的后半部分讨论。"

#: ../../docs/arch/index.rst:105
msgid ""
"**tir/transform** contains transformation passes for TIR level functions."
" Many tir passes serve the purpose of lowering. For example, there are "
"passes to flatten multi-dimensional access to one-dimensional pointer "
"access, to expand the intrinsics into target-specific ones, and to "
"decorate the function entry to meet the runtime calling convention. Of "
"course, there are also optimizations passes, such as access index "
"simplification and dead code elimination."
msgstr ""
"**tir/transform** 包含 TIR 级函数的变换 pass。"
"许多 tir pass 都是用来降级的。"
"例如，有一些 pass 可以将多维访问扁平化为一维指针访问，将 intrinsic 扩展为特定于目标的内容，"
"并装饰函数条目以满足运行时调用约定。"
"当然，也有优化 pass，比如访问索引简化和死代码消除。"

#: ../../docs/arch/index.rst:107
msgid ""
"Many low-level optimizations can be handled in the target phase by the "
"LLVM, CUDA C, and other target compilers. As a result, we leave low-level"
" optimizations such as register allocation to the downstream compilers "
"and only focus on optimizations that are not covered by them."
msgstr ""
"许多低级优化可以在目标阶段由 LLVM、CUDA C 和其他目标编译器处理。"
"因此，将寄存器分配等低级优化留给下游编译器，只关注它们不涉及的优化。"

#: ../../docs/arch/index.rst:110
msgid "Search-space and Learning-based Transformations"
msgstr "搜索空间和基于学习的变换"

#: ../../docs/arch/index.rst:112
msgid ""
"The transformation passes we described so far are deterministic and rule-"
"based. One design goal of the TVM stack is to support high-performance "
"code optimizations for different hardware platforms. To do so, we will "
"need to investigate as many optimization choices as possible, including "
"but not limited to, multi-dimensional tensor access, loop tiling "
"behavior, special accelerator memory hierarchy, and threading."
msgstr ""
"到目前为止，描述的转换 passes 都是确定的和基于规则的。"
"TVM 堆栈的一个设计目标是支持针对不同硬件平台的高性能代码优化。"
"为此，需要研究尽可能多的优化选择，包括但不限于多维张量访问、循环 tiling 行为、特殊的加速器内存层次结构和线程。"

#: ../../docs/arch/index.rst:114
msgid ""
"It is hard to define a heuristic to make all of the choices. Instead, we "
"will take a search and learning-based approach. We first define a "
"collection of actions we can take to transform a program. Example actions"
" include loop transformations, inlining, vectorization. We call these "
"actions **scheduling primitives**. The collection of scheduling "
"primitives defines a search space of possible optimizations we can make "
"to a program. The system then searches over different possible scheduling"
" sequence to pick the best scheduling combination. The search procedure "
"is usually guided by a machine learning algorithm."
msgstr ""
"很难定义启发式来做出所有的选择。相反，将采取基于搜索和学习的方法。"
"首先定义一组可以用来变换程序的行为。示例行为包括循环变换、内联、向量化。"
"称这些行为为 **调度原语** （scheduling primitive）。"
"调度原语集定义了对程序进行优化的可能搜索空间。"
"然后，系统在不同的可能调度序列中搜索出最优的调度组合。"
"搜索过程通常由机器学习算法指导。"

#: ../../docs/arch/index.rst:121
msgid ""
"We can record the best schedule sequence for an (possibly-fused) operator"
" once the search is completed. The compiler can then just lookup the best"
" schedule sequence and apply it to the program. Notably, this schedule "
"application phase is **exactly like** the rule-based transformations, "
"enabling us to share the same interface convention with tradition passes."
msgstr ""
"一旦搜索完成，可以为（可能融合的）算子记录最佳的调度序列。"
"然后，编译器就可以查找最佳的调度序列，并将其应用到程序中。"
"值得注意的是，这个调度应用阶段与基于规则的变换非常相似，使能够与传统 passes 共享相同的接口约定。"

#: ../../docs/arch/index.rst:125
msgid ""
"We use search based optimizations to handle the initial tir function "
"generation problem. This part of the module is called "
"AutoTVM(auto_scheduler). We expect to expand the learning-based "
"transformations to more areas as we continue to develop the TVM stack."
msgstr ""
"使用基于搜索的优化来处理初始 tir 函数生成问题。"
"模块的这一部分称为 AutoTVM（auto_scheduler）。"
"随着继续开发 TVM 堆栈，希望将基于学习的变换扩展到更多领域。"

#: ../../docs/arch/index.rst:129
msgid "Target Translation"
msgstr "目标翻译"

#: ../../docs/arch/index.rst:131
msgid ""
"The target translation phase transforms an IRModule to the corresponding "
"target executable format. For backends such as x86 and ARM, we use the "
"LLVM IRBuilder to build in-memory LLVM IR. We can also generate source-"
"level languages such as CUDA C and OpenCL. Finally, we support direct "
"translations of a Relay function (sub-graph) to specific targets via "
"external code generators. It is important that the final code generation "
"phase is as lightweight as possible. Vast majority of transformations and"
" lowering should be performed before the target translation phase."
msgstr ""
"目标翻译阶段将 IRModule 变换为相应的目标可执行格式。"
"对于像 x86 和 ARM 这样的后端，使用 LLVM IRBuilder 来构建内存中的 LLVM IR。"
"也可以生成源代码级的语言，比如 CUDA C 和 OpenCL。"
"最后，支持通过外部代码生成器将 Relay 函数（子图）直接变换到特定目标。"
"重要的是，最终的代码生成阶段要尽可能的轻量级。"
"绝大多数的变换和降级应该在目标变换阶段之前进行。"

#: ../../docs/arch/index.rst:138
msgid ""
"We also provide a Target structure to specify the compilation target. The"
" transformations before the target translation phase can also be affected"
" by the target — for example, a target's vector length would change the "
"vectorization behavior."
msgstr ""
"还提供了 Target 结构来指定编译目标。"
"目标变换阶段之前的变换也会受到目标的影响 —— 例如，目标的矢量长度会改变矢量化行为。"

#: ../../docs/arch/index.rst:144
msgid "Runtime Execution"
msgstr "运行时执行"

#: ../../docs/arch/index.rst:146
msgid ""
"The main goal of TVM's runtime is to provide a minimal API for loading "
"and executing the compiled artifact in a language of their choice, "
"including Python, C++, Rust, Go, Java, and JavaScript. The code snippet "
"below shows such an example in Python:"
msgstr ""
"TVM 运行时的主要目标是提供最小的 API 来加载和执行编译后的工件，使用他们自己选择的语言，"
"包括 Python、C++、Rust、Go、Java 和 JavaScript。"
"下面的代码片段展示了 Python 示例："

#: ../../docs/arch/index.rst:159
msgid ""
":py:class:`tvm.runtime.Module` encapsulates the result of compilation. A "
"runtime.Module contains a GetFunction method to obtain PackedFuncs by "
"name."
msgstr ""
":py:class:`tvm.runtime.Module` 封装了编译的结果。"
"runtime.Module 包含 GetFunction 方法，可以按名称获取 PackedFuncs。"

#: ../../docs/arch/index.rst:161
msgid ""
":py:class:`tvm.runtime.PackedFunc` is a type-erased function interface "
"for both the generated functions. A runtime.PackedFunc can take arguments"
" and return values with the following types: POD types(int, float), "
"string, runtime.PackedFunc, runtime.Module, runtime.NDArray, and other "
"sub-classes of runtime.Object."
msgstr ""
":py:class:`tvm.runtime.PackedFunc` 是两个生成函数的类型擦除函数接口。"
"runtime.PackedFunc 可以接受以下类型的参数和返回值："
"POD 类型（int, float），字符串，runtime.PackedFunc，runtime.Module，runtime.NDArray 以及 runtime.Object 的其他子类。"

#: ../../docs/arch/index.rst:164
msgid ""
":py:class:`tvm.runtime.Module` and :py:class:`tvm.runtime.PackedFunc` are"
" powerful mechanisms to modularize the runtime. For example, to get the "
"above `addone` function on CUDA, we can use LLVM to generate the host-"
"side code to compute the launching parameters(e.g. size of the thread "
"groups) and then call into another PackedFunc from a CUDAModule that is "
"backed by the CUDA driver API. The same mechanism can be used for OpenCL "
"kernels."
msgstr ""
":py:class:`tvm.runtime.Module` 和 :py:class:`tvm.runtime.PackedFunc` 是模块化运行时的强大机制。"
"例如，要在 CUDA 上获得上述的 ``addone`` 函数，可以使用 LLVM 生成主机端代码来计算启动参数"
"（例如：线程组大小）然后从 CUDAModule 中调用另一个 PackedFunc，这个 CUDA 驱动 API 支持它。"
"同样的机制也可以用于 OpenCL 内核。"

#: ../../docs/arch/index.rst:166
msgid ""
"The above example only deals with a simple `addone` function. The code "
"snippet below gives an example of an end-to-end model execution using the"
" same interface:"
msgstr ""
"上面的例子只处理了简单的 ``addone`` 函数。下面的代码片段给出了使用相同接口执行端到端模型的例子："

#: ../../docs/arch/index.rst:183
msgid ""
"The main take away is that runtime.Module and runtime.PackedFunc are "
"sufficient to encapsulate both operator level programs (such as addone), "
"as well as the end-to-end models."
msgstr ""
"主要的结论是，runtime.Module 和 runtime.PackedFunc 足以封装算子级程序（如 addone）以及端到端模型。"

#: ../../docs/arch/index.rst:186
msgid "Summary and Discussions"
msgstr "总结和讨论"

#: ../../docs/arch/index.rst:188
msgid "In summary, the key data structures in the compilation flows are:"
msgstr "总之，编译流中的关键数据结构如下："

#: ../../docs/arch/index.rst:190
msgid "IRModule: contains relay.Function and tir.PrimFunc"
msgstr "IRModule：包含 relay.Function 和 tir.PrimFunc"

#: ../../docs/arch/index.rst:191
msgid "runtime.Module: contains runtime.PackedFunc"
msgstr "runtime.Module：包含 runtime.PackedFunc"

#: ../../docs/arch/index.rst:193
msgid ""
"Most parts of the compilation are transformations among the key data "
"structures."
msgstr ""
"编译的大部分是关键数据结构之间的变换。"

#: ../../docs/arch/index.rst:195
msgid ""
"relay/transform and tir/transform are determinstic rule-based "
"transformations"
msgstr ""
"relay/transform 和 tir/transform 是基于规则的确定变换。"

#: ../../docs/arch/index.rst:196
msgid "auto_scheduler and autotvm contains the search-based transformations"
msgstr "auto_scheduler 和 autovm 包含基于搜索的变换"

#: ../../docs/arch/index.rst:198
msgid ""
"Finally, the compilation flow example is only a typical use-case of the "
"TVM stack. We expose these key data structures and transformations to "
"python and C++ APIs. As a result, you can use TVM just like the way you "
"use numpy, except that the data structure of interest changes from the "
"numpy.ndarray to tvm.IRModule. Here are some example use-cases:"
msgstr ""
"最后，编译流的例子只是 TVM 堆栈的典型用例。"
"将这些关键数据结构和变换公开给 python 和 C++ API。"
"因此，您可以像使用 numpy 一样使用 TVM，除了感兴趣的数据结构由 numpy.ndarray 转变为 tvm.IRModule。"
"下面是一些示例用例："

#: ../../docs/arch/index.rst:202
msgid "Directly construct IRModule using the python API."
msgstr "使用 python API 直接构造 IRModule。"

#: ../../docs/arch/index.rst:203
msgid "Compose a custom set of transformations(e.g. customize quantization)."
msgstr "组成自定义的变换集（例如，自定义量化）。"

#: ../../docs/arch/index.rst:204
msgid "Manipulate the IR directly using TVM's python API."
msgstr "使用 TVM 的 python API 直接操作 IR。"

#: ../../docs/arch/index.rst:208
msgid "Logical Architecture Components"
msgstr "逻辑架构组件"

#: ../../docs/arch/index.rst:214
msgid "TVM Architecture Diagram"
msgstr "TVM 架构图"

#: ../../docs/arch/index.rst:216
msgid ""
"The above figure shows the major logical components in the project. "
"Please read the following sections for information about the components "
"and their relations."
msgstr ""
"上图显示了项目中的主要逻辑组件。"
"请阅读以下部分，了解组件及其关系。"

#: ../../docs/arch/index.rst:221
msgid "tvm/support"
msgstr ""

#: ../../docs/arch/index.rst:222
msgid ""
"The support module contains the most common utilities for the "
"infrastructure, such as generic arena allocator, socket, and logging."
msgstr ""
"support 模块包含了基础设施中最常用的工具，如通用 arena 分配器、套接字和日志记录。"

#: ../../docs/arch/index.rst:226
msgid "tvm/runtime"
msgstr ""

#: ../../docs/arch/index.rst:228
msgid ""
"The runtime serves as the foundation of the TVM stack. It provides the "
"mechanism to load and execute compiled artifacts. The runtime defines a "
"stable standard set of C APIs to interface with frontend languages such "
"as Python and Rust."
msgstr ""
"runtime 是 TVM 堆栈的基础。它提供了加载和执行已编译构件的机制。"
"runtime 定义了一组稳定的标准 C API，用于与 Python 和 Rust 等前端语言进行接口翻译。"

#: ../../docs/arch/index.rst:231
msgid ""
"`runtime::Object` is one of the primary data structures in TVM runtime "
"besides the `runtime::PackedFunc`. It is a reference-counted base class "
"with a type index to support runtime type checking and downcasting. The "
"object system allows the developer to introduce new data structures to "
"the runtime, such as Array, Map, and new IR data structures."
msgstr ""
"`runtime::Object` 是 TVM runtime 中除了 `runtime::PackedFunc` 之外的主要数据结构之一。"
"它是引用计数的基类，具有类型索引以支持运行时类型检查和 downcasting。"
"对象系统允许开发者在运行时引入新的数据结构，比如 Array、Map 和新的 IR 数据结构。"

#: ../../docs/arch/index.rst:235
msgid ""
"Besides deployment use-cases, the compiler itself also makes heavy use of"
" TVM's runtime mechanism. All of the IR data structures are subclasses of"
" `runtime::Object`, as a result, they can be directly accessed and "
"manipulated from the Python frontend. We use the PackedFunc mechanism to "
"expose various APIs to the frontend."
msgstr ""
"除了部署用例，编译器本身也大量使用了 TVM 的 runtime 机制。"
"所有 IR 数据结构都是 `runtime::Object` 的子类，因此，它们可以直接从 Python 前端访问和操作。"
"使用 PackedFunc 机制将各种 API 暴露给前端。"

#: ../../docs/arch/index.rst:239
msgid ""
"Runtime support for different hardware backends are defined in "
"subdirectories of runtime(e.g. runtime/opencl). These hardware-specific "
"runtime modules define APIs for device memory allocation and device "
"function serialization."
msgstr ""
"对不同硬件后端的运行时支持定义在 runtime 的子目录中（例如 runtime/opencl）。"
"这些硬件特定的 runtime 模块为设备内存分配和设备函数序列化定义了 API。"

#: ../../docs/arch/index.rst:242
msgid ""
"`runtime/rpc` implements an RPC support for PackedFunc. We can use the "
"RPC mechanism to send a cross-compiled library to a remote device and "
"benchmark the execution performance. The rpc infrastructure enables data "
"collection from a wide range of hardware backends for learning-based "
"optimizations."
msgstr ""
"``runtime/rpc`` 实现了对 PackedFunc 的 RPC 支持。"
"可以使用 RPC 机制将交叉编译的库发送到远程设备，并对执行性能进行基准测试。"
"rpc 基础设施允许从广泛的硬件后端收集数据，以进行基于学习的优化。"

#: ../../docs/arch/index.rst:264
msgid "tvm/node"
msgstr ""

#: ../../docs/arch/index.rst:265
msgid ""
"The node module adds additional features on top of the `runtime::Object` "
"for IR data structures. The main features include reflection, "
"serialization, structural equivalence, and hashing."
msgstr ""
"node 模块在 `runtime::Object` 的基础上为 IR 数据结构增加了额外的特性。"
"其主要特性包括反射（reflection）、序列化、结构等效（structural equivalence）和哈希。"

#: ../../docs/arch/index.rst:268
msgid ""
"Thanks to the node module, we can directly access any field of the TVM's "
"IRNode by their name in Python."
msgstr ""
"多亏了 node 模块，可以通过 Python 中的名称直接访问 TVM 的 IRNode 的任何字段。"

#: ../../docs/arch/index.rst:279
msgid ""
"We can also serialize arbitrary IR node into a JSON format, and load them"
" back. The ability to save/store, and inspect an IR node provides a "
"foundation for making the compiler more accessible."
msgstr ""
"还可以将任意 IR 节点序列化为 JSON 格式，并将其加载回来。保存/存储和检查 IR 节点的能力为编译器的可访问性提供了基础。"

#: ../../docs/arch/index.rst:284
msgid "tvm/ir"
msgstr ""

#: ../../docs/arch/index.rst:285
msgid ""
"The `tvm/ir` folder contains the unified data structure and interfaces "
"across for all IR function variants. The components in `tvm/ir` are "
"shared by `tvm/relay` and `tvm/tir`, notable ones include"
msgstr ""
"``tvm/ir`` 文件夹包含了所有 IR 函数变体的统一数据结构和接口。"
"``tvm/ir`` 中的组件由 ``tvm/relay`` 和 ``tvm/tir`` 共享，其中值得注意的包括"

#: ../../docs/arch/index.rst:288
msgid "IRModule"
msgstr ""

#: ../../docs/arch/index.rst:289
msgid "Type"
msgstr ""

#: ../../docs/arch/index.rst:290
msgid "PassContext and Pass"
msgstr ""

#: ../../docs/arch/index.rst:291
msgid "Op"
msgstr ""

#: ../../docs/arch/index.rst:293
msgid ""
"Different variants of functions(e.g. relay.Function and tir.PrimFunc) can"
" co-exist in an IRModule. While these variants may not have the same "
"content representation, they use the same data structure to represent "
"types. As a consequence, we use the same data structure to represent "
"function (type) signatures of these variants. The unified type system "
"allows one function variant to call another function once we clearly "
"define the calling convention. This opens doors for future cross-"
"function-variant optimizations."
msgstr ""
"函数的不同变体（<例如 relay.Function 和 tir.PrimFunc）可以在 IRModule 中共存。"
"虽然这些变量可能没有相同的内容表示形式，但它们使用相同的数据结构来表示类型。"
"因此，使用相同的数据结构来表示这些变量的函数（类型）签名。"
"统一类型系统允许一个函数变量在明确定义调用约定后调用另一个函数。"
"这为未来的跨功能优化打开了大门。"

#: ../../docs/arch/index.rst:299
msgid ""
"We also provide a unified PassContext for configuring the pass behavior, "
"and common composite passes to execute a pass pipeline. The following "
"code snippet gives an example of PassContext configuration."
msgstr ""
"还提供了统一的 PassContext 来配置 pass 行为，以及通用的复合 pass 来执行 pass 管道。"
"下面的代码片段给出了 PassContext 配置的例子。"

#: ../../docs/arch/index.rst:309
msgid ""
"Op is the common class to represent all system-defined primitive "
"operator/intrinsics. Developers can register new Ops as well as their "
"additional attributes(e.g. whether the Op is elementwise) to the system."
msgstr ""
"Op 是表示所有系统定义的原语 operator/intrinsics 的公共类。"
"开发者可以注册新的 Ops 以及它们的附加属性（例如，不管 Op 是否为 elementwise）。"

#: ../../docs/arch/index.rst:319
msgid "tvm/target"
msgstr ""

#: ../../docs/arch/index.rst:320
msgid ""
"The target module contains all the code generators that translate an "
"IRModule to a target runtime.Module. It also provides a common `Target` "
"class that describes the target."
msgstr ""
"target 模块包含所有将 IRModule 翻译为 target runtime.Module 的代码生成器。"
"它还提供了通用的 ``Target`` 类来描述目标。"

#: ../../docs/arch/index.rst:326
msgid ""
"The compilation pipeline can be customized according to the target by "
"querying the attribute information in the target and builtin information "
"registered to each target id(cuda, opencl)."
msgstr ""
"编译管道可以根据目标定制，查询目标中的属性信息和注册到每个目标 id 的内置信息（cuda, opencl）。"

#: ../../docs/arch/index.rst:335
msgid "tvm/tir"
msgstr ""

#: ../../docs/arch/index.rst:337
msgid ""
"TIR contains the definition of the low-level program representations. We "
"use `tir::PrimFunc` to represent functions that can be transformed by TIR"
" passes. Besides the IR data structures, the tir module also defines a "
"set of builtin intrinsics and their attributes via the common Op "
"registry, as well as transformation passes in `tir/transform`."
msgstr ""
"TIR 包含低级程序表示的定义。使用 `tir::PrimFunc` 来表示可以通过 TIR pass 进行变换的函数。"
"除了 IR 数据结构外，tir 模块还通过公共 Op 注册表定义了一组内建 intrinsic 及其属性，以及在 `tir/transform` 中的变换。"

#: ../../docs/arch/index.rst:341
msgid "tvm/arith"
msgstr ""

#: ../../docs/arch/index.rst:343
msgid ""
"This module is closely tied to the TIR. One of the key problems in the "
"low-level code generation is the analysis of the indices' arithmetic "
"properties — the positiveness, variable bound, and the integer set that "
"describes the iterator space. arith module provides a collection of tools"
" that do (primarily integer) analysis. A TIR pass can use these analyses "
"to simplify and optimize the code."
msgstr ""
"这个模块与 TIR 紧密相连。低级代码生成中的一个关键问题是对索引的算术属性的分析——正定性、变量边界和描述迭代器空间的整数集。"
"Arith 模块提供了一组进行（主要是整数）分析的工具。TIR pass 可以利用这些分析来简化和优化代码。"

#: ../../docs/arch/index.rst:348
msgid "tvm/te"
msgstr ""

#: ../../docs/arch/index.rst:350
msgid ""
"The name te stands for \"tensor expression\". This is a domain-specific "
"language module that allows us to construct `tir::PrimFunc` variants "
"quickly by writing tensor expressions. Importantly, a tensor expression "
"itself is not a self-contained function that can be stored into IRModule."
" Instead, it is a fragment of IR that we can stitch together to build an "
"IRModule."
msgstr ""
"名称 te 代表“张量表达式”（tensor expression）。"
"这是领域专用语言（domain-specific language，简称 DSL）模块，"
"它允许通过编写张量表达式来快速构建 `tir::PrimFunc` 变体。"
"重要的是，张量表达式本身并不是可以存储在 IRModule 中的自包含函数。”
"相反，它是 IR 的片段，可以把它拼接在一起来构建 IRModule。"

#: ../../docs/arch/index.rst:353
msgid ""
"`te/schedule` provides a collection of scheduling primitives to control "
"the function being generated. In the future, we might bring some of these"
" scheduling components to the a `tir::PrimFunc` itself."
msgstr ""
"`te/schedule` 提供了一组调度原语来控制生成的函数。"
"未来，我们可能会把这些调度组件带到 `tir::PrimFunc` 本身。"

#: ../../docs/arch/index.rst:363
msgid "tvm/topi"
msgstr ""

#: ../../docs/arch/index.rst:364
msgid ""
"While possible to construct operators directly via TIR or tensor "
"expressions (TE) for each use case it is tedious to do so. `topi` (Tensor"
" operator inventory) provides a set of pre-defined operators (in TE or "
"TIR) defined by numpy and found in common deep learning workloads. We "
"also provide a collection of common schedule templates to obtain "
"performant implementations across different target platforms."
msgstr ""
"虽然可以通过 TIR 或张量表达式（TE）为每个用例直接构造算子，但这样做很繁琐。"
"`topi` （张量算子清单）提供了一组由 numpy 定义的预定义算子（在 TE 或 TIR 中），可在常见的深度学习工作负载中找到。"
"还提供了一组通用的调度模板，以便在不同的目标平台上实现性能。"

#: ../../docs/arch/index.rst:370
msgid "tvm/relay"
msgstr ""

#: ../../docs/arch/index.rst:371
msgid ""
"Relay is the high-level functional IR used to represent full models. "
"Various optimizations are defined in `relay.transform`. The Relay "
"compiler defines multiple dialects, and each dialect is designed to "
"support specific styles of optimization. Notable ones include QNN(for "
"importing pre-quantized models), VM(for lowering to dynamic virtual "
"machine), memory(for memory optimization)."
msgstr ""
"Relay 是用来表示完整模型的高级函数 IR。"
"在 `relay.transform` 中定义了各种优化。Relay 编译器定义了多种方言，每种方言都被设计成支持特定类型的优化。"
"值得注意的有 QNN（用于导入预量化模型）、VM（用于降级到动态虚拟机）、memory（用于内存优化）。"

#: ../../docs/arch/index.rst:384
msgid "tvm/autotvm"
msgstr ""

#: ../../docs/arch/index.rst:386
msgid ""
"AutoTVM and AutoScheduler are both components which automate search based"
" program optimization. This is rapidly evolving and primarily consists "
"of:"
msgstr ""
"AutoTVM 和 AutoScheduler 都是基于程序优化的自动搜索组件。"
"这一领域正在迅速发展，主要包括："

#: ../../docs/arch/index.rst:388
msgid "Cost models and feature extraction."
msgstr "成本模型与特征提取。"

#: ../../docs/arch/index.rst:389
msgid ""
"A record format for storing program benchmark results for cost model "
"construction."
msgstr "用于存储成本模型构建所需的程序基准结果的记录格式。"

#: ../../docs/arch/index.rst:390
msgid "A set of search policies over program transformations."
msgstr "程序变换上的一组搜索策略。"

#: ../../docs/arch/index.rst:392
msgid ""
"Automated program optimization is still an active research field. As a "
"result, we have attempted to modularize the design so that researchers "
"may quickly modify a component or apply their own algorithms via the "
"Python bindings, and customize the search and plugin their algorithms "
"from the Python binding."
msgstr ""
"自动化程序优化仍然是一个活跃的研究领域。"
"因此，尝试模块化设计，以便研究人员可以通过 Python 绑定快速修改组件或应用他们自己的算法，"
"并从 Python 绑定定制搜索和拔插他们的算法。"

#: ../../docs/arch/index.rst:402
msgid "Frontends"
msgstr "前端"

#: ../../docs/arch/index.rst:403
msgid ""
"Frontends ingest models from different frameworks into the TVM stack. "
":py:mod:`tvm.relay.frontend` is the namespace for model ingestion APIs."
msgstr ""
"前端从不同框架吸收模型到 TVM 堆栈。”
":py:mod:`tvm.relay.frontend` 是模型摄取 API 的命名空间。"

#: ../../docs/arch/index.rst:413
msgid "Security"
msgstr "安全"

#: ../../docs/arch/index.rst:421
msgid "microTVM"
msgstr ""

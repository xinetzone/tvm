# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the TVM package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: TVM \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-03-31 18:33+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../docs/reference/api/python/relay/nn.rst:19
msgid "tvm.relay.nn"
msgstr ""

#~ msgid ":py:obj:`Constant <tvm.relay.nn.Constant>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid ":py:obj:`Expr <tvm.relay.nn.Expr>`\\"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`adaptive_avg_pool1d "
#~ "<tvm.relay.nn.adaptive_avg_pool1d>`\\ \\(data\\[\\, "
#~ "output\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`adaptive_avg_pool2d "
#~ "<tvm.relay.nn.adaptive_avg_pool2d>`\\ \\(data\\[\\, "
#~ "output\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`adaptive_avg_pool3d "
#~ "<tvm.relay.nn.adaptive_avg_pool3d>`\\ \\(data\\[\\, "
#~ "output\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`adaptive_max_pool1d "
#~ "<tvm.relay.nn.adaptive_max_pool1d>`\\ \\(data\\[\\, "
#~ "output\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`adaptive_max_pool2d "
#~ "<tvm.relay.nn.adaptive_max_pool2d>`\\ \\(data\\[\\, "
#~ "output\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`adaptive_max_pool3d "
#~ "<tvm.relay.nn.adaptive_max_pool3d>`\\ \\(data\\[\\, "
#~ "output\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`avg_pool1d <tvm.relay.nn.avg_pool1d>`\\ "
#~ "\\(data\\[\\, pool\\_size\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`avg_pool2d <tvm.relay.nn.avg_pool2d>`\\ "
#~ "\\(data\\[\\, pool\\_size\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`avg_pool2d_grad <tvm.relay.nn.avg_pool2d_grad>`\\ "
#~ "\\(out\\_grad\\, data\\[\\, pool\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`avg_pool3d <tvm.relay.nn.avg_pool3d>`\\ "
#~ "\\(data\\[\\, pool\\_size\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ":py:obj:`batch_flatten <tvm.relay.nn.batch_flatten>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`batch_matmul <tvm.relay.nn.batch_matmul>`\\ "
#~ "\\(tensor\\_a\\, tensor\\_b\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`batch_norm <tvm.relay.nn.batch_norm>`\\ "
#~ "\\(data\\, gamma\\, beta\\, moving\\_mean\\, "
#~ "...\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`batch_to_space_nd <tvm.relay.nn.batch_to_space_nd>`\\"
#~ " \\(data\\, block\\_shape\\, crops\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`bias_add <tvm.relay.nn.bias_add>`\\ \\(data\\,"
#~ " bias\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`bitpack <tvm.relay.nn.bitpack>`\\ \\(data\\[\\,"
#~ " bits\\, pack\\_axis\\, bit\\_axis\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`bitserial_conv2d <tvm.relay.nn.bitserial_conv2d>`\\ "
#~ "\\(data\\, weight\\[\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`bitserial_dense <tvm.relay.nn.bitserial_dense>`\\ "
#~ "\\(data\\, weight\\[\\, units\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ":py:obj:`const <tvm.relay.nn.const>`\\ \\(value\\[\\, dtype\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv2d_gemm_weight_transform "
#~ "<tvm.relay.nn.contrib_conv2d_gemm_weight_transform>`\\ \\(...\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv2d_gemm_without_weight_transform "
#~ "<tvm.relay.nn.contrib_conv2d_gemm_without_weight_transform>`\\ "
#~ "\\(...\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv2d_nchwc "
#~ "<tvm.relay.nn.contrib_conv2d_nchwc>`\\ \\(data\\, "
#~ "kernel\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv2d_winograd_nnpack_weight_transform "
#~ "<tvm.relay.nn.contrib_conv2d_winograd_nnpack_weight_transform>`\\ "
#~ "\\(...\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv2d_winograd_weight_transform "
#~ "<tvm.relay.nn.contrib_conv2d_winograd_weight_transform>`\\ "
#~ "\\(...\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv2d_winograd_without_weight_transform "
#~ "<tvm.relay.nn.contrib_conv2d_winograd_without_weight_transform>`\\ "
#~ "\\(...\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv3d_winograd_weight_transform "
#~ "<tvm.relay.nn.contrib_conv3d_winograd_weight_transform>`\\ "
#~ "\\(...\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv3d_winograd_without_weight_transform "
#~ "<tvm.relay.nn.contrib_conv3d_winograd_without_weight_transform>`\\ "
#~ "\\(...\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_dense_pack <tvm.relay.nn.contrib_dense_pack>`\\"
#~ " \\(data\\, weight\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_depthwise_conv2d_nchwc "
#~ "<tvm.relay.nn.contrib_depthwise_conv2d_nchwc>`\\ \\(data\\, "
#~ "kernel\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv1d <tvm.relay.nn.conv1d>`\\ \\(data\\, "
#~ "weight\\[\\, strides\\, padding\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv1d_transpose <tvm.relay.nn.conv1d_transpose>`\\ "
#~ "\\(data\\, weight\\[\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv2d <tvm.relay.nn.conv2d>`\\ \\(data\\, "
#~ "weight\\[\\, strides\\, padding\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv2d_transpose <tvm.relay.nn.conv2d_transpose>`\\ "
#~ "\\(data\\, weight\\[\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv3d <tvm.relay.nn.conv3d>`\\ \\(data\\, "
#~ "weight\\[\\, strides\\, padding\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv3d_transpose <tvm.relay.nn.conv3d_transpose>`\\ "
#~ "\\(data\\, weight\\[\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`correlation <tvm.relay.nn.correlation>`\\ "
#~ "\\(data1\\, data2\\, kernel\\_size\\, ...\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`cross_entropy <tvm.relay.nn.cross_entropy>`\\ "
#~ "\\(predictions\\, targets\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`cross_entropy_with_logits "
#~ "<tvm.relay.nn.cross_entropy_with_logits>`\\ \\(predictions\\,"
#~ " targets\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`deformable_conv2d <tvm.relay.nn.deformable_conv2d>`\\"
#~ " \\(data\\, offset\\, weight\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`dense <tvm.relay.nn.dense>`\\ \\(data\\, "
#~ "weight\\[\\, units\\, out\\_dtype\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`depth_to_space <tvm.relay.nn.depth_to_space>`\\ "
#~ "\\(data\\, block\\_size\\[\\, layout\\, mode\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`dilate <tvm.relay.nn.dilate>`\\ \\(data\\, "
#~ "strides\\[\\, dilation\\_value\\]\\)"
#~ msgstr ""

#~ msgid ":py:obj:`dropout <tvm.relay.nn.dropout>`\\ \\(data\\[\\, rate\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`dropout_raw <tvm.relay.nn.dropout_raw>`\\ "
#~ "\\(data\\[\\, rate\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`fast_softmax <tvm.relay.nn.fast_softmax>`\\ "
#~ "\\(data\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`fifo_buffer <tvm.relay.nn.fifo_buffer>`\\ "
#~ "\\(data\\, buffer\\, axis\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_pad_tuple1d <tvm.relay.nn.get_pad_tuple1d>`\\ "
#~ "\\(padding\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_pad_tuple2d <tvm.relay.nn.get_pad_tuple2d>`\\ "
#~ "\\(padding\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_pad_tuple3d <tvm.relay.nn.get_pad_tuple3d>`\\ "
#~ "\\(padding\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`global_avg_pool1d <tvm.relay.nn.global_avg_pool1d>`\\"
#~ " \\(data\\[\\, layout\\, out\\_layout\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`global_avg_pool2d <tvm.relay.nn.global_avg_pool2d>`\\"
#~ " \\(data\\[\\, layout\\, out\\_layout\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`global_avg_pool3d <tvm.relay.nn.global_avg_pool3d>`\\"
#~ " \\(data\\[\\, layout\\, out\\_layout\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`global_max_pool1d <tvm.relay.nn.global_max_pool1d>`\\"
#~ " \\(data\\[\\, layout\\, out\\_layout\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`global_max_pool2d <tvm.relay.nn.global_max_pool2d>`\\"
#~ " \\(data\\[\\, layout\\, out\\_layout\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`global_max_pool3d <tvm.relay.nn.global_max_pool3d>`\\"
#~ " \\(data\\[\\, layout\\, out\\_layout\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`group_norm <tvm.relay.nn.group_norm>`\\ "
#~ "\\(data\\, gamma\\, beta\\, num\\_groups\\[\\, "
#~ "...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`instance_norm <tvm.relay.nn.instance_norm>`\\ "
#~ "\\(data\\, gamma\\, beta\\[\\, axis\\, "
#~ "...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`l2_normalize <tvm.relay.nn.l2_normalize>`\\ "
#~ "\\(data\\, eps\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`layer_norm <tvm.relay.nn.layer_norm>`\\ "
#~ "\\(data\\, gamma\\, beta\\[\\, axis\\, "
#~ "...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`leaky_relu <tvm.relay.nn.leaky_relu>`\\ "
#~ "\\(data\\[\\, alpha\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`log_softmax <tvm.relay.nn.log_softmax>`\\ "
#~ "\\(data\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`lrn <tvm.relay.nn.lrn>`\\ \\(data\\[\\, "
#~ "size\\, axis\\, bias\\, alpha\\, beta\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`matmul <tvm.relay.nn.matmul>`\\ \\(tensor\\_a\\,"
#~ " tensor\\_b\\[\\, units\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`max_pool1d <tvm.relay.nn.max_pool1d>`\\ "
#~ "\\(data\\[\\, pool\\_size\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`max_pool2d <tvm.relay.nn.max_pool2d>`\\ "
#~ "\\(data\\[\\, pool\\_size\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`max_pool2d_grad <tvm.relay.nn.max_pool2d_grad>`\\ "
#~ "\\(out\\_grad\\, data\\[\\, pool\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`max_pool3d <tvm.relay.nn.max_pool3d>`\\ "
#~ "\\(data\\[\\, pool\\_size\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`mirror_pad <tvm.relay.nn.mirror_pad>`\\ "
#~ "\\(data\\, pad\\_width\\[\\, mode\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`nll_loss <tvm.relay.nn.nll_loss>`\\ "
#~ "\\(predictions\\, targets\\, weights\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`pad <tvm.relay.nn.pad>`\\ \\(data\\, "
#~ "pad\\_width\\[\\, pad\\_value\\, pad\\_mode\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`prelu <tvm.relay.nn.prelu>`\\ \\(data\\, "
#~ "alpha\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid ":py:obj:`relu <tvm.relay.nn.relu>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid ":py:obj:`softmax <tvm.relay.nn.softmax>`\\ \\(data\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`space_to_batch_nd <tvm.relay.nn.space_to_batch_nd>`\\"
#~ " \\(data\\, block\\_shape\\, paddings\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`space_to_depth <tvm.relay.nn.space_to_depth>`\\ "
#~ "\\(data\\, block\\_size\\[\\, layout\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`sparse_add <tvm.relay.nn.sparse_add>`\\ "
#~ "\\(dense\\_mat\\, sparse\\_mat\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`sparse_dense <tvm.relay.nn.sparse_dense>`\\ "
#~ "\\(dense\\_mat\\, sparse\\_mat\\[\\, sparse\\_lhs\\]\\)"
#~ msgstr ""

#~ msgid ":py:obj:`sparse_transpose <tvm.relay.nn.sparse_transpose>`\\ \\(x\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`upsampling <tvm.relay.nn.upsampling>`\\ "
#~ "\\(data\\[\\, scale\\_h\\, scale\\_w\\, layout\\,"
#~ " ...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`upsampling3d <tvm.relay.nn.upsampling3d>`\\ "
#~ "\\(data\\[\\, scale\\_d\\, scale\\_h\\, ...\\]\\)"
#~ msgstr ""

#~ msgid ":py:obj:`checked_type <tvm.relay.nn.Expr.checked_type>`\\"
#~ msgstr ""

#~ msgid "Neural network related operators."
#~ msgstr ""

#~ msgid "**Classes:**"
#~ msgstr ""

#~ msgid ":py:obj:`Constant <tvm.relay.op.nn.Constant>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "A constant expression in Relay."
#~ msgstr ""

#~ msgid ":py:obj:`Expr <tvm.relay.op.nn.Expr>`\\"
#~ msgstr ""

#~ msgid "alias of :py:class:`tvm.ir.expr.RelayExpr`"
#~ msgstr ""

#~ msgid "**Functions:**"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`adaptive_avg_pool1d "
#~ "<tvm.relay.op.nn.adaptive_avg_pool1d>`\\ \\(data\\[\\, "
#~ "output\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "1D adaptive average pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`adaptive_avg_pool2d "
#~ "<tvm.relay.op.nn.adaptive_avg_pool2d>`\\ \\(data\\[\\, "
#~ "output\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "2D adaptive average pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`adaptive_avg_pool3d "
#~ "<tvm.relay.op.nn.adaptive_avg_pool3d>`\\ \\(data\\[\\, "
#~ "output\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "3D adaptive avg pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`adaptive_max_pool1d "
#~ "<tvm.relay.op.nn.adaptive_max_pool1d>`\\ \\(data\\[\\, "
#~ "output\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "1D adaptive max pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`adaptive_max_pool2d "
#~ "<tvm.relay.op.nn.adaptive_max_pool2d>`\\ \\(data\\[\\, "
#~ "output\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "2D adaptive max pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`adaptive_max_pool3d "
#~ "<tvm.relay.op.nn.adaptive_max_pool3d>`\\ \\(data\\[\\, "
#~ "output\\_size\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "3D adaptive max pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`avg_pool1d <tvm.relay.op.nn.avg_pool1d>`\\ "
#~ "\\(data\\[\\, pool\\_size\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "1D average pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`avg_pool2d <tvm.relay.op.nn.avg_pool2d>`\\ "
#~ "\\(data\\[\\, pool\\_size\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "2D average pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`avg_pool2d_grad <tvm.relay.op.nn.avg_pool2d_grad>`\\"
#~ " \\(out\\_grad\\, data\\[\\, pool\\_size\\, "
#~ "...\\]\\)"
#~ msgstr ""

#~ msgid "Gradient of 2D average pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`avg_pool3d <tvm.relay.op.nn.avg_pool3d>`\\ "
#~ "\\(data\\[\\, pool\\_size\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "3D average pooling operator."
#~ msgstr ""

#~ msgid ":py:obj:`batch_flatten <tvm.relay.op.nn.batch_flatten>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "BatchFlatten."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`batch_matmul <tvm.relay.op.nn.batch_matmul>`\\ "
#~ "\\(tensor\\_a\\, tensor\\_b\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Compute batch matrix multiplication of `tensor_a` and `tensor_b`."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`batch_norm <tvm.relay.op.nn.batch_norm>`\\ "
#~ "\\(data\\, gamma\\, beta\\, moving\\_mean\\, "
#~ "...\\)"
#~ msgstr ""

#~ msgid "Batch normalization layer (Ioffe and Szegedy, 2014)."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`batch_to_space_nd "
#~ "<tvm.relay.op.nn.batch_to_space_nd>`\\ \\(data\\, "
#~ "block\\_shape\\, crops\\)"
#~ msgstr ""

#~ msgid "Reshape the batch dimension into spatial dimensions."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`bias_add <tvm.relay.op.nn.bias_add>`\\ \\(data\\,"
#~ " bias\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid "add_bias operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`bitpack <tvm.relay.op.nn.bitpack>`\\ "
#~ "\\(data\\[\\, bits\\, pack\\_axis\\, bit\\_axis\\,"
#~ " ...\\]\\)"
#~ msgstr ""

#~ msgid "Tensor packing for bitserial operations."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`bitserial_conv2d <tvm.relay.op.nn.bitserial_conv2d>`\\"
#~ " \\(data\\, weight\\[\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "2D convolution using bitserial computation."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`bitserial_dense <tvm.relay.op.nn.bitserial_dense>`\\"
#~ " \\(data\\, weight\\[\\, units\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Bitserial Dense operator."
#~ msgstr ""

#~ msgid ":py:obj:`const <tvm.relay.op.nn.const>`\\ \\(value\\[\\, dtype\\]\\)"
#~ msgstr ""

#~ msgid "Create a constant value."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv2d_gemm_weight_transform "
#~ "<tvm.relay.op.nn.contrib_conv2d_gemm_weight_transform>`\\ "
#~ "\\(...\\)"
#~ msgstr ""

#~ msgid "Weight Transformation part for 2D convolution with gemm algorithm."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv2d_gemm_without_weight_transform "
#~ "<tvm.relay.op.nn.contrib_conv2d_gemm_without_weight_transform>`\\ "
#~ "\\(...\\)"
#~ msgstr ""

#~ msgid "2D convolution with gemm algorithm."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv2d_nchwc "
#~ "<tvm.relay.op.nn.contrib_conv2d_nchwc>`\\ \\(data\\, "
#~ "kernel\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Variant of 2D convolution."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv2d_winograd_nnpack_weight_transform "
#~ "<tvm.relay.op.nn.contrib_conv2d_winograd_nnpack_weight_transform>`\\"
#~ " \\(...\\)"
#~ msgstr ""

#~ msgid "Weight Transformation part for 2D convolution with winograd algorithm."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv2d_winograd_weight_transform "
#~ "<tvm.relay.op.nn.contrib_conv2d_winograd_weight_transform>`\\ "
#~ "\\(...\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv2d_winograd_without_weight_transform "
#~ "<tvm.relay.op.nn.contrib_conv2d_winograd_without_weight_transform>`\\"
#~ " \\(...\\)"
#~ msgstr ""

#~ msgid "2D convolution with winograd algorithm."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv3d_winograd_weight_transform "
#~ "<tvm.relay.op.nn.contrib_conv3d_winograd_weight_transform>`\\ "
#~ "\\(...\\)"
#~ msgstr ""

#~ msgid "Weight Transformation part for 3D convolution with winograd algorithm."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_conv3d_winograd_without_weight_transform "
#~ "<tvm.relay.op.nn.contrib_conv3d_winograd_without_weight_transform>`\\"
#~ " \\(...\\)"
#~ msgstr ""

#~ msgid "3D convolution with winograd algorithm."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_dense_pack "
#~ "<tvm.relay.op.nn.contrib_dense_pack>`\\ \\(data\\, "
#~ "weight\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Dense operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`contrib_depthwise_conv2d_nchwc "
#~ "<tvm.relay.op.nn.contrib_depthwise_conv2d_nchwc>`\\ \\(data\\,"
#~ " kernel\\)"
#~ msgstr ""

#~ msgid "Variant of 2D depthwise convolution."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv1d <tvm.relay.op.nn.conv1d>`\\ \\(data\\, "
#~ "weight\\[\\, strides\\, padding\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "1D convolution."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv1d_transpose <tvm.relay.op.nn.conv1d_transpose>`\\"
#~ " \\(data\\, weight\\[\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "One dimensional transposed convolution operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv2d <tvm.relay.op.nn.conv2d>`\\ \\(data\\, "
#~ "weight\\[\\, strides\\, padding\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "2D convolution."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv2d_backward_weight "
#~ "<tvm.relay.op.nn.conv2d_backward_weight>`\\ \\(grad\\, "
#~ "data\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "The gradient of conv2d with respect to weight."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv2d_transpose <tvm.relay.op.nn.conv2d_transpose>`\\"
#~ " \\(data\\, weight\\[\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Two dimensional transposed convolution operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv3d <tvm.relay.op.nn.conv3d>`\\ \\(data\\, "
#~ "weight\\[\\, strides\\, padding\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "3D convolution."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`conv3d_transpose <tvm.relay.op.nn.conv3d_transpose>`\\"
#~ " \\(data\\, weight\\[\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "3D transpose convolution."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`correlation <tvm.relay.op.nn.correlation>`\\ "
#~ "\\(data1\\, data2\\, kernel\\_size\\, ...\\)"
#~ msgstr ""

#~ msgid "Applies correlation to inputs."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`cross_entropy <tvm.relay.op.nn.cross_entropy>`\\ "
#~ "\\(predictions\\, targets\\)"
#~ msgstr ""

#~ msgid "CrossEntropy without logits."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`cross_entropy_with_logits "
#~ "<tvm.relay.op.nn.cross_entropy_with_logits>`\\ \\(predictions\\,"
#~ " targets\\)"
#~ msgstr ""

#~ msgid "CrossEntropy with logits."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`deformable_conv2d "
#~ "<tvm.relay.op.nn.deformable_conv2d>`\\ \\(data\\, "
#~ "offset\\, weight\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Deformable 2d convolution."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`dense <tvm.relay.op.nn.dense>`\\ \\(data\\, "
#~ "weight\\[\\, units\\, out\\_dtype\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`depth_to_space <tvm.relay.op.nn.depth_to_space>`\\ "
#~ "\\(data\\, block\\_size\\[\\, layout\\, mode\\]\\)"
#~ msgstr ""

#~ msgid "Convert channels into spatial blocks."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`dilate <tvm.relay.op.nn.dilate>`\\ \\(data\\, "
#~ "strides\\[\\, dilation\\_value\\]\\)"
#~ msgstr ""

#~ msgid "Dilate data with given dilation value (0 by default)."
#~ msgstr ""

#~ msgid ":py:obj:`dropout <tvm.relay.op.nn.dropout>`\\ \\(data\\[\\, rate\\]\\)"
#~ msgstr ""

#~ msgid "Applies the dropout operation to the input array."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`dropout_raw <tvm.relay.op.nn.dropout_raw>`\\ "
#~ "\\(data\\[\\, rate\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`fast_softmax <tvm.relay.op.nn.fast_softmax>`\\ "
#~ "\\(data\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid "Computes softmax."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`fifo_buffer <tvm.relay.op.nn.fifo_buffer>`\\ "
#~ "\\(data\\, buffer\\, axis\\)"
#~ msgstr ""

#~ msgid ""
#~ "FIFO buffer to enable computation reuse"
#~ " in CNNs with sliding indow input"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_pad_tuple1d <tvm.relay.op.nn.get_pad_tuple1d>`\\"
#~ " \\(padding\\)"
#~ msgstr ""

#~ msgid ""
#~ "Common code to get the 1 "
#~ "dimensional pad option :param padding: "
#~ "Padding size :type padding: Union[int, "
#~ "Tuple[int, ...]]"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_pad_tuple2d <tvm.relay.op.nn.get_pad_tuple2d>`\\"
#~ " \\(padding\\)"
#~ msgstr ""

#~ msgid ""
#~ "Common code to get the pad option"
#~ " :param padding: Padding size :type "
#~ "padding: Union[int, Tuple[int, ...]]"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`get_pad_tuple3d <tvm.relay.op.nn.get_pad_tuple3d>`\\"
#~ " \\(padding\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`global_avg_pool1d "
#~ "<tvm.relay.op.nn.global_avg_pool1d>`\\ \\(data\\[\\, "
#~ "layout\\, out\\_layout\\]\\)"
#~ msgstr ""

#~ msgid "1D global average pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`global_avg_pool2d "
#~ "<tvm.relay.op.nn.global_avg_pool2d>`\\ \\(data\\[\\, "
#~ "layout\\, out\\_layout\\]\\)"
#~ msgstr ""

#~ msgid "2D global average pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`global_avg_pool3d "
#~ "<tvm.relay.op.nn.global_avg_pool3d>`\\ \\(data\\[\\, "
#~ "layout\\, out\\_layout\\]\\)"
#~ msgstr ""

#~ msgid "3D global average pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`global_max_pool1d "
#~ "<tvm.relay.op.nn.global_max_pool1d>`\\ \\(data\\[\\, "
#~ "layout\\, out\\_layout\\]\\)"
#~ msgstr ""

#~ msgid "1D global maximum pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`global_max_pool2d "
#~ "<tvm.relay.op.nn.global_max_pool2d>`\\ \\(data\\[\\, "
#~ "layout\\, out\\_layout\\]\\)"
#~ msgstr ""

#~ msgid "2D global maximum pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`global_max_pool3d "
#~ "<tvm.relay.op.nn.global_max_pool3d>`\\ \\(data\\[\\, "
#~ "layout\\, out\\_layout\\]\\)"
#~ msgstr ""

#~ msgid "3D global maximum pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`group_norm <tvm.relay.op.nn.group_norm>`\\ "
#~ "\\(data\\, gamma\\, beta\\, num\\_groups\\[\\, "
#~ "...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Group normalization normalizes over group "
#~ "of channels for each training examples."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`instance_norm <tvm.relay.op.nn.instance_norm>`\\ "
#~ "\\(data\\, gamma\\, beta\\[\\, axis\\, "
#~ "...\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Instance Normalization (Ulyanov and et "
#~ "al., 2016) Applies instance normalization "
#~ "to the n-dimensional input array."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`l2_normalize <tvm.relay.op.nn.l2_normalize>`\\ "
#~ "\\(data\\, eps\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid "Perform L2 normalization on the input data"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`layer_norm <tvm.relay.op.nn.layer_norm>`\\ "
#~ "\\(data\\, gamma\\, beta\\[\\, axis\\, "
#~ "...\\]\\)"
#~ msgstr ""

#~ msgid "Layer normalization (Lei Ba and et al., 2016)."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`leaky_relu <tvm.relay.op.nn.leaky_relu>`\\ "
#~ "\\(data\\[\\, alpha\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does Leaky version of a "
#~ "Rectified Linear Unit."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`log_softmax <tvm.relay.op.nn.log_softmax>`\\ "
#~ "\\(data\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid "Computes log softmax."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`lrn <tvm.relay.op.nn.lrn>`\\ \\(data\\[\\, "
#~ "size\\, axis\\, bias\\, alpha\\, beta\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does local response normalization."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`matmul <tvm.relay.op.nn.matmul>`\\ "
#~ "\\(tensor\\_a\\, tensor\\_b\\[\\, units\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Matmul operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`max_pool1d <tvm.relay.op.nn.max_pool1d>`\\ "
#~ "\\(data\\[\\, pool\\_size\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "1D maximum pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`max_pool2d <tvm.relay.op.nn.max_pool2d>`\\ "
#~ "\\(data\\[\\, pool\\_size\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "2D maximum pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`max_pool2d_grad <tvm.relay.op.nn.max_pool2d_grad>`\\"
#~ " \\(out\\_grad\\, data\\[\\, pool\\_size\\, "
#~ "...\\]\\)"
#~ msgstr ""

#~ msgid "Gradient of 2D maximum pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`max_pool3d <tvm.relay.op.nn.max_pool3d>`\\ "
#~ "\\(data\\[\\, pool\\_size\\, strides\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "3D maximum pooling operator."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`mirror_pad <tvm.relay.op.nn.mirror_pad>`\\ "
#~ "\\(data\\, pad\\_width\\[\\, mode\\]\\)"
#~ msgstr ""

#~ msgid "MirrorPadding"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`nll_loss <tvm.relay.op.nn.nll_loss>`\\ "
#~ "\\(predictions\\, targets\\, weights\\[\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "Negative log likelihood loss."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`pad <tvm.relay.op.nn.pad>`\\ \\(data\\, "
#~ "pad\\_width\\[\\, pad\\_value\\, pad\\_mode\\]\\)"
#~ msgstr ""

#~ msgid "Padding"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`prelu <tvm.relay.op.nn.prelu>`\\ \\(data\\, "
#~ "alpha\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid ":py:obj:`relu <tvm.relay.op.nn.relu>`\\ \\(data\\)"
#~ msgstr ""

#~ msgid "Rectified linear unit."
#~ msgstr ""

#~ msgid ":py:obj:`softmax <tvm.relay.op.nn.softmax>`\\ \\(data\\[\\, axis\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`space_to_batch_nd "
#~ "<tvm.relay.op.nn.space_to_batch_nd>`\\ \\(data\\, "
#~ "block\\_shape\\, paddings\\)"
#~ msgstr ""

#~ msgid ""
#~ "Divide spatial dimensions of the data"
#~ " into a grid of blocks and "
#~ "interleave them into batch dim."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`space_to_depth <tvm.relay.op.nn.space_to_depth>`\\ "
#~ "\\(data\\, block\\_size\\[\\, layout\\]\\)"
#~ msgstr ""

#~ msgid "Convert spatial blocks into channels."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`sparse_add <tvm.relay.op.nn.sparse_add>`\\ "
#~ "\\(dense\\_mat\\, sparse\\_mat\\)"
#~ msgstr ""

#~ msgid ""
#~ "Computes the matrix addition of "
#~ "`dense_mat` and `sparse_mat`, where "
#~ "`dense_mat` is a dense matrix and "
#~ "`sparse_mat` is a sparse (CSR) "
#~ "namedtuple with fields `data`, `indices`, "
#~ "and `indptr`."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`sparse_dense <tvm.relay.op.nn.sparse_dense>`\\ "
#~ "\\(dense\\_mat\\, sparse\\_mat\\[\\, sparse\\_lhs\\]\\)"
#~ msgstr ""

#~ msgid ""
#~ "Computes the matrix multiplication of "
#~ "`dense_mat` and `sparse_mat`, where "
#~ "`dense_mat` is a dense matrix and "
#~ "`sparse_mat` is a sparse (either BSR "
#~ "or CSR) namedtuple with fields `data`,"
#~ " `indices`, and `indptr`."
#~ msgstr ""

#~ msgid ":py:obj:`sparse_transpose <tvm.relay.op.nn.sparse_transpose>`\\ \\(x\\)"
#~ msgstr ""

#~ msgid ""
#~ "Computes the fast matrix transpose of"
#~ " x, where x is a sparse tensor"
#~ " in CSR format (represented as a "
#~ "namedtuple with fields `data`, `indices`, "
#~ "and `indptr`)."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`upsampling <tvm.relay.op.nn.upsampling>`\\ "
#~ "\\(data\\[\\, scale\\_h\\, scale\\_w\\, layout\\,"
#~ " ...\\]\\)"
#~ msgstr ""

#~ msgid "Upsampling."
#~ msgstr ""

#~ msgid ""
#~ ":py:obj:`upsampling3d <tvm.relay.op.nn.upsampling3d>`\\ "
#~ "\\(data\\[\\, scale\\_d\\, scale\\_h\\, ...\\]\\)"
#~ msgstr ""

#~ msgid "3D Upsampling."
#~ msgstr ""

#~ msgid "参数"
#~ msgstr ""

#~ msgid "The data content of the constant expression."
#~ msgstr ""

#~ msgid ":py:obj:`checked_type <tvm.relay.op.nn.Expr.checked_type>`\\"
#~ msgstr ""

#~ msgid "Get the checked type of tvm.relay.Expr."
#~ msgstr ""

#~ msgid "1D adaptive average pooling operator. This operator is experimental."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 1D average value calculation"
#~ " across each window represented by W."
#~ msgstr ""

#~ msgid ""
#~ "In the default case, where the "
#~ "data_layout is `NCW` a data Tensor "
#~ "with shape `(batch_size, in_channels, width)`,"
#~ " to produce an output Tensor with "
#~ "shape (batch_size, in_channels, output_width)."
#~ msgstr ""

#~ msgid ""
#~ "The pooling kernel and stride sizes "
#~ "are automatically chosen for desired "
#~ "output sizes."
#~ msgstr ""

#~ msgid "For output_size:"
#~ msgstr ""

#~ msgid ""
#~ "If this argument is not provided, "
#~ "input height and width will be "
#~ "used as output width."
#~ msgstr ""

#~ msgid ""
#~ "If a single integer is provided "
#~ "for output_size, the output size is "
#~ "(N x C x output_size) for any "
#~ "input (NCW)."
#~ msgstr ""

#~ msgid "The input data to the operator."
#~ msgstr ""

#~ msgid "Output height and width."
#~ msgstr ""

#~ msgid "Layout of the input."
#~ msgstr ""

#~ msgid "Layout of the output."
#~ msgstr ""

#~ msgid "返回"
#~ msgstr ""

#~ msgid "**result** -- The computed result."
#~ msgstr ""

#~ msgid "返回类型"
#~ msgstr ""

#~ msgid "2D adaptive average pooling operator. This operator is experimental."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 2D average value calculation"
#~ " across each window represented by "
#~ "WxH."
#~ msgstr ""

#~ msgid ""
#~ "In the default case, where the "
#~ "data_layout is `NCHW` a data Tensor "
#~ "with shape `(batch_size, in_channels, height,"
#~ " width)`, to produce an output Tensor"
#~ " with shape (batch_size, in_channels, "
#~ "output_height, output_width)."
#~ msgstr ""

#~ msgid ""
#~ "If this argument is not provided, "
#~ "input height and width will be "
#~ "used as output height and width."
#~ msgstr ""

#~ msgid ""
#~ "If a single integer is provided "
#~ "for output_size, the output size is "
#~ "(N x C x output_size x "
#~ "output_size) for any input (NCHW)."
#~ msgstr ""

#~ msgid ""
#~ "If a tuple of integers (height, "
#~ "width) are provided for output_size, the"
#~ " output size is (N x C x "
#~ "height x width) for any input "
#~ "(NCHW)."
#~ msgstr ""

#~ msgid "3D adaptive avg pooling operator. This operator is experimental."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 3D avg value calculation "
#~ "across each window represented by DxWxH."
#~ msgstr ""

#~ msgid ""
#~ "In the default case, where the "
#~ "data_layout is `NCDHW` a data Tensor "
#~ "with shape `(batch_size, in_channels, depth,"
#~ " height, width)`, to produce an "
#~ "output Tensor with shape (batch_size, "
#~ "in_channels, output_depth, output_height, "
#~ "output_width)."
#~ msgstr ""

#~ msgid ""
#~ "If this argument is not provided, "
#~ "input depth, height and width will "
#~ "be used as output depth, height "
#~ "and width."
#~ msgstr ""

#~ msgid ""
#~ "If a single integer is provided "
#~ "for output_size, the output size is "
#~ "(N x C x output_size x output_size"
#~ " x output_size) for any input "
#~ "(NCDHW)."
#~ msgstr ""

#~ msgid ""
#~ "If a tuple of integers (depth, "
#~ "height, width) are provided for "
#~ "output_size, the output size is (N "
#~ "x C x depth x height x "
#~ "width) for any input (NCDHW)."
#~ msgstr ""

#~ msgid "1D adaptive max pooling operator. This operator is experimental."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 1D max value calculation "
#~ "across each window represented by W."
#~ msgstr ""

#~ msgid "2D adaptive max pooling operator. This operator is experimental."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 2D max value calculation "
#~ "across each window represented by WxH."
#~ msgstr ""

#~ msgid "3D adaptive max pooling operator. This operator is experimental."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 3D max value calculation "
#~ "across each window represented by DxWxH."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 1D average value calculation"
#~ " with in pool_size sized window by"
#~ " striding defined by stride"
#~ msgstr ""

#~ msgid ""
#~ "In the default case, where the "
#~ "data_layout is `NCW` a data Tensor "
#~ "with shape `(batch_size, channels, width)`,"
#~ " to produce an output Tensor."
#~ msgstr ""

#~ msgid ""
#~ "The ceil_mode is used to take ceil"
#~ " or floor while computing out shape."
#~ " count_include_pad indicates including or "
#~ "excluding padded input values in "
#~ "computation. This operator accepts data "
#~ "layout specification."
#~ msgstr ""

#~ msgid "The size of window for pooling."
#~ msgstr ""

#~ msgid "The strides of pooling."
#~ msgstr ""

#~ msgid "The dilation of pooling."
#~ msgstr ""

#~ msgid "The padding for pooling."
#~ msgstr ""

#~ msgid "Layout of the output"
#~ msgstr ""

#~ msgid "To enable or disable ceil while pooling."
#~ msgstr ""

#~ msgid "To include padding to compute the average."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 2D average value calculation"
#~ " with in pool_size sized window by"
#~ " striding defined by stride"
#~ msgstr ""

#~ msgid ""
#~ "In the default case, where the "
#~ "data_layout is `NCHW` a data Tensor "
#~ "with shape `(batch_size, in_channels, height,"
#~ " width)`, to produce an output Tensor"
#~ " with the following rule:"
#~ msgstr ""

#~ msgid "with data of shape (b, c, h, w), pool_size (kh, kw)"
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{out}(b, c, y, x)  = \\frac{1}{kh"
#~ " * kw} \\sum_{m=0}^{kh-1} \\sum_{n=0}^{kw-1}\n"
#~ ""
#~ "     \\mbox{data}(b, c, \\mbox{stride}[0] *"
#~ " y + m, \\mbox{stride}[1] * x +"
#~ " n)"
#~ msgstr ""

#~ msgid ""
#~ "Padding is applied to data before "
#~ "the computation. ceil_mode is used to"
#~ " take ceil or floor while computing"
#~ " out shape. count_include_pad indicates "
#~ "including or excluding padded input "
#~ "values in computation. This operator "
#~ "accepts data layout specification."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes out_grad and data"
#~ " as input and calculates gradient of"
#~ " avg_pool2d."
#~ msgstr ""

#~ msgid "The output gradient"
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 3D average value calculation"
#~ " with in pool_size sized window by"
#~ " striding defined by stride"
#~ msgstr ""

#~ msgid ""
#~ "In the default case, where the "
#~ "data_layout is `NCDHW` a data Tensor "
#~ "with shape `(batch_size, channels, depth, "
#~ "height, width)`, to produce an output"
#~ " Tensor."
#~ msgstr ""

#~ msgid ""
#~ "This operator flattens all the "
#~ "dimensions except for the batch "
#~ "dimension. which results a 2D output."
#~ msgstr ""

#~ msgid ""
#~ "For data with shape ``(d1, d2, "
#~ "..., dk)`` batch_flatten(data) returns "
#~ "reshaped output of shape ``(d1, "
#~ "d2*...*dk)``."
#~ msgstr ""

#~ msgid "**result** -- The Flattened result."
#~ msgstr ""

#~ msgid ""
#~ "Both `tensor_a` and `tensor_b` can be"
#~ " transposed. For legacy reason, we "
#~ "use NT format (transpose_a=False, "
#~ "transpose_b=True) by default."
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{batch_matmul}(A, B)[i, :, :] = "
#~ "\\mbox{matmul}(A[i, :, :], B[i, :, :])"
#~ msgstr ""

#~ msgid "The first input."
#~ msgstr ""

#~ msgid "The second input."
#~ msgstr ""

#~ msgid "Specifies the output data type for mixed precision batch matmul."
#~ msgstr ""

#~ msgid "Whether the first tensor is in transposed format."
#~ msgstr ""

#~ msgid "Whether the second tensor is in transposed format."
#~ msgstr ""

#~ msgid ""
#~ "Batch normalization layer (Ioffe and "
#~ "Szegedy, 2014). Normalizes the input at"
#~ " each batch, i.e. applies a "
#~ "transformation that maintains the mean "
#~ "activation close to 0 and the "
#~ "activation standard deviation close to "
#~ "1."
#~ msgstr ""

#~ msgid ""
#~ "data\\_mean[i] = mean(data[:,i,:,...]) \\\\\n"
#~ "data\\_var[i] = var(data[:,i,:,...])"
#~ msgstr ""

#~ msgid ""
#~ "Then compute the normalized output, "
#~ "which has the same shape as input,"
#~ " as following:"
#~ msgstr ""

#~ msgid ""
#~ "out[:,i,:,...] = \\frac{data[:,i,:,...] - "
#~ "data\\_mean[i]}{\\sqrt{data\\_var[i]+\\epsilon}}\n"
#~ "    * gamma[i] + beta[i]"
#~ msgstr ""

#~ msgid ""
#~ "Both *mean* and *var* returns a "
#~ "scalar by treating the input as a"
#~ " vector."
#~ msgstr ""

#~ msgid ""
#~ "Assume the input has size *k* on"
#~ " axis 1, then both ``gamma`` and "
#~ "``beta`` have shape *(k,)*."
#~ msgstr ""

#~ msgid ""
#~ "Besides the inputs and the outputs, "
#~ "this operator accepts two auxiliary "
#~ "states, ``moving_mean`` and ``moving_var``, "
#~ "which are *k*-length vectors. They are"
#~ " global statistics for the whole "
#~ "dataset, which are updated by"
#~ msgstr ""

#~ msgid ""
#~ "The parameter ``axis`` specifies which "
#~ "axis of the input shape denotes "
#~ "the 'channel' (separately normalized groups)."
#~ "  The default is 1. Specifying -1 "
#~ "sets the channel axis to be the"
#~ " last item in the input shape."
#~ msgstr ""

#~ msgid "This operator can be optimized away for inference."
#~ msgstr ""

#~ msgid "Input to which batch_norm will be applied."
#~ msgstr ""

#~ msgid "The gamma scale factor."
#~ msgstr ""

#~ msgid "The beta offset factor."
#~ msgstr ""

#~ msgid "Running mean of input,"
#~ msgstr ""

#~ msgid "Running variance of input."
#~ msgstr ""

#~ msgid "Specify along which shape axis the channel is specified."
#~ msgstr ""

#~ msgid "Small float added to variance to avoid dividing by zero."
#~ msgstr ""

#~ msgid ""
#~ "If True, add offset of beta to "
#~ "normalized tensor, If False, beta is "
#~ "ignored."
#~ msgstr ""

#~ msgid ""
#~ "If true, multiply by gamma. If "
#~ "False, gamma is not used. When the"
#~ " next layer is piecewise linear (also"
#~ " e.g. nn.relu), this can be disabled"
#~ " since the scaling will be done "
#~ "by the next layer."
#~ msgstr ""

#~ msgid ""
#~ "**result** -- Tuple of normed data "
#~ "(same shape as input), new running "
#~ "mean (k-length vector), and new running"
#~ " variance (k-length vector)"
#~ msgstr ""

#~ msgid "N-D with shape [batch, spatial_shape, remaining_shape]"
#~ msgstr ""

#~ msgid ""
#~ "1-D of size [M] where M is "
#~ "number of spatial dims, specifies block"
#~ " size for each spatial dimension."
#~ msgstr ""

#~ msgid ""
#~ "2-D of shape [M, 2] where M "
#~ "is number of spatial dims, specifies "
#~ "[begin, end] crop size for each "
#~ "spatial dimension."
#~ msgstr ""

#~ msgid ""
#~ "**result** -- N-D Tensor with shape "
#~ "[batch / prod(block_shape), in_shape[1] * "
#~ "block_shape[0] - crops[0,0] - crops[0,1], "
#~ "..., in_shape[M] * block_shape[M-1] - "
#~ "crops[M-1, 0] - crops[M-1, 1], "
#~ "remaining_shape]"
#~ msgstr ""

#~ msgid ""
#~ "Add 1D bias to the axis of "
#~ "data. This function is a special "
#~ "case of add which allows inference "
#~ "of shape of the bias from data."
#~ msgstr ""

#~ msgid "The bias to be added."
#~ msgstr ""

#~ msgid "The axis to add the bias."
#~ msgstr ""

#~ msgid "**result** -- The final result."
#~ msgstr ""

#~ msgid ""
#~ "The values along the input tensor's "
#~ "pack_axis are quantized and packed "
#~ "together into the specified pack_type in"
#~ " a new bit axis."
#~ msgstr ""

#~ msgid ""
#~ "For example, consider bitpacking with "
#~ "data to be a tensor with shape "
#~ "`[1, 64, 128, 128]`, pack_axis=1, "
#~ "bit_axis=4, pack_type=uint8, and bits=2. The"
#~ " output in this case will be of"
#~ " shape `[1, 8, 128, 128, 2]`. "
#~ "The dimension of axis 1 has been"
#~ " reduced by a factor of 8 since"
#~ " each value is packed into an "
#~ "8-bit uint8. Axis 4 is now two "
#~ "bitplanes representing the quantized value "
#~ "of the incoming data. The output "
#~ "tensor is now ready to be used "
#~ "in a bitserial operation."
#~ msgstr ""

#~ msgid "The incoming tensor to be packed."
#~ msgstr ""

#~ msgid "Number of bits that should be packed."
#~ msgstr ""

#~ msgid "Axis that should be decomposed and packed."
#~ msgstr ""

#~ msgid "New axis containing bitplane."
#~ msgstr ""

#~ msgid "Datatype to pack bits into."
#~ msgstr ""

#~ msgid "Name of the operation."
#~ msgstr ""

#~ msgid "**result** -- The packed tensor."
#~ msgstr ""

#~ msgid "The weight expressions."
#~ msgstr ""

#~ msgid "The strides of convolution."
#~ msgstr ""

#~ msgid "The padding of convolution on both sides of inputs before convolution."
#~ msgstr ""

#~ msgid "Number of output channels of this convolution."
#~ msgstr ""

#~ msgid "The spatial of the convolution kernel."
#~ msgstr ""

#~ msgid "Number of bits to pack for activations."
#~ msgstr ""

#~ msgid "Number of bits to pack for weights."
#~ msgstr ""

#~ msgid "Layout of the kernel"
#~ msgstr ""

#~ msgid "Specifies the output data type for mixed precision conv2d."
#~ msgstr ""

#~ msgid ""
#~ "Bitserial Dense operator. Applies matrix "
#~ "multiplication of two quantized matrices "
#~ "using a fast bitserial algorithm."
#~ msgstr ""

#~ msgid "`Y = X * W`"
#~ msgstr ""

#~ msgid "Number of hidden units of the dense transformation."
#~ msgstr ""

#~ msgid "Number of bits incoming tensor should be packed with."
#~ msgstr ""

#~ msgid "Number of bits weight tensor should be packed with."
#~ msgstr ""

#~ msgid "Datatype to pack individual bits into before computation."
#~ msgstr ""

#~ msgid "Specifies the output data type for mixed precision dense."
#~ msgstr ""

#~ msgid "Whether to use unipolar or bipolar quantization for inputs."
#~ msgstr ""

#~ msgid "The constant value."
#~ msgstr ""

#~ msgid "The data type of the resulting constant."
#~ msgstr ""

#~ msgid "When dtype is None, we use the following rule:"
#~ msgstr ""

#~ msgid "int maps to \"int32\""
#~ msgstr ""

#~ msgid "float maps to \"float32\""
#~ msgstr ""

#~ msgid "bool maps to \"bool\""
#~ msgstr ""

#~ msgid "other using the same default rule as numpy."
#~ msgstr ""

#~ msgid ""
#~ "We separate this as a single op"
#~ " to enable pre-compute for inference."
#~ " Use this together with "
#~ "nn.contrib_conv2d_gemm_without_weight_transform"
#~ msgstr ""

#~ msgid "Tile rows of the weight transformation for ConvGemm."
#~ msgstr ""

#~ msgid "Tile columns of the weight transformation for ConvGemm."
#~ msgstr ""

#~ msgid ""
#~ "The basic parameters are the same "
#~ "as the ones in vanilla conv2d. It"
#~ " assumes the weight is pre-"
#~ "transformed by nn.contrib_conv2d_gemm_weight_transform"
#~ msgstr ""

#~ msgid "Specifies the dilation rate to be used for dilated convolution."
#~ msgstr ""

#~ msgid "Number of groups for grouped convolution."
#~ msgstr ""

#~ msgid "Layout of the weight."
#~ msgstr ""

#~ msgid "Layout of the output, by default, out_layout is the same as data_layout"
#~ msgstr ""

#~ msgid ""
#~ "This operator takes the weight as "
#~ "the convolution kernel and convolves it"
#~ " with data to produce an output, "
#~ "following a specialized NCHWc data "
#~ "layout."
#~ msgstr ""

#~ msgid "The kernel expressions."
#~ msgstr ""

#~ msgid ""
#~ "We separate this as a single op"
#~ " to enable pre-compute for inference."
#~ " Use this together with "
#~ "nn.contrib_conv2d_winograd_without_weight_transform"
#~ msgstr ""

#~ msgid "The Tile size of winograd. E.g. 2 for F(2x2, 3x3) and 4 for F(4x4, 3x3)"
#~ msgstr ""

#~ msgid ""
#~ "The basic parameters are the same "
#~ "as the ones in vanilla conv2d. It"
#~ " assumes the weight is pre-"
#~ "transformed by nn.contrib_conv2d_winograd_weight_transform"
#~ msgstr ""

#~ msgid ""
#~ "We separate this as a single op"
#~ " to enable pre-compute for inference."
#~ " Use this together with "
#~ "nn.contrib_conv3d_winograd_without_weight_transform"
#~ msgstr ""

#~ msgid ""
#~ "The Tile size of winograd. E.g. 2"
#~ " for F(2x2x2, 3x3x3) and 4 for "
#~ "F(4x4x4, 3x3x3)"
#~ msgstr ""

#~ msgid ""
#~ "The basic parameters are the same "
#~ "as the ones in vanilla conv3d. It"
#~ " assumes the weight is pre-"
#~ "transformed by nn.contrib_conv3d_winograd_weight_transform"
#~ msgstr ""

#~ msgid "Dense operator. Applies a linear transformation with packed weight"
#~ msgstr ""

#~ msgid "`Y = X * W^T`"
#~ msgstr ""

#~ msgid "The input data to the operator, of shape `(batch, units_in)`."
#~ msgstr ""

#~ msgid ""
#~ "The transformed weight expressions, 3-D "
#~ "matrix, of shape `(units // "
#~ "pack_weight_tile, units_in, pack_weight_tile)`."
#~ msgstr ""

#~ msgid "The layout of weight, such as \"NC\" or \"NC8n\"."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes the weight as "
#~ "the depthwise convolution kernel and "
#~ "depthwise convolves it with data to "
#~ "produce an output, following a "
#~ "specialized NCHWc data layout."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes the weight as "
#~ "the convolution kernel and convolves it"
#~ " with data to produce an output."
#~ msgstr ""

#~ msgid ""
#~ "In the default case, where the "
#~ "data_layout is `NCW` and kernel_layout "
#~ "is `OIW`, conv1d takes in a data"
#~ " Tensor with shape `(batch_size, "
#~ "in_channels, width)`, and a weight "
#~ "Tensor with shape `(channels, in_channels, "
#~ "kernel_size)` to produce an output "
#~ "Tensor with the following rule:"
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{out}[b, c, w] = \\sum_{dw, k}\n"
#~ "   \\mbox{data}[b, k, \\mbox{strides}[0] * w + dw] *\n"
#~ "   \\mbox{weight}[c, k, dw]"
#~ msgstr ""

#~ msgid ""
#~ "Padding and dilation are applied to "
#~ "data and weight respectively before the"
#~ " computation. This operator accepts data"
#~ " layout specification. Semantically, the "
#~ "operator will convert the layout to "
#~ "the canonical layout (`NCW` for data "
#~ "and `OIW` for weight), perform the "
#~ "computation, then convert to the "
#~ "out_layout."
#~ msgstr ""

#~ msgid ""
#~ "The padding of convolution on both "
#~ "sides of the input before convolution."
#~ msgstr ""

#~ msgid "Currently unused for 1D convolution."
#~ msgstr ""

#~ msgid "The spatial dimension of the convolution kernel."
#~ msgstr ""

#~ msgid "The padding of convolution on both sides of inputs."
#~ msgstr ""

#~ msgid "Used to disambiguate the output shape."
#~ msgstr ""

#~ msgid ""
#~ "In the default case, where the "
#~ "data_layout is `NCHW` and kernel_layout "
#~ "is `OIHW`, conv2d takes in a data"
#~ " Tensor with shape `(batch_size, "
#~ "in_channels, height, width)`, and a "
#~ "weight Tensor with shape `(channels, "
#~ "in_channels, kernel_size[0], kernel_size[1])` to "
#~ "produce an output Tensor with the "
#~ "following rule:"
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{out}[b, c, y, x] = \\sum_{dy, dx, k}\n"
#~ "   \\mbox{data}[b, k, \\mbox{strides}[0] * "
#~ "y  + dy, \\mbox{strides}[1] * x +"
#~ " dx] *\n"
#~ "   \\mbox{weight}[c, k, dy, dx]"
#~ msgstr ""

#~ msgid ""
#~ "Padding and dilation are applied to "
#~ "data and weight respectively before the"
#~ " computation. This operator accepts data"
#~ " layout specification. Semantically, the "
#~ "operator will convert the layout to "
#~ "the canonical layout (`NCHW` for data"
#~ " and `OIHW` for weight), perform the"
#~ " computation, then convert to the "
#~ "out_layout."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes the output gradient"
#~ " `grad` and convolves it with `data`"
#~ " as the convolution kernel, to "
#~ "produce the gradient with respect to "
#~ "weight."
#~ msgstr ""

#~ msgid ""
#~ "Note that the parameter `kernel_size` is"
#~ " the spatial size of the "
#~ "corresponding forward convolution kernel, not"
#~ " that of `data`. `grad_layout` and "
#~ "`kernel_layout` are the layouts of "
#~ "`grad` and the weight gradient "
#~ "respectively."
#~ msgstr ""

#~ msgid ""
#~ "Other parameters are the same as "
#~ "the conv2d op. See its documentation "
#~ "for more details."
#~ msgstr ""

#~ msgid ""
#~ "In the default case, where the "
#~ "data_layout is `NCDHW` and kernel_layout "
#~ "is `OIDHW`, conv3d takes in a data"
#~ " Tensor with shape `(batch_size, "
#~ "in_channels, depth, height, width)`, and "
#~ "a weight Tensor with shape `(channels,"
#~ " in_channels, kernel_size[0], kernel_size[1], "
#~ "kernel_size[2])` to produce an output "
#~ "Tensor with the following rule:"
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{out}[b, c, z, y, x] = \\sum_{dz, dy, dx, k}\n"
#~ "   \\mbox{data}[b, k, \\mbox{strides}[0] * "
#~ "z  + dz, \\mbox{strides}[1] * y  +"
#~ " dy,\n"
#~ "   \\mbox{strides}[2] * x + dx] * \\mbox{weight}[c, k, dz, dy, dx]"
#~ msgstr ""

#~ msgid ""
#~ "Padding and dilation are applied to "
#~ "data and weight respectively before the"
#~ " computation. This operator accepts data"
#~ " layout specification. Semantically, the "
#~ "operator will convert the layout to "
#~ "the canonical layout (`NCDHW` for data"
#~ " and `OIDHW` for weight), perform the"
#~ " computation, then convert to the "
#~ "out_layout."
#~ msgstr ""

#~ msgid "Specifies the output data type for mixed precision conv3d."
#~ msgstr ""

#~ msgid ""
#~ "The correlation layer performs multiplicative"
#~ " patch comparisons between two feature "
#~ "maps. Given two multi-channel feature"
#~ " maps :math:`f_{1}, f_{2}`, with :math:`w`,"
#~ " :math:`h`, and :math:`c` being their "
#~ "width, height, and number of channels,"
#~ " the correlation layer lets the "
#~ "network compare each patch from "
#~ ":math:`f_{1}` with each patch from "
#~ ":math:`f_{2}`."
#~ msgstr ""

#~ msgid ""
#~ "For now we consider only a single"
#~ " comparison of two patches. The "
#~ "'correlation' of two patches centered at"
#~ " :math:`x_{1}` in the first map and"
#~ " :math:`x_{2}` in the second map is"
#~ " then defined as:"
#~ msgstr ""

#~ msgid ""
#~ "c(x_{1}, x_{2}) = \\sum_{o \\in [-k,k]"
#~ " \\times [-k,k]} <f_{1}(x_{1} + o), "
#~ "f_{2}(x_{2} + o)>"
#~ msgstr ""

#~ msgid "for a square patch of size :math:`K:=2k+1`."
#~ msgstr ""

#~ msgid ""
#~ "Note that the equation above is "
#~ "identical to one step of a "
#~ "convolution in neural networks, but "
#~ "instead of convolving data with a "
#~ "filter, it convolves data with other"
#~ "    data. For this reason, it has "
#~ "no training weights."
#~ msgstr ""

#~ msgid ""
#~ "Computing :math:`c(x_{1}, x_{2})` involves "
#~ ":math:`c * K^{2}` multiplications. Comparing"
#~ " all patch combinations involves "
#~ ":math:`w^{2}*h^{2}` such computations."
#~ msgstr ""

#~ msgid ""
#~ "Given a maximum displacement :math:`d`, "
#~ "for each location :math:`x_{1}` it "
#~ "computes correlations :math:`c(x_{1}, x_{2})` "
#~ "only in a neighborhood of size "
#~ ":math:`D:=2d+1`, by limiting the range "
#~ "of :math:`x_{2}`. We use strides "
#~ ":math:`s_{1}, s_{2}`, to quantize "
#~ ":math:`x_{1}` globally and to quantize "
#~ ":math:`x_{2}` within the neighborhood centered"
#~ " around :math:`x_{1}`."
#~ msgstr ""

#~ msgid "The final output is defined by the following expression:"
#~ msgstr ""

#~ msgid "out[n, q, i, j] = c(x_{i, j}, x_{q})"
#~ msgstr ""

#~ msgid ""
#~ "where :math:`i` and :math:`j` enumerate "
#~ "spatial locations in :math:`f_{1}`, and "
#~ ":math:`q` denotes the :math:`q^{th}` "
#~ "neighborhood of :math:`x_{i,j}`."
#~ msgstr ""

#~ msgid "4-D with shape [batch, channel, height, width]"
#~ msgstr ""

#~ msgid "Kernel size for correlation, must be an odd number"
#~ msgstr ""

#~ msgid "Max displacement of Correlation"
#~ msgstr ""

#~ msgid "Stride for data1"
#~ msgstr ""

#~ msgid "Stride for data2 within the neightborhood centered around data1"
#~ msgstr ""

#~ msgid ""
#~ "Padding size, or [pad_height, pad_width] "
#~ "for 2 ints, or [pad_top, pad_left, "
#~ "pad_bottom, pad_right] for 4 ints"
#~ msgstr ""

#~ msgid "operation type is either multiplication or substraction"
#~ msgstr ""

#~ msgid "layout of data1, data2 and the output"
#~ msgstr ""

#~ msgid ""
#~ "**Output** -- 4-D with shape [batch, "
#~ "out_channel, out_height, out_width]"
#~ msgstr ""

#~ msgid "The predictions."
#~ msgstr ""

#~ msgid "The targets."
#~ msgstr ""

#~ msgid ""
#~ "The deformable convolution operation is "
#~ "described in https://arxiv.org/abs/1703.06211"
#~ msgstr ""

#~ msgid "The offset expressions."
#~ msgstr ""

#~ msgid "Number of deformable groups."
#~ msgstr ""

#~ msgid "Dense operator. Applies a linear transformation"
#~ msgstr ""

#~ msgid ""
#~ "The input data to the operator, of"
#~ " shape `(d_1, d_2, ..., d_n, "
#~ "units_in)`."
#~ msgstr ""

#~ msgid "The weight expressions, 2-D matrix, of shape `(units, units_in)`."
#~ msgstr ""

#~ msgid ""
#~ "Specifies the output data type for "
#~ "mixed precision dense, of shape `(d_1,"
#~ " d_2, ..., d_n, units)`."
#~ msgstr ""

#~ msgid "Input data with channels divisible by block_size**2"
#~ msgstr ""

#~ msgid "Size of blocks to convert channels into."
#~ msgstr ""

#~ msgid "One of NCHW or NHWC, indicates channel axis."
#~ msgstr ""

#~ msgid "One of DCR or CDR, indicates which order channels are accessed in."
#~ msgstr ""

#~ msgid ""
#~ "**result** --  Tensor with shape "
#~ "[in_batch, in_channel / block_size * "
#~ "block_size,                    in_height * "
#~ "block_size, in_width * block_size]"
#~ msgstr ""

#~ msgid "**result** --"
#~ msgstr ""

#~ msgid "Tensor with shape [in_batch, in_channel / block_size * block_size,"
#~ msgstr ""

#~ msgid "in_height * block_size, in_width * block_size]"
#~ msgstr ""

#~ msgid "n-D, can be any layout."
#~ msgstr ""

#~ msgid "Dilation stride on each dimension, 1 means no dilation."
#~ msgstr ""

#~ msgid "Value used to dilate the input."
#~ msgstr ""

#~ msgid "**Output** -- The computed result"
#~ msgstr ""

#~ msgid ""
#~ "During training, each element of the "
#~ "input is set to zero with "
#~ "probability ``p``. The whole array is"
#~ " rescaled by ``1/(1-p)`` to keep the"
#~ " expected sum of the input unchanged."
#~ msgstr ""

#~ msgid "The probability for an element to be reset to 0."
#~ msgstr ""

#~ msgid "**result** -- The result of dropout"
#~ msgstr ""

#~ msgid ""
#~ "Computes softmax. Use approximation to "
#~ "compute exponent for faster speed."
#~ msgstr ""

#~ msgid ""
#~ "\\text{softmax}(x)_i = \\frac{exp(x_i)}{\\sum_j exp(x_j)}\n"
#~ "\n"
#~ msgstr ""

#~ msgid "The axis to sum over when computing softmax"
#~ msgstr ""

#~ msgid "Compute equivalent of"
#~ msgstr ""

#~ msgid "Useful for"
#~ msgstr ""

#~ msgid ""
#~ "Encoding explicit re-use of computation"
#~ " in convolution ops operated on a "
#~ "sliding window input"
#~ msgstr ""

#~ msgid ""
#~ "Implementing a FIFO queue to cache "
#~ "intermediate results, e.g. as in Fast"
#~ " WaveNet."
#~ msgstr ""

#~ msgid "The input data"
#~ msgstr ""

#~ msgid "Previous value of the FIFO buffer"
#~ msgstr ""

#~ msgid "Specify which axis should be used for buffering"
#~ msgstr ""

#~ msgid "**result** -- Updated value for the buffer"
#~ msgstr ""

#~ msgid ""
#~ "* **pad_left** (*int*) -- Padding size"
#~ " on left * **pad_right** (*int*) --"
#~ " Padding size on right."
#~ msgstr ""

#~ msgid "**pad_left** (*int*) -- Padding size on left"
#~ msgstr ""

#~ msgid "**pad_right** (*int*) -- Padding size on right."
#~ msgstr ""

#~ msgid ""
#~ "* **pad_top** (*int*) -- Padding size"
#~ " on top * **pad_left** (*int*) -- "
#~ "Padding size on left * **pad_down** "
#~ "(*int*) -- Padding size on down. *"
#~ " **pad_right** (*int*) -- Padding size "
#~ "on right."
#~ msgstr ""

#~ msgid "**pad_top** (*int*) -- Padding size on top"
#~ msgstr ""

#~ msgid "**pad_down** (*int*) -- Padding size on down."
#~ msgstr ""

#~ msgid ""
#~ "* **pad_front** (*int*) -- Padding size"
#~ " on front * **pad_top** (*int*) --"
#~ " Padding size on top * **pad_left**"
#~ " (*int*) -- Padding size on left "
#~ "* **pad_back** (*int*) -- Padding size"
#~ " on back * **pad_down** (*int*) --"
#~ " Padding size on down. * "
#~ "**pad_right** (*int*) -- Padding size on"
#~ " right."
#~ msgstr ""

#~ msgid "**pad_front** (*int*) -- Padding size on front"
#~ msgstr ""

#~ msgid "**pad_back** (*int*) -- Padding size on back"
#~ msgstr ""

#~ msgid ""
#~ "In the default case, where the "
#~ "data_layout is `NCW` a data Tensor "
#~ "with shape `(batch_size, in_channels, width)`,"
#~ " to produce an output Tensor with "
#~ "the following rule:"
#~ msgstr ""

#~ msgid "with data of shape (b, c, w)"
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{out}(b, c, 1)  = \\frac{1}{w} "
#~ "\\sum_{n=0}^{w-1} \\mbox{data}(b, c, n)"
#~ msgstr ""

#~ msgid "with data of shape (b, c, h, w)"
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{out}(b, c, 1, 1)  = \\frac{1}{h"
#~ " * w} \\sum_{m=0}^{h-1} \\sum_{n=0}^{w-1}\n"
#~ "     \\mbox{data}(b, c, m, n)"
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 3D average value calculation"
#~ " across each window represented by "
#~ "DxWxH."
#~ msgstr ""

#~ msgid ""
#~ "In the default case, where the "
#~ "data_layout is `NCDHW` a data Tensor "
#~ "with shape `(batch_size, in_channels, depth,"
#~ " height, width)`, to produce an "
#~ "output Tensor with the following rule:"
#~ msgstr ""

#~ msgid "with data of shape (b, c, d, h, w)"
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{out}(b, c, 1, 1, 1)  = "
#~ "\\frac{1}{d * h * w} \\sum_{l=0}^{d-1}"
#~ "  \\sum_{m=0}^{h-1}\n"
#~ "     \\sum_{n=0}^{w-1} \\mbox{data}(b, c, l, m, n)"
#~ msgstr ""

#~ msgid "with data of shape (b, c, w) .. math::"
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{out}(b, c, 1, 1)  = \\max_{m=0,"
#~ " \\ldots, h} \\max_{n=0, \\ldots, w}\n"
#~ ""
#~ "     \\mbox{data}(b, c, m, n)"
#~ msgstr ""

#~ msgid "with data of shape (b, c, d, h, w) .. math::"
#~ msgstr ""

#~ msgid ""
#~ "Group normalization normalizes over group "
#~ "of channels for each training examples."
#~ " We can say that, Group Norm is"
#~ " in between Instance Norm and Layer"
#~ " Norm. When we put all the "
#~ "channels into a single group, group "
#~ "normalization becomes Layer normalization. "
#~ "And, when we put each channel into"
#~ " different groups it becomes Instance "
#~ "normalization"
#~ msgstr ""

#~ msgid "https://arxiv.org/pdf/1803.08494.pdf"
#~ msgstr ""

#~ msgid ""
#~ "Applies group normalization to the "
#~ "n-dimensional input array by seperating "
#~ "the input channels into 'num_groups' "
#~ "groups, each containing 'num_channels / "
#~ "num_groups' channels. The mean and "
#~ "standard-deviation are calculated separately "
#~ "over the each group. gamma and "
#~ "beta are learnable per-channel affine"
#~ " transform parameter vectors of size "
#~ "num_channels."
#~ msgstr ""

#~ msgid ""
#~ "out = \\frac{data - mean(data, "
#~ "axis)}{\\sqrt{var(data, axis)+\\epsilon}}\n"
#~ "    * gamma + beta"
#~ msgstr ""

#~ msgid ""
#~ "Unlike batch normalization, the mean and"
#~ " var are computed along a group "
#~ "of channels."
#~ msgstr ""

#~ msgid ""
#~ "If the input has size k on "
#~ "axis 1, then both gamma and beta"
#~ " have shape (k,)."
#~ msgstr ""

#~ msgid "Input to which group_norm will be applied."
#~ msgstr ""

#~ msgid "The number of groups to separate the channels into."
#~ msgstr ""

#~ msgid "The axis of the channels."
#~ msgstr ""

#~ msgid "If True, multiply by gamma. If False, gamma is not used."
#~ msgstr ""

#~ msgid "**result** -- The normalized data."
#~ msgstr ""

#~ msgid ""
#~ "out = \\frac{data - mean(data)}{\\sqrt{var(data)+\\epsilon}}\n"
#~ "    * gamma + beta"
#~ msgstr ""

#~ msgid ""
#~ "The instance normalization is similar to"
#~ " batch normalization, but unlike batch "
#~ "normalization, the mean and var are "
#~ "calculated per-dimension separately for "
#~ "each object(instance) in a mini-batch,"
#~ " not over a batch. And the same"
#~ " normalization is applied both at "
#~ "test and train time."
#~ msgstr ""

#~ msgid ""
#~ "The parameter ``axis`` specifies which "
#~ "axis of the input shape denotes "
#~ "the 'channel'.  The default is 1. "
#~ "Specifying -1 sets the channel axis "
#~ "to be the last item in the "
#~ "input shape."
#~ msgstr ""

#~ msgid "Input to which instance_norm will be applied."
#~ msgstr ""

#~ msgid ""
#~ "* **result** (*tvm.relay.Expr*) -- The "
#~ "normalized data. * **.. _`Instance "
#~ "Normalization** (The Missing Ingredient for"
#~ " Fast Stylization`:) -- "
#~ "https://arxiv.org/abs/1607.08022"
#~ msgstr ""

#~ msgid "**result** (*tvm.relay.Expr*) -- The normalized data."
#~ msgstr ""

#~ msgid ""
#~ "**.. _`Instance Normalization** (The Missing"
#~ " Ingredient for Fast Stylization`:) -- "
#~ "https://arxiv.org/abs/1607.08022"
#~ msgstr ""

#~ msgid ""
#~ "y(i, j) = x(i, j) / sqrt(max(sum(x^2), eps))\n"
#~ "\n"
#~ msgstr ""

#~ msgid "epsilon value"
#~ msgstr ""

#~ msgid "axis over the normalization applied"
#~ msgstr ""

#~ msgid ""
#~ "Layer normalization (Lei Ba and et "
#~ "al., 2016). Applies layer normalization "
#~ "to the n-dimensional input array. This"
#~ " operator takes an n-dimensional input "
#~ "array and normalizes the input using "
#~ "the given axis:"
#~ msgstr ""

#~ msgid ""
#~ "Unlike batch normalization, the mean and"
#~ " var are computed along the channel"
#~ " dimension."
#~ msgstr ""

#~ msgid ""
#~ "Assume the input has size k on "
#~ "axis 1, then both gamma and beta"
#~ " have shape (k,)."
#~ msgstr ""

#~ msgid "Input to which layer_norm will be applied."
#~ msgstr ""

#~ msgid "The axis that should be normalized, typically the axis of the channels."
#~ msgstr ""

#~ msgid "`y = x > 0 ? x : alpha * x`"
#~ msgstr ""

#~ msgid "Slope coefficient for the negative half axis."
#~ msgstr ""

#~ msgid "\\text{log_softmax}(x)_i = \\log \\frac{exp(x_i)}{\\sum_j exp(x_j)}"
#~ msgstr ""

#~ msgid "The axis to sum over when computing log softmax"
#~ msgstr ""

#~ msgid ""
#~ "Normalize the input in a local "
#~ "region across or within feature maps."
#~ " Each input value is divided by "
#~ "(data / (bias + (alpha * sum_data"
#~ " ^2 /size))^beta) where n is the "
#~ "size of each local region, and the"
#~ " sum is taken over the region "
#~ "centered at that value (zero padding "
#~ "is added where necessary)."
#~ msgstr ""

#~ msgid ""
#~ "(data / (bias + (alpha * sum_data ^2 /size))^beta)\n"
#~ "\n"
#~ msgstr ""

#~ msgid "The size of the local region to be considered for normalization."
#~ msgstr ""

#~ msgid "Input data layout channel axis. Default value is 1 for NCHW format"
#~ msgstr ""

#~ msgid "The offset parameter to avoid dividing by 0."
#~ msgstr ""

#~ msgid "The scaling parameter."
#~ msgstr ""

#~ msgid "The exponent parameter."
#~ msgstr ""

#~ msgid ""
#~ "Matmul operator. Applies a linear "
#~ "transformation. The A & B can be"
#~ " transposed."
#~ msgstr ""

#~ msgid "`C = A * B`"
#~ msgstr ""

#~ msgid ""
#~ "The first input of the operator, "
#~ "of shape `(d_1, d_2, ..., d_n, "
#~ "units_in)` or `(d_1, d_2, ..., units_in,"
#~ " d_n)`."
#~ msgstr ""

#~ msgid ""
#~ "The second input expressions, 2-D "
#~ "matrix, of shape `(units_in, units)` or"
#~ " `(units, units_in)`."
#~ msgstr ""

#~ msgid "Number of hidden units of the matmul transformation."
#~ msgstr ""

#~ msgid ""
#~ "Specifies the output data type for "
#~ "mixed precision matmul, of shape `(d_1,"
#~ " d_2, ..., d_n, units)`."
#~ msgstr ""

#~ msgid "Whether the data tensor is in transposed format."
#~ msgstr ""

#~ msgid "Whether the weight tensor is in transposed format."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 1D max value calculation "
#~ "with in pool_size sized window by "
#~ "striding defined by stride."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 2D max value calculation "
#~ "with in pool_size sized window by "
#~ "striding defined by stride"
#~ msgstr ""

#~ msgid "with data of shape (b, c, h, w) and pool_size (kh, kw)"
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{out}(b, c, y, x)  = \\max_{m=0,"
#~ " \\ldots, kh-1} \\max_{n=0, \\ldots, kw-1}"
#~ "\n"
#~ "     \\mbox{data}(b, c, \\mbox{stride}[0] *"
#~ " y + m, \\mbox{stride}[1] * x +"
#~ " n)"
#~ msgstr ""

#~ msgid ""
#~ "Padding is applied to data before "
#~ "the computation. ceil_mode is used to"
#~ " take ceil or floor while computing"
#~ " out shape. This operator accepts "
#~ "data layout specification."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes out_grad and data"
#~ " as input and calculates gradient of"
#~ " max_pool2d."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 3D max value calculation "
#~ "with in pool_size sized window by "
#~ "striding defined by stride."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes in a tensor "
#~ "and pads each axis by the "
#~ "specified widths using mirroring of the"
#~ " border pixels."
#~ msgstr ""

#~ msgid "The input data to the operator"
#~ msgstr ""

#~ msgid ""
#~ "Number of values padded to the "
#~ "edges of each axis, in the format"
#~ " of ((before_1, after_1), ..., (before_N,"
#~ " after_N))"
#~ msgstr ""

#~ msgid "What type of mirroring to use, must be SYMMETRIC or REFLECT."
#~ msgstr ""

#~ msgid "output{n, i_1, i_2, ..., i_k} = -p * w"
#~ msgstr ""

#~ msgid "where t = target{n, i_1, i_2, ..., i_k}"
#~ msgstr ""

#~ msgid ""
#~ "p = predictions{n, t, i_1, i_2, "
#~ "i_k} w = weights{n, i_1, i_2, ...,"
#~ " i_k} if t != ignore_index else "
#~ "0"
#~ msgstr ""

#~ msgid "result = reduction(output)"
#~ msgstr ""

#~ msgid "The target value of each prediction."
#~ msgstr ""

#~ msgid "The weight of each target value."
#~ msgstr ""

#~ msgid ""
#~ "The reduction method to apply to "
#~ "the output. Possible values are "
#~ "\"mean\", \"sum\" and \"none\"."
#~ msgstr ""

#~ msgid "The target value to ignore."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes in a tensor "
#~ "and pads each axis by the "
#~ "specified widths using the specified "
#~ "value."
#~ msgstr ""

#~ msgid "The value used for padding"
#~ msgstr ""

#~ msgid ""
#~ "'constant' pads with constant_value pad_value"
#~ " 'edge' pads using the edge values"
#~ " of the input array 'reflect' pads"
#~ " by reflecting values with respect to"
#~ " the edge"
#~ msgstr ""

#~ msgid "y = x > 0 ? x : alpha * x"
#~ msgstr ""

#~ msgid "Specify which shape axis the channel is specified."
#~ msgstr ""

#~ msgid ""
#~ "out = max(x, 0)\n"
#~ "\n"
#~ msgstr ""

#~ msgid ""
#~ "2-D of shape [M, 2] where M "
#~ "is number of spatial dims, specifies "
#~ "[before, after] paddings for each "
#~ "spatial dimension."
#~ msgstr ""

#~ msgid "The value used for padding."
#~ msgstr ""

#~ msgid ""
#~ "**result** -- N-D Tensor with shape "
#~ "[in_batch * prod(block_shape), padded_data[1] "
#~ "/ block_shape[0], ..., padded_data[M] / "
#~ "block_shape[M-1], remaining_shape]"
#~ msgstr ""

#~ msgid "Input data with spatial dimensions divisible by block_size"
#~ msgstr ""

#~ msgid "Size of blocks to decompose into channels."
#~ msgstr ""

#~ msgid ""
#~ "**result** --  Tensor with shape "
#~ "[in_batch, in_channel * block_size * "
#~ "block_size,                    in_height / "
#~ "block_size, in_width / block_size]"
#~ msgstr ""

#~ msgid "Tensor with shape [in_batch, in_channel * block_size * block_size,"
#~ msgstr ""

#~ msgid "in_height / block_size, in_width / block_size]"
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{sparse_add}(dense_mat, sparse_mat)[m, n] ="
#~ " \\mbox{add}(\\mbox{as_dense}(S), (D))[m, n]"
#~ msgstr ""

#~ msgid ""
#~ "where `as_dense` returns dense equivalent "
#~ "of the given S(sparse matrix) while "
#~ "performing addition with given D(dense "
#~ "matrix)."
#~ msgstr ""

#~ msgid "The input dense matrix for the matrix addition"
#~ msgstr ""

#~ msgid "The input sparse matrix(CSR) for the matrix addition."
#~ msgstr ""

#~ msgid "实际案例"
#~ msgstr ""

#~ msgid "\\if sparse_lhs=False:"
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{sparse_dense}(dense_mat, sparse_mat)[m, n]\n"
#~ "= \\mbox{matmul}(D, \\mbox{as_dense}(S)^T)[m, n]"
#~ msgstr ""

#~ msgid "\\if sparse_lhs=True:"
#~ msgstr ""

#~ msgid ""
#~ "\\mbox{sparse_dense}(dense_mat, sparse_mat)[m, n]\n"
#~ "= \\mbox{matmul}(\\mbox{as_dense}(S), (D)^T)[m, n]"
#~ msgstr ""

#~ msgid ""
#~ "where `as_dense` returns dense equivalent "
#~ "of the given S(sparse matrix) while "
#~ "performing matmul with given D(dense "
#~ "matrix)."
#~ msgstr ""

#~ msgid ""
#~ "See "
#~ "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html"
#~ " and "
#~ "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.bsr_matrix.html"
#~ " for more detail on the sparse "
#~ "matrix representation."
#~ msgstr ""

#~ msgid "The input dense matrix for the matrix multiplication"
#~ msgstr ""

#~ msgid "The input sparse matrix for the matrix multiplication."
#~ msgstr ""

#~ msgid "Indicates whether lhs or rhs matrix is sparse. Default value is False."
#~ msgstr ""

#~ msgid "** Currently only support Square Matrices **"
#~ msgstr ""

#~ msgid "\\mbox{sparse_transpose}(x)[n, n] = (x^T)[n, n]"
#~ msgstr ""

#~ msgid ""
#~ "Please refer to "
#~ "https://github.com/scipy/scipy/blob/v1.3.0/scipy/sparse/csr.py "
#~ "for the algorithm implemented in this"
#~ " operator."
#~ msgstr ""

#~ msgid "The sparse weight matrix for the fast matrix transpose."
#~ msgstr ""

#~ msgid ""
#~ "**result** -- Tuple of output sparse "
#~ "tensor (same shape and format as "
#~ "input), i.e. if CSR then output is"
#~ " in ([data, indices, indptr]) form"
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 2D scaling to the given"
#~ " scale factor. In the default case,"
#~ " where the data_layout is `NCHW` with"
#~ " data of shape (n, c, h, w) "
#~ "out will have a shape (n, c, "
#~ "h*scale_h, w*scale_w)"
#~ msgstr ""

#~ msgid ""
#~ "method indicates the algorithm to be "
#~ "used while calculating the out value "
#~ "and method can be one of "
#~ "(\"bilinear\", \"nearest_neighbor\", \"bicubic\")"
#~ msgstr ""

#~ msgid "The scale factor for height upsampling."
#~ msgstr ""

#~ msgid "The scale factor for width upsampling."
#~ msgstr ""

#~ msgid "Scale method to used [nearest_neighbor, bilinear, bicubic]."
#~ msgstr ""

#~ msgid "Whether to keep corners in proper place."
#~ msgstr ""

#~ msgid ""
#~ "This operator takes data as input "
#~ "and does 3D scaling to the given"
#~ " scale factor. In the default case,"
#~ " where the data_layout is `NCDHW` "
#~ "with data of shape (n, c, d, "
#~ "h, w) out will have a shape "
#~ "(n, c, d*scale_d, h*scale_h, w*scale_w)"
#~ msgstr ""

#~ msgid ""
#~ "method indicates the algorithm to be "
#~ "used while calculating the out value "
#~ "and method can be one of "
#~ "(\"trilinear\", \"nearest_neighbor\")"
#~ msgstr ""

#~ msgid "The scale factor for depth upsampling."
#~ msgstr ""

#~ msgid "Scale method to used [nearest_neighbor, trilinear]."
#~ msgstr ""

#~ msgid ""
#~ "Describes how to transform the "
#~ "coordinate in the resized tensor to "
#~ "the coordinate in the original tensor."
#~ " Refer to the ONNX Resize operator"
#~ " specification for details. Available "
#~ "options are \"half_pixel\", \"align_corners\" "
#~ "and \"asymmetric\"."
#~ msgstr ""

